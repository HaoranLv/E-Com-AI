{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PaddlePaddle BYOS\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments.  This can speed up iterative testing and debugging while using the same familiar Python SDK interface.  Just change your estimator's `train_instance_type` to `local` (or `local_gpu` if you're using an ml.p2 or ml.p3 notebook instance).\n",
    "\n",
    "In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU).\n",
    "\n",
    "**Note, you can only run a single local notebook at one time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/bin/bash ./utils/setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t\t finetune.py  README.md\t\t\t   uie_byos.ipynb\n",
      "doccano_org.py\t lambda       requirements.txt\t\t   utils\n",
      "doccano.py\t model\t      uie_byos_en_stary_gpu.ipynb  utils.py\n",
      "evaluate.py\t model.py     uie_byos_gpu_en.ipynb\n",
      "export_model.py  prepare.py   uie_byos_gpu.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting paddlepaddle\n",
      "  Using cached paddlepaddle-2.3.2-cp38-cp38-manylinux1_x86_64.whl (112.6 MB)\n",
      "Collecting paddlenlp\n",
      "  Using cached paddlenlp-2.4.0-py3-none-any.whl (1.8 MB)\n",
      "Collecting paddle-bfloat==0.1.7\n",
      "  Using cached paddle_bfloat-0.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "Collecting astor\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: protobuf<=3.20.0,>=3.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (3.19.4)\n",
      "Requirement already satisfied: numpy>=1.13 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (1.21.2)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (9.0.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (2.26.0)\n",
      "Collecting opt-einsum==3.3.0\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: decorator in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlepaddle) (5.1.0)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: colorama in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (0.4.3)\n",
      "Collecting paddlefsl\n",
      "  Using cached paddlefsl-1.1.0-py3-none-any.whl (101 kB)\n",
      "Collecting datasets>=2.0.0\n",
      "  Using cached datasets-2.4.0-py3-none-any.whl (365 kB)\n",
      "Requirement already satisfied: dill<0.3.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (0.3.4)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Collecting jieba\n",
      "  Using cached jieba-0.42.1-py3-none-any.whl\n",
      "Collecting paddle2onnx\n",
      "  Using cached paddle2onnx-1.0.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (4.62.3)\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: multiprocess<=0.70.12.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from paddlenlp) (0.70.12.2)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (3.8.1)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (7.0.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (1.3.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (2021.11.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp) (21.3)\n",
      "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.9.1-py3-none-any.whl (120 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle) (3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from seqeval->paddlenlp) (1.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp) (3.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from packaging->datasets>=2.0.0->paddlenlp) (3.0.6)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (3.0.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.7.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (4.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.7.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (5.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp) (2021.3)\n",
      "Installing collected packages: sentencepiece, paddle2onnx, paddle-bfloat, jieba, xxhash, opt-einsum, colorlog, astor, responses, paddlepaddle, paddlefsl, huggingface-hub, seqeval, datasets, paddlenlp\n",
      "Successfully installed astor-0.8.1 colorlog-6.7.0 datasets-2.4.0 huggingface-hub-0.9.1 jieba-0.42.1 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddle2onnx-1.0.0 paddlefsl-1.1.0 paddlenlp-2.4.0 paddlepaddle-2.3.2 responses-0.18.0 sentencepiece-0.1.97 seqeval-1.2.2 xxhash-3.0.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install paddlepaddle paddlenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch and Chainer. This tutorial focuses on how to create a convolutional neural network model to train the [Cifar10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html) using **PyTorch in local mode**.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "This notebook was created and tested on a single ml.p2.xlarge notebook instance.\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-PaddleNLP'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prepare.py \\\n",
    "    --mode 'folder' \\\n",
    "    --input_path '../Annotated_Data/Data_Mining' \\\n",
    "    --output_folder './output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-10-11 08:12:24,984] [    INFO]\u001b[0m - Converting doccano data...\u001b[0m\n",
      "100%|██████████████████████████████████████| 331/331 [00:00<00:00, 28855.29it/s]\n",
      "\u001b[32m[2022-10-11 08:12:24,997] [    INFO]\u001b[0m - Adding negative samples for first stage prompt...\u001b[0m\n",
      "100%|██████████████████████████████████████| 331/331 [00:00<00:00, 48295.92it/s]\n",
      "\u001b[32m[2022-10-11 08:12:25,004] [    INFO]\u001b[0m - Adding negative samples for second stage prompt...\u001b[0m\n",
      "100%|██████████████████████████████████████| 331/331 [00:00<00:00, 17172.34it/s]\n",
      "\u001b[32m[2022-10-11 08:12:25,025] [    INFO]\u001b[0m - Converting doccano data...\u001b[0m\n",
      "100%|████████████████████████████████████████| 37/37 [00:00<00:00, 44505.09it/s]\n",
      "\u001b[32m[2022-10-11 08:12:25,026] [    INFO]\u001b[0m - Adding negative samples for first stage prompt...\u001b[0m\n",
      "100%|████████████████████████████████████████| 37/37 [00:00<00:00, 72620.14it/s]\n",
      "\u001b[32m[2022-10-11 08:12:25,027] [    INFO]\u001b[0m - Adding negative samples for second stage prompt...\u001b[0m\n",
      "100%|███████████████████████████████████████| 37/37 [00:00<00:00, 457785.39it/s]\n",
      "\u001b[32m[2022-10-11 08:12:25,028] [    INFO]\u001b[0m - Converting doccano data...\u001b[0m\n",
      "0it [00:00, ?it/s]\n",
      "\u001b[32m[2022-10-11 08:12:25,028] [    INFO]\u001b[0m - Adding negative samples for first stage prompt...\u001b[0m\n",
      "0it [00:00, ?it/s]\n",
      "\u001b[32m[2022-10-11 08:12:25,070] [    INFO]\u001b[0m - Save 4026 examples to ./data/train.txt.\u001b[0m\n",
      "\u001b[32m[2022-10-11 08:12:25,075] [    INFO]\u001b[0m - Save 598 examples to ./data/dev.txt.\u001b[0m\n",
      "\u001b[32m[2022-10-11 08:12:25,076] [    INFO]\u001b[0m - Save 0 examples to ./data/test.txt.\u001b[0m\n",
      "\u001b[32m[2022-10-11 08:12:25,076] [    INFO]\u001b[0m - Finished! It takes 0.09 seconds\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python doccano.py \\\n",
    "    --folder_path ./output \\\n",
    "    --task_type ext \\\n",
    "    --save_dir ./data \\\n",
    "    --splits 0.9 0.1 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the data\n",
    "We use the ```sagemaker.Session.upload_data``` function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use this later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = sagemaker.Session().upload_data(path = \"./data\", key_prefix=prefix)\n",
    "# base_dir = 'file:///home/ec2-user/SageMaker/paddlenlp_sagemaker/data/'\n",
    "# inputs = {'training': base_dir}\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-064542430558/sagemaker/DEMO-PaddleNLP'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script Functions\n",
    "\n",
    "SageMaker invokes the main function defined within your training script for training. When deploying your trained model to an endpoint, the model_fn() is called to determine how to load your trained model. The model_fn() along with a few other functions list below are called to enable predictions on SageMaker.\n",
    "\n",
    "### [Predicting Functions](https://github.com/aws/sagemaker-pytorch-containers/blob/master/src/sagemaker_pytorch_container/serving.py)\n",
    "* model_fn(model_dir) - loads your model.\n",
    "* input_fn(serialized_input_data, content_type) - deserializes predictions to predict_fn.\n",
    "* output_fn(prediction_output, accept) - serializes predictions from predict_fn.\n",
    "* predict_fn(input_data, model) - calls a model on data deserialized in input_fn.\n",
    "\n",
    "The model_fn() is the only function that doesn't have a default implementation and is required by the user for using PyTorch on SageMaker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training job using the sagemaker.PyTorch estimator\n",
    "\n",
    "The `PyTorch` class allows us to run our training function on SageMaker. We need to configure it with our training script, an IAM role, the number of training instances, and the training instance type. For local training with GPU, we could set this to \"local_gpu\".  In this case, `instance_type` was set above based on your whether you're running a GPU instance.\n",
    "\n",
    "After we've constructed our `PyTorch` object, we fit it using the data we uploaded to S3. Even though we're in local mode, using S3 as our data source makes sense because it maintains consistency with how SageMaker's distributed, managed training ingests data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training using GPU instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'training': 's3://sagemaker-us-west-2-064542430558/sagemaker/DEMO-PaddleNLP'}\n"
     ]
    }
   ],
   "source": [
    "inputs = {'training': data_location}\n",
    "\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload uie-base-en pretrain\n",
    "\n",
    "# uie_en_model_s3 = sagemaker.Session().upload_data(path = \"../uie-base-en/taskflow/information_extraction/uie-base-en\", key_prefix=\"model_uie_base_en\")\n",
    "uie_en_model_s3 = 's3://sagemaker-us-west-2-064542430558/model_uie_base_en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-11 08:30:52 Starting - Starting the training job...\n",
      "2022-10-11 08:31:19 Starting - Preparing the instances for trainingProfilerReport-1665477052: InProgress\n",
      ".........\n",
      "2022-10-11 08:32:36 Downloading - Downloading input data...\n",
      "2022-10-11 08:33:16 Training - Downloading the training image.....................\n",
      "2022-10-11 08:36:49 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-10-11 08:36:52,430 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-10-11 08:36:52,476 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-10-11 08:36:52,482 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-10-11 08:36:53,009 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mLooking in indexes: https://opentuna.cn/pypi/web/simple/\u001b[0m\n",
      "\u001b[34mCollecting paddlepaddle-gpu\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/fb/f2/6b6ae62d5ecd916d61e1f527cb14990038d473cc670c30045f80b557e6e1/paddlepaddle_gpu-2.3.1-cp38-cp38-manylinux1_x86_64.whl (393.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 393.9/393.9 MB 2.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting paddlenlp\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/8e/e1/94cdbaca400a57687a8529213776468f003b64b6e35a6f4acf6b6539f543/paddlenlp-2.3.4-py3-none-any.whl (1.4 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 1.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting astor\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.13 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (1.22.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (5.1.1)\u001b[0m\n",
      "\u001b[34mCollecting protobuf<=3.20.0,>=3.1.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/88/88/cd55f87e896b82a3aba8e6c0affc077de51f7321cf730622b17ef7b0f69c/protobuf-3.20.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 4.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting paddle-bfloat==0.1.7\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/76/d7/ba0e1aeec33e20c78af5cf2fdbb7e7cabfe4679557e68759a17c97e03540/paddle_bfloat-0.1.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.5/385.5 kB 8.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.20.0 in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (2.27.1)\u001b[0m\n",
      "\u001b[34mCollecting opt-einsum==3.3.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl (65 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 8.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Pillow in /opt/conda/lib/python3.8/site-packages (from paddlepaddle-gpu->-r requirements.txt (line 2)) (9.1.1)\u001b[0m\n",
      "\u001b[34mCollecting datasets>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/98/29/f381f8a633fed2c4f41c191498c3bc43d91a8e44c5202a8b0b2bd8b1acf3/datasets-2.3.2-py3-none-any.whl (362 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 362.3/362.3 kB 9.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting jieba\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/c6/cb/18eeb235f833b726522d7ebed54f2278ce28ba9438e3135ab0278d9792a2/jieba-0.42.1.tar.gz (19.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 19.2/19.2 MB 11.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 3)) (0.4.4)\u001b[0m\n",
      "\u001b[34mCollecting paddle2onnx\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/78/76/811c8c897d68e211bc7ba13fa6161f54747eb717bffae80db0ea09ca2e43/paddle2onnx-0.9.8-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 6.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting seqeval\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.6/43.6 kB 3.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from paddlenlp->-r requirements.txt (line 3)) (4.61.2)\u001b[0m\n",
      "\u001b[34mCollecting dill<0.3.5\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/b6/c3/973676ceb86b60835bb3978c6db67a5dc06be6cfdbd14ef0f5a13e3fc9fd/dill-0.3.4-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.9/86.9 kB 1.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting colorlog\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/7d/54/e24efe5469ecb2710112055de87a2900e9494810bcfc25c12c7a0723eb64/colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting multiprocess<=0.70.12.2\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/e6/22/b09b8394f8c86ff0cfebd725ea96bba0accd4a4b2be437bcba6a0cf7d1c3/multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.3/128.3 kB 2.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/68/91/ded0f64f90abfc5413c620fc345a0aef1e7ff5addda8704cc6b3bf589c64/sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 3.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting paddlefsl\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/fb/4a/25d1959a8f1fe5ee400f32fc9fc8b56d4fd6fc25315e23c0171f6e705e2a/paddlefsl-1.1.0-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.0/101.0 kB 8.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2022.5.0)\u001b[0m\n",
      "\u001b[34mCollecting tqdm\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/8a/c4/d15f1e627fff25443ded77ea70a7b5532d6371498f9285d44d62587e209c/tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.4/78.4 kB 8.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/79/f3/2b3a6dc5986303b3dd1bbbcf482022acb2583c428cd23f0b6d37b1a1a519/responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/38/71/e1db3f96fa85f77906ef002a08fa8d02dbdb3292180d41eb1b17ddab72bf/aiohttp-3.8.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 5.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting xxhash\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/6a/cf/50f4cfde85d90c2b3e9c98b46e17d190bbdd97b54d3e0876e1d9360e487f/xxhash-3.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.1/212.1 kB 9.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (1.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (6.0.0)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0.0,>=0.1.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/d8/2c/9af8451ab780598e3b26a84d4f0e3844841456657401eb6843fdb622bb41/huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.5/101.5 kB 8.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (21.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (2022.5.18.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (1.26.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.20.0->paddlepaddle-gpu->-r requirements.txt (line 2)) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.8/site-packages (from seqeval->paddlenlp->-r requirements.txt (line 3)) (1.0.2)\u001b[0m\n",
      "\u001b[34mCollecting filelock\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/a6/d5/17f02b379525d1ff9678bfa58eb9548f561c8826deb0b85797aa0eed582d/filelock-3.7.1-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (3.10.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing<3,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2.4.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 3)) (1.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 3)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp->-r requirements.txt (line 3)) (2.2.0)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/aa/a6/a4ddcb1c3d93fc5d77a19b1ec338a3efec65b44345168d8ac9bf8461224a/yarl-1.7.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (308 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.6/308.6 kB 9.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/3b/87/fe94898f2d44a93a35d5aa74671ed28094d80753a1113d68b799fab6dc22/aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/3b/76/3d7c273b91e6dc914859f8752d42b763f39ae83782ec9a063a526c816977/frozenlist-1.3.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 158.7/158.7 kB 9.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/d6/c1/8991e7c5385b897b8c020cdaad718c5b087a6626d1d11a23e1ea87e325a7/async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (21.4.0)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading https://opentuna.cn/pypi/web/packages/8f/39/a7e04961b4c00d68aba337e3fdef9fd4f666dcd98f41725067a1de5d3399/multidict-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 9.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets>=2.0.0->paddlenlp->-r requirements.txt (line 3)) (2021.3)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: jieba, seqeval\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for jieba (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314477 sha256=bac9bdc818b3f22c8dcf61021a629ad3bb9d6d3998e658a0f4408e851cf4b61f\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/e9/6d/0d/92e938a9f51144388ebba6a81ebe4206fdd93f9c9de1434ec2\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for seqeval (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=140d3d017a262e8ed9ae0451472ca0e98f5bd3228cb90c1bd58c65b3ce1fdae6\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/6d/ff/58/c7ebcaa099f483531e06ca79ad5802e594d1c97c96c9c0f200\u001b[0m\n",
      "\u001b[34mSuccessfully built jieba seqeval\u001b[0m\n",
      "\u001b[34mInstalling collected packages: sentencepiece, paddle2onnx, paddle-bfloat, jieba, xxhash, tqdm, protobuf, opt-einsum, multidict, frozenlist, filelock, dill, colorlog, async-timeout, astor, yarl, responses, paddlepaddle-gpu, paddlefsl, multiprocess, huggingface-hub, aiosignal, seqeval, aiohttp, datasets, paddlenlp\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tqdm\u001b[0m\n",
      "\u001b[34mFound existing installation: tqdm 4.61.2\u001b[0m\n",
      "\u001b[34mUninstalling tqdm-4.61.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tqdm-4.61.2\u001b[0m\n",
      "\u001b[34mAttempting uninstall: protobuf\u001b[0m\n",
      "\u001b[34mFound existing installation: protobuf 3.20.1\u001b[0m\n",
      "\u001b[34mUninstalling protobuf-3.20.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled protobuf-3.20.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: dill\u001b[0m\n",
      "\u001b[34mFound existing installation: dill 0.3.5.1\u001b[0m\n",
      "\u001b[34mUninstalling dill-0.3.5.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled dill-0.3.5.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: multiprocess\u001b[0m\n",
      "\u001b[34mFound existing installation: multiprocess 0.70.13\u001b[0m\n",
      "\u001b[34mUninstalling multiprocess-0.70.13:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled multiprocess-0.70.13\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mpathos 0.2.9 requires dill>=0.3.5.1, but you have dill 0.3.4 which is incompatible.\u001b[0m\n",
      "\u001b[34mpathos 0.2.9 requires multiprocess>=0.70.13, but you have multiprocess 0.70.12.2 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-3.8.1 aiosignal-1.2.0 astor-0.8.1 async-timeout-4.0.2 colorlog-6.6.0 datasets-2.3.2 dill-0.3.4 filelock-3.7.1 frozenlist-1.3.0 huggingface-hub-0.8.1 jieba-0.42.1 multidict-6.0.2 multiprocess-0.70.12.2 opt-einsum-3.3.0 paddle-bfloat-0.1.7 paddle2onnx-0.9.8 paddlefsl-1.1.0 paddlenlp-2.3.4 paddlepaddle-gpu-2.3.1 protobuf-3.20.0 responses-0.18.0 sentencepiece-0.1.96 seqeval-1.2.2 tqdm-4.64.0 xxhash-3.0.0 yarl-1.7.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip available: 22.1.2 -> 22.2.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2022-10-11 08:38:05,670 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2022-10-11 08:38:05,670 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2022-10-11 08:38:05,803 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 16,\n",
      "        \"dev_path\": \"/opt/ml/input/data/training/dev.txt\",\n",
      "        \"device\": \"gpu\",\n",
      "        \"freeze\": true,\n",
      "        \"learning_rate\": 1e-05,\n",
      "        \"logging_steps\": 10,\n",
      "        \"max_seq_len\": 512,\n",
      "        \"model\": \"uie-base\",\n",
      "        \"num_epochs\": 20,\n",
      "        \"save_dir\": \"/opt/ml/model\",\n",
      "        \"seed\": 1000,\n",
      "        \"train_path\": \"/opt/ml/input/data/training/train.txt\",\n",
      "        \"valid_steps\": 1000\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-10-11-08-30-51-779\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-064542430558/pytorch-training-2022-10-11-08-30-51-779/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"finetune\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g4dn.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g4dn.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"finetune.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch_size\":16,\"dev_path\":\"/opt/ml/input/data/training/dev.txt\",\"device\":\"gpu\",\"freeze\":true,\"learning_rate\":1e-05,\"logging_steps\":10,\"max_seq_len\":512,\"model\":\"uie-base\",\"num_epochs\":20,\"save_dir\":\"/opt/ml/model\",\"seed\":1000,\"train_path\":\"/opt/ml/input/data/training/train.txt\",\"valid_steps\":1000}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=finetune.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=finetune\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-064542430558/pytorch-training-2022-10-11-08-30-51-779/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":16,\"dev_path\":\"/opt/ml/input/data/training/dev.txt\",\"device\":\"gpu\",\"freeze\":true,\"learning_rate\":1e-05,\"logging_steps\":10,\"max_seq_len\":512,\"model\":\"uie-base\",\"num_epochs\":20,\"save_dir\":\"/opt/ml/model\",\"seed\":1000,\"train_path\":\"/opt/ml/input/data/training/train.txt\",\"valid_steps\":1000},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-10-11-08-30-51-779\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-064542430558/pytorch-training-2022-10-11-08-30-51-779/source/sourcedir.tar.gz\",\"module_name\":\"finetune\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g4dn.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g4dn.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"finetune.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch_size\",\"16\",\"--dev_path\",\"/opt/ml/input/data/training/dev.txt\",\"--device\",\"gpu\",\"--freeze\",\"True\",\"--learning_rate\",\"1e-05\",\"--logging_steps\",\"10\",\"--max_seq_len\",\"512\",\"--model\",\"uie-base\",\"--num_epochs\",\"20\",\"--save_dir\",\"/opt/ml/model\",\"--seed\",\"1000\",\"--train_path\",\"/opt/ml/input/data/training/train.txt\",\"--valid_steps\",\"1000\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_DEV_PATH=/opt/ml/input/data/training/dev.txt\u001b[0m\n",
      "\u001b[34mSM_HP_DEVICE=gpu\u001b[0m\n",
      "\u001b[34mSM_HP_FREEZE=true\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING_RATE=1e-05\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_STEPS=10\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_SEQ_LEN=512\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL=uie-base\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_EPOCHS=20\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=1000\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_PATH=/opt/ml/input/data/training/train.txt\u001b[0m\n",
      "\u001b[34mSM_HP_VALID_STEPS=1000\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python finetune.py --batch_size 16 --dev_path /opt/ml/input/data/training/dev.txt --device gpu --freeze True --learning_rate 1e-05 --logging_steps 10 --max_seq_len 512 --model uie-base --num_epochs 20 --save_dir /opt/ml/model --seed 1000 --train_path /opt/ml/input/data/training/train.txt --valid_steps 1000\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:38:09,310] [    INFO]#033[0m - Downloading resource files...#033[0m\u001b[0m\n",
      "\u001b[34m0%|          | 0/460749 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 3/460749 [00:00<9:33:53, 13.38it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 35/460749 [00:00<1:26:22, 88.90it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 83/460749 [00:00<43:34, 176.18it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 195/460749 [00:00<26:12, 292.88it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 307/460749 [00:01<22:27, 341.63it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 419/460749 [00:01<18:16, 419.80it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 547/460749 [00:01<17:29, 438.52it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 675/460749 [00:01<16:03, 477.64it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 803/460749 [00:01<14:15, 537.73it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 947/460749 [00:02<14:20, 534.30it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1091/460749 [00:02<12:44, 601.09it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1251/460749 [00:02<12:50, 596.07it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1411/460749 [00:02<11:27, 668.36it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1587/460749 [00:03<11:35, 660.40it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1763/460749 [00:03<11:00, 694.82it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 1955/460749 [00:03<10:20, 739.56it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 2147/460749 [00:03<09:18, 821.07it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2355/460749 [00:04<08:58, 850.75it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2563/460749 [00:04<08:44, 872.79it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 2803/460749 [00:04<08:13, 927.92it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3027/460749 [00:04<07:36, 1003.19it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3283/460749 [00:04<07:43, 986.60it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3555/460749 [00:05<07:15, 1049.82it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 3827/460749 [00:05<06:57, 1095.31it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4115/460749 [00:05<06:37, 1147.75it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4419/460749 [00:05<05:57, 1274.91it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 4739/460749 [00:06<05:46, 1317.36it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 5075/460749 [00:06<05:33, 1368.27it/s]\u001b[0m\n",
      "\u001b[34m1%|          | 5427/460749 [00:06<05:19, 1424.85it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 5795/460749 [00:06<04:27, 1699.19it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 5979/460749 [00:06<05:03, 1497.28it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 6195/460749 [00:06<04:59, 1517.78it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 6595/460749 [00:07<04:01, 1883.86it/s]\u001b[0m\n",
      "\u001b[34m1%|▏         | 6797/460749 [00:07<04:39, 1626.26it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7043/460749 [00:07<04:52, 1552.07it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7491/460749 [00:07<04:08, 1824.64it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 7955/460749 [00:07<03:22, 2233.80it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8191/460749 [00:07<03:55, 1920.98it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8467/460749 [00:08<04:10, 1808.50it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 8979/460749 [00:08<03:34, 2109.76it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9523/460749 [00:08<02:53, 2595.04it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 9797/460749 [00:08<03:22, 2231.00it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10115/460749 [00:08<03:19, 2258.87it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 10707/460749 [00:08<02:38, 2838.51it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11006/460749 [00:09<03:05, 2418.85it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11363/460749 [00:09<03:16, 2290.68it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 12019/460749 [00:09<02:46, 2694.66it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 12707/460749 [00:09<02:15, 3313.35it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13055/460749 [00:09<02:37, 2836.64it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 13459/460749 [00:09<02:35, 2874.41it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 14211/460749 [00:10<02:03, 3614.98it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 14591/460749 [00:10<02:25, 3072.38it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 15043/460749 [00:10<02:21, 3141.41it/s]\u001b[0m\n",
      "\u001b[34m3%|▎         | 15859/460749 [00:10<01:52, 3959.04it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 16275/460749 [00:10<02:12, 3355.78it/s]\u001b[0m\n",
      "\u001b[34m4%|▎         | 16787/460749 [00:10<02:08, 3467.84it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 17683/460749 [00:10<01:41, 4370.24it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 18142/460749 [00:11<01:59, 3696.96it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 18707/460749 [00:11<01:55, 3825.34it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 19699/460749 [00:11<01:31, 4829.06it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 20206/460749 [00:11<01:47, 4083.89it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 20819/460749 [00:11<01:44, 4206.04it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 21923/460749 [00:11<01:22, 5332.17it/s]\u001b[0m\n",
      "\u001b[34m5%|▍         | 22482/460749 [00:12<01:37, 4508.77it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 23155/460749 [00:12<01:34, 4637.04it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 24355/460749 [00:12<01:14, 5852.91it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 24969/460749 [00:12<01:28, 4941.37it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 25715/460749 [00:12<01:25, 5106.21it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 27009/460749 [00:12<01:03, 6841.37it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 27773/460749 [00:12<01:19, 5454.33it/s]\u001b[0m\n",
      "\u001b[34m6%|▌         | 28547/460749 [00:13<01:17, 5550.79it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 29824/460749 [00:13<01:00, 7134.29it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 30643/460749 [00:13<01:14, 5750.62it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 31667/460749 [00:13<01:07, 6394.43it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 32398/460749 [00:13<01:05, 6509.40it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 33331/460749 [00:13<01:02, 6847.81it/s]\u001b[0m\n",
      "\u001b[34m7%|▋         | 34067/460749 [00:13<01:02, 6876.12it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 35107/460749 [00:13<00:57, 7383.69it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 35872/460749 [00:14<00:57, 7334.37it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 36947/460749 [00:14<00:54, 7818.84it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 37741/460749 [00:14<00:54, 7716.30it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 38899/460749 [00:14<00:50, 8305.38it/s]\u001b[0m\n",
      "\u001b[34m9%|▊         | 39733/460749 [00:14<00:51, 8169.60it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 40931/460749 [00:14<00:48, 8740.20it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 41804/460749 [00:14<00:48, 8571.78it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 43075/460749 [00:14<00:45, 9215.77it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 43993/460749 [00:14<00:46, 9007.09it/s]\u001b[0m\n",
      "\u001b[34m10%|▉         | 45315/460749 [00:15<00:42, 9672.41it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 46278/460749 [00:15<00:43, 9431.94it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 47683/460749 [00:15<00:41, 9902.48it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 48976/460749 [00:15<00:38, 10709.81it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 50147/460749 [00:15<00:38, 10546.87it/s]\u001b[0m\n",
      "\u001b[34m11%|█         | 51206/460749 [00:15<00:39, 10305.91it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 52723/460749 [00:15<00:37, 10775.84it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 54067/460749 [00:15<00:35, 11488.59it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 55395/460749 [00:16<00:36, 11159.05it/s]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 56573/460749 [00:16<00:35, 11325.81it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 58211/460749 [00:16<00:33, 11854.97it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 59397/460749 [00:16<00:33, 11846.51it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 61123/460749 [00:16<00:31, 12819.78it/s]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 62404/460749 [00:16<00:32, 12354.55it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 64147/460749 [00:16<00:29, 13269.51it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 65473/460749 [00:16<00:33, 11795.48it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 67267/460749 [00:16<00:31, 12311.71it/s]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 68723/460749 [00:17<00:32, 11921.26it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 70195/460749 [00:17<00:30, 12624.28it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 71479/460749 [00:17<00:33, 11774.70it/s]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 73123/460749 [00:17<00:32, 11941.68it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 75043/460749 [00:17<00:30, 12715.60it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 76321/460749 [00:17<00:31, 12379.98it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 77779/460749 [00:17<00:30, 12435.98it/s]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 79171/460749 [00:17<00:30, 12490.44it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 80707/460749 [00:18<00:29, 12697.96it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 82019/460749 [00:18<00:30, 12469.24it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 83571/460749 [00:18<00:29, 12731.54it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 84844/460749 [00:18<00:30, 12374.42it/s]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 86323/460749 [00:18<00:29, 12486.41it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 87571/460749 [00:18<00:30, 12086.08it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 89043/460749 [00:18<00:30, 12299.56it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 90323/460749 [00:18<00:30, 12107.38it/s]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 91955/460749 [00:18<00:29, 12684.48it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 93222/460749 [00:19<00:29, 12322.64it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 94835/460749 [00:19<00:28, 12803.91it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 96113/460749 [00:19<00:29, 12434.32it/s]\u001b[0m\n",
      "\u001b[34m21%|██        | 97459/460749 [00:19<00:29, 12182.93it/s]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 98676/460749 [00:19<00:30, 11830.96it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 100195/460749 [00:19<00:29, 12202.00it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 101571/460749 [00:19<00:29, 12294.73it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 103027/460749 [00:19<00:28, 12347.73it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 104451/460749 [00:19<00:28, 12525.37it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 105907/460749 [00:20<00:28, 12509.29it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 107251/460749 [00:20<00:28, 12427.58it/s]\u001b[0m\n",
      "\u001b[34m24%|██▎       | 108595/460749 [00:20<00:28, 12146.19it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 109811/460749 [00:20<00:29, 11807.00it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 111427/460749 [00:20<00:28, 12456.44it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 112691/460749 [00:20<00:28, 12152.37it/s]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 114291/460749 [00:20<00:27, 12651.87it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 115587/460749 [00:20<00:27, 12378.49it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 117187/460749 [00:20<00:26, 12808.80it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 118466/460749 [00:21<00:27, 12417.95it/s]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 119955/460749 [00:21<00:27, 12572.87it/s]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 121211/460749 [00:21<00:27, 12141.76it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 122595/460749 [00:21<00:27, 12129.64it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 124035/460749 [00:21<00:27, 12395.22it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 125411/460749 [00:21<00:27, 12224.12it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 126995/460749 [00:21<00:25, 12849.92it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 128291/460749 [00:21<00:26, 12322.80it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 129939/460749 [00:21<00:25, 13092.09it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 131252/460749 [00:22<00:26, 12484.97it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 132755/460749 [00:22<00:25, 12879.84it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 134048/460749 [00:22<00:26, 12234.36it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 135475/460749 [00:22<00:25, 12543.81it/s]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 136771/460749 [00:22<00:26, 12093.66it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 138275/460749 [00:22<00:25, 12557.18it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 139731/460749 [00:22<00:25, 12533.14it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 141139/460749 [00:22<00:25, 12613.01it/s]\u001b[0m\n",
      "\u001b[34m31%|███       | 142739/460749 [00:23<00:24, 12950.95it/s]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 144036/460749 [00:23<00:25, 12576.32it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 145683/460749 [00:23<00:24, 13086.42it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 146991/460749 [00:23<00:24, 12589.42it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 148371/460749 [00:23<00:28, 10921.73it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 150819/460749 [00:23<00:23, 13314.48it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 152177/460749 [00:23<00:25, 12158.94it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 154147/460749 [00:23<00:26, 11632.34it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 156195/460749 [00:24<00:23, 12776.99it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 157504/460749 [00:24<00:25, 11847.35it/s]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 159507/460749 [00:24<00:26, 11415.41it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 161859/460749 [00:24<00:22, 13192.79it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 163218/460749 [00:24<00:24, 12184.12it/s]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 165187/460749 [00:24<00:25, 11668.65it/s]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 167683/460749 [00:25<00:21, 13640.22it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 169092/460749 [00:25<00:23, 12191.23it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 170803/460749 [00:25<00:25, 11568.80it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 173187/460749 [00:25<00:21, 13370.00it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 174571/460749 [00:25<00:23, 11961.22it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 176451/460749 [00:25<00:24, 11722.09it/s]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 178451/460749 [00:25<00:22, 12706.29it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 179756/460749 [00:26<00:23, 11810.85it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 181859/460749 [00:26<00:24, 11599.91it/s]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 183795/460749 [00:26<00:22, 12480.56it/s]\u001b[0m\n",
      "\u001b[34m40%|████      | 185068/460749 [00:26<00:23, 11659.27it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 187267/460749 [00:26<00:23, 11618.28it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 189267/460749 [00:26<00:21, 12618.71it/s]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 190551/460749 [00:26<00:23, 11677.04it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 192659/460749 [00:27<00:23, 11544.21it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 194995/460749 [00:27<00:20, 13253.69it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 196354/460749 [00:27<00:21, 12203.50it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 198371/460749 [00:27<00:22, 11787.64it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 200419/460749 [00:27<00:20, 12839.40it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 201733/460749 [00:27<00:21, 11916.32it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 203747/460749 [00:28<00:20, 12787.83it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 205042/460749 [00:28<00:20, 12581.07it/s]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 206531/460749 [00:28<00:20, 12587.15it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 207795/460749 [00:28<00:20, 12288.45it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 209315/460749 [00:28<00:20, 12503.25it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 210566/460749 [00:28<00:20, 12244.29it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 212147/460749 [00:28<00:19, 12579.09it/s]\u001b[0m\n",
      "\u001b[34m46%|████▋     | 213404/460749 [00:28<00:20, 12335.31it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 214931/460749 [00:28<00:19, 12476.41it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 216222/460749 [00:29<00:19, 12593.26it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 217715/460749 [00:29<00:19, 12327.85it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 218950/460749 [00:29<00:20, 12029.71it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 220387/460749 [00:29<00:19, 12095.67it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 221731/460749 [00:29<00:19, 12216.54it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 223203/460749 [00:29<00:19, 12257.21it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 224643/460749 [00:29<00:18, 12587.37it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 226083/460749 [00:29<00:18, 12425.96it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 227571/460749 [00:29<00:18, 12837.69it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 228899/460749 [00:30<00:18, 12295.23it/s]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 230355/460749 [00:30<00:18, 12667.13it/s]\u001b[0m\n",
      "\u001b[34m50%|█████     | 231627/460749 [00:30<00:19, 12005.78it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 233171/460749 [00:30<00:17, 12731.49it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 234453/460749 [00:30<00:18, 11988.20it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 235987/460749 [00:30<00:17, 12775.47it/s]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 237279/460749 [00:30<00:18, 12124.73it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 238883/460749 [00:30<00:17, 12977.49it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 240195/460749 [00:30<00:17, 12292.25it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 241715/460749 [00:31<00:16, 12893.61it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 243018/460749 [00:31<00:17, 12135.17it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 244371/460749 [00:31<00:17, 12398.83it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 245779/460749 [00:31<00:17, 12179.04it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 247235/460749 [00:31<00:16, 12609.25it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 248771/460749 [00:31<00:16, 12657.27it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 250115/460749 [00:31<00:16, 12654.70it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 251763/460749 [00:31<00:16, 12982.45it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 253063/460749 [00:31<00:16, 12716.09it/s]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 254595/460749 [00:32<00:16, 12772.37it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 255872/460749 [00:32<00:16, 12441.62it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 257347/460749 [00:32<00:16, 12495.95it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 258596/460749 [00:32<00:16, 12252.43it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 260163/460749 [00:32<00:16, 12525.41it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 261507/460749 [00:32<00:15, 12544.27it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 262995/460749 [00:32<00:15, 12505.65it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 264467/460749 [00:32<00:15, 12868.84it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 265763/460749 [00:33<00:15, 12226.11it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 267363/460749 [00:33<00:14, 13012.96it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 268671/460749 [00:33<00:15, 12225.60it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 270131/460749 [00:33<00:14, 12770.56it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 271420/460749 [00:33<00:15, 12052.68it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 273091/460749 [00:33<00:14, 13172.96it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 274426/460749 [00:33<00:14, 12426.37it/s]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 275971/460749 [00:33<00:14, 13120.30it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 277301/460749 [00:33<00:14, 12317.28it/s]\u001b[0m\n",
      "\u001b[34m60%|██████    | 278595/460749 [00:34<00:14, 12428.23it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 279852/460749 [00:34<00:15, 11775.15it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 281363/460749 [00:34<00:14, 12480.44it/s]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 282787/460749 [00:34<00:14, 12275.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 284211/460749 [00:34<00:14, 12596.00it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 285715/460749 [00:34<00:13, 12565.18it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 287155/460749 [00:34<00:13, 12842.66it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 288579/460749 [00:34<00:13, 12530.68it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 290147/460749 [00:34<00:12, 13154.63it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 291470/460749 [00:35<00:13, 12417.85it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 293011/460749 [00:35<00:12, 13066.92it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 294329/460749 [00:35<00:13, 12258.08it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 295715/460749 [00:35<00:13, 12605.51it/s]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 296989/460749 [00:35<00:13, 11955.13it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 298547/460749 [00:35<00:12, 12695.68it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 299829/460749 [00:35<00:13, 12106.12it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 301459/460749 [00:35<00:12, 12969.43it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 302767/460749 [00:35<00:12, 12366.67it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 304291/460749 [00:36<00:12, 12866.12it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 305619/460749 [00:36<00:12, 12354.11it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 307139/460749 [00:36<00:11, 12841.74it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 308431/460749 [00:36<00:12, 12131.96it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 309923/460749 [00:36<00:11, 12700.15it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 311204/460749 [00:36<00:12, 12050.68it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 312787/460749 [00:36<00:11, 12832.69it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 314082/460749 [00:36<00:11, 12225.28it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 315731/460749 [00:36<00:11, 13110.32it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 317053/460749 [00:37<00:11, 12456.60it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 318643/460749 [00:37<00:10, 13149.54it/s]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 319969/460749 [00:37<00:11, 12475.58it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 321507/460749 [00:37<00:10, 13043.74it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 322823/460749 [00:37<00:11, 12367.17it/s]\u001b[0m\n",
      "\u001b[34m70%|███████   | 324227/460749 [00:37<00:10, 12619.17it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 325498/460749 [00:37<00:11, 11992.06it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 326755/460749 [00:37<00:11, 11921.03it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 328211/460749 [00:37<00:10, 12071.65it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 329619/460749 [00:38<00:10, 12307.63it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 331107/460749 [00:38<00:10, 12427.11it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 332531/460749 [00:38<00:10, 12596.56it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 333955/460749 [00:38<00:10, 12459.47it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 335411/460749 [00:38<00:09, 12701.04it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 336683/460749 [00:38<00:10, 12120.77it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 338275/460749 [00:38<00:09, 12841.59it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 339564/460749 [00:38<00:09, 12161.61it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 341107/460749 [00:39<00:09, 12841.69it/s]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 342400/460749 [00:39<00:09, 12181.83it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 344035/460749 [00:39<00:08, 13089.81it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 345356/460749 [00:39<00:09, 12409.98it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 346947/460749 [00:39<00:08, 13152.93it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 348275/460749 [00:39<00:09, 12370.22it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 349811/460749 [00:39<00:08, 13080.25it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 351135/460749 [00:39<00:08, 12254.32it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 352499/460749 [00:39<00:08, 12593.68it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 353775/460749 [00:40<00:09, 11803.97it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 355347/460749 [00:40<00:08, 12795.02it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 356648/460749 [00:40<00:08, 12045.01it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 358275/460749 [00:40<00:07, 13104.42it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 359610/460749 [00:40<00:08, 12332.64it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 361187/460749 [00:40<00:07, 13186.44it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 362529/460749 [00:40<00:07, 12364.56it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 364099/460749 [00:40<00:07, 13239.30it/s]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 365449/460749 [00:40<00:07, 12338.05it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 366904/460749 [00:41<00:07, 12933.20it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 368223/460749 [00:41<00:07, 12126.72it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 369460/460749 [00:41<00:07, 12177.03it/s]\u001b[0m\n",
      "\u001b[34m80%|████████  | 370696/460749 [00:41<00:07, 11650.47it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 372371/460749 [00:41<00:06, 12773.43it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 373663/460749 [00:41<00:07, 12124.78it/s]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 375283/460749 [00:41<00:06, 13018.15it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 376599/460749 [00:41<00:06, 12226.94it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 378163/460749 [00:41<00:06, 13074.59it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 379490/460749 [00:42<00:06, 12188.37it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 380972/460749 [00:42<00:06, 12896.08it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 382285/460749 [00:42<00:06, 12089.63it/s]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 383827/460749 [00:42<00:05, 12931.72it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 385145/460749 [00:42<00:06, 12168.07it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 386771/460749 [00:42<00:05, 13274.71it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 388127/460749 [00:42<00:05, 12408.84it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 389722/460749 [00:42<00:05, 13365.21it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 391089/460749 [00:42<00:05, 12506.91it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 392599/460749 [00:43<00:05, 13206.96it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 393948/460749 [00:43<00:05, 12360.92it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 395349/460749 [00:43<00:05, 12806.26it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 396654/460749 [00:43<00:05, 11991.47it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 397915/460749 [00:43<00:05, 12158.19it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 399251/460749 [00:43<00:05, 11872.92it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 400707/460749 [00:43<00:04, 12371.91it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 402195/460749 [00:43<00:04, 12387.06it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 403603/460749 [00:43<00:04, 12612.77it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 405091/460749 [00:44<00:04, 12551.31it/s]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 406355/460749 [00:44<00:04, 12342.30it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 407859/460749 [00:44<00:04, 12409.95it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 409102/460749 [00:44<00:04, 12108.60it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 410739/460749 [00:44<00:03, 12678.00it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 412006/460749 [00:44<00:03, 12412.79it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 413619/460749 [00:44<00:03, 12771.27it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 415011/460749 [00:44<00:03, 12822.86it/s]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 416467/460749 [00:45<00:03, 12633.50it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 418035/460749 [00:45<00:03, 13195.73it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 419357/460749 [00:45<00:03, 12494.71it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 421027/460749 [00:45<00:02, 13412.27it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 422377/460749 [00:45<00:03, 12552.76it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 423907/460749 [00:45<00:02, 13246.71it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 425248/460749 [00:45<00:02, 12444.42it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 426755/460749 [00:45<00:02, 13083.91it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 428082/460749 [00:45<00:02, 12219.97it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 429443/460749 [00:46<00:02, 12590.50it/s]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 430771/460749 [00:46<00:02, 12013.18it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 432387/460749 [00:46<00:02, 13015.48it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 433779/460749 [00:46<00:02, 12464.37it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 435235/460749 [00:46<00:01, 12908.00it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 436787/460749 [00:46<00:01, 12814.87it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 438099/460749 [00:46<00:01, 12773.88it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 439795/460749 [00:46<00:01, 13100.43it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 441109/460749 [00:46<00:01, 12908.19it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 442723/460749 [00:47<00:01, 13043.00it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 444028/460749 [00:47<00:01, 12724.65it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 445555/460749 [00:47<00:01, 12813.15it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 446836/460749 [00:47<00:01, 12446.32it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 448083/460749 [00:47<00:01, 11933.74it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 449475/460749 [00:47<00:00, 12341.66it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 450963/460749 [00:47<00:00, 12271.61it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 452467/460749 [00:47<00:00, 12887.39it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 453843/460749 [00:47<00:00, 12352.39it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 455459/460749 [00:48<00:00, 13244.71it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 456796/460749 [00:48<00:00, 12453.64it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 458403/460749 [00:48<00:00, 13335.61it/s]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 459754/460749 [00:48<00:00, 12458.86it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 460749/460749 [00:48<00:00, 9503.36it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 1229.28it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/183 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m2%|▏         | 3/183 [00:00<00:13, 13.30it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 19/183 [00:00<00:05, 29.67it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 35/183 [00:00<00:03, 43.90it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 51/183 [00:01<00:02, 52.80it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 67/183 [00:01<00:01, 58.58it/s]\u001b[0m\n",
      "\u001b[34m45%|████▌     | 83/183 [00:01<00:01, 62.39it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 99/183 [00:01<00:01, 65.00it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 115/183 [00:02<00:01, 51.11it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 131/183 [00:02<00:00, 56.06it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 163/183 [00:02<00:00, 78.65it/s]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 179/183 [00:02<00:00, 76.52it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 183/183 [00:02<00:00, 62.27it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 1215.74it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 1/1 [00:00<00:00, 1264.87it/s]\u001b[0m\n",
      "\u001b[34m<<<< load model from uie-base-en!!!\u001b[0m\n",
      "\u001b[34mW1011 08:39:06.070834    73 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 11.6, Runtime API Version: 10.2\u001b[0m\n",
      "\u001b[34mW1011 08:39:06.091187    73 gpu_resources.cc:91] device: 0, cuDNN Version: 8.0.\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:39:10,910] [    INFO]#033[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '/opt/ml/checkpoints/'.#033[0m\u001b[0m\n",
      "\u001b[34m<<<< freeze the encoder layers!!!\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:39:26,655] [    INFO]#033[0m - global step 10, epoch: 1, loss: 0.00247, speed: 0.64 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:39:39,476] [    INFO]#033[0m - global step 20, epoch: 1, loss: 0.00225, speed: 0.78 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:39:52,319] [    INFO]#033[0m - global step 30, epoch: 1, loss: 0.00203, speed: 0.78 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:40:05,235] [    INFO]#033[0m - global step 40, epoch: 1, loss: 0.00188, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:40:18,177] [    INFO]#033[0m - global step 50, epoch: 1, loss: 0.00185, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:40:31,125] [    INFO]#033[0m - global step 60, epoch: 1, loss: 0.00187, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:40:44,091] [    INFO]#033[0m - global step 70, epoch: 1, loss: 0.00180, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:40:57,070] [    INFO]#033[0m - global step 80, epoch: 1, loss: 0.00176, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:41:10,059] [    INFO]#033[0m - global step 90, epoch: 1, loss: 0.00176, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:41:23,012] [    INFO]#033[0m - global step 100, epoch: 1, loss: 0.00171, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:41:36,003] [    INFO]#033[0m - global step 110, epoch: 1, loss: 0.00166, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:41:49,011] [    INFO]#033[0m - global step 120, epoch: 1, loss: 0.00157, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:42:02,019] [    INFO]#033[0m - global step 130, epoch: 1, loss: 0.00153, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:42:15,007] [    INFO]#033[0m - global step 140, epoch: 1, loss: 0.00151, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:42:28,015] [    INFO]#033[0m - global step 150, epoch: 1, loss: 0.00149, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:42:41,001] [    INFO]#033[0m - global step 160, epoch: 1, loss: 0.00148, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:42:54,011] [    INFO]#033[0m - global step 170, epoch: 1, loss: 0.00147, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:43:07,003] [    INFO]#033[0m - global step 180, epoch: 1, loss: 0.00150, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:43:20,013] [    INFO]#033[0m - global step 190, epoch: 1, loss: 0.00149, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:43:33,040] [    INFO]#033[0m - global step 200, epoch: 1, loss: 0.00145, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:43:46,051] [    INFO]#033[0m - global step 210, epoch: 1, loss: 0.00146, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:43:59,046] [    INFO]#033[0m - global step 220, epoch: 1, loss: 0.00145, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:44:12,026] [    INFO]#033[0m - global step 230, epoch: 1, loss: 0.00145, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:44:25,009] [    INFO]#033[0m - global step 240, epoch: 1, loss: 0.00145, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:44:38,008] [    INFO]#033[0m - global step 250, epoch: 1, loss: 0.00145, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:44:50,991] [    INFO]#033[0m - global step 260, epoch: 1, loss: 0.00143, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:45:03,987] [    INFO]#033[0m - global step 270, epoch: 1, loss: 0.00144, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:45:17,011] [    INFO]#033[0m - global step 280, epoch: 1, loss: 0.00144, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:45:30,027] [    INFO]#033[0m - global step 290, epoch: 1, loss: 0.00144, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:45:43,027] [    INFO]#033[0m - global step 300, epoch: 1, loss: 0.00142, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:45:56,036] [    INFO]#033[0m - global step 310, epoch: 1, loss: 0.00140, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:46:08,892] [    INFO]#033[0m - global step 320, epoch: 1, loss: 0.00140, speed: 0.78 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:46:21,496] [    INFO]#033[0m - global step 330, epoch: 2, loss: 0.00141, speed: 0.79 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:46:34,498] [    INFO]#033[0m - global step 340, epoch: 2, loss: 0.00141, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:46:47,498] [    INFO]#033[0m - global step 350, epoch: 2, loss: 0.00139, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:47:00,492] [    INFO]#033[0m - global step 360, epoch: 2, loss: 0.00138, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:47:13,503] [    INFO]#033[0m - global step 370, epoch: 2, loss: 0.00137, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:47:26,517] [    INFO]#033[0m - global step 380, epoch: 2, loss: 0.00136, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:47:39,558] [    INFO]#033[0m - global step 390, epoch: 2, loss: 0.00135, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:47:52,611] [    INFO]#033[0m - global step 400, epoch: 2, loss: 0.00134, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:48:05,630] [    INFO]#033[0m - global step 410, epoch: 2, loss: 0.00133, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:48:18,616] [    INFO]#033[0m - global step 420, epoch: 2, loss: 0.00132, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:48:31,630] [    INFO]#033[0m - global step 430, epoch: 2, loss: 0.00132, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:48:44,643] [    INFO]#033[0m - global step 440, epoch: 2, loss: 0.00131, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:48:57,667] [    INFO]#033[0m - global step 450, epoch: 2, loss: 0.00131, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:49:10,649] [    INFO]#033[0m - global step 460, epoch: 2, loss: 0.00130, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:49:23,659] [    INFO]#033[0m - global step 470, epoch: 2, loss: 0.00130, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:49:36,669] [    INFO]#033[0m - global step 480, epoch: 2, loss: 0.00129, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:49:49,689] [    INFO]#033[0m - global step 490, epoch: 2, loss: 0.00129, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:50:02,688] [    INFO]#033[0m - global step 500, epoch: 2, loss: 0.00128, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:50:15,689] [    INFO]#033[0m - global step 510, epoch: 2, loss: 0.00128, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:50:28,691] [    INFO]#033[0m - global step 520, epoch: 2, loss: 0.00127, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:50:41,704] [    INFO]#033[0m - global step 530, epoch: 2, loss: 0.00127, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:50:54,709] [    INFO]#033[0m - global step 540, epoch: 2, loss: 0.00126, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:51:07,699] [    INFO]#033[0m - global step 550, epoch: 2, loss: 0.00125, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:51:20,689] [    INFO]#033[0m - global step 560, epoch: 2, loss: 0.00124, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:51:33,673] [    INFO]#033[0m - global step 570, epoch: 2, loss: 0.00125, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:51:46,718] [    INFO]#033[0m - global step 580, epoch: 2, loss: 0.00124, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:51:59,697] [    INFO]#033[0m - global step 590, epoch: 2, loss: 0.00123, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:52:12,708] [    INFO]#033[0m - global step 600, epoch: 2, loss: 0.00123, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:52:25,716] [    INFO]#033[0m - global step 610, epoch: 2, loss: 0.00122, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:52:38,722] [    INFO]#033[0m - global step 620, epoch: 2, loss: 0.00122, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:59:34,224] [    INFO]#033[0m - global step 940, epoch: 3, loss: 0.00107, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 08:59:47,258] [    INFO]#033[0m - global step 950, epoch: 3, loss: 0.00107, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:00:00,266] [    INFO]#033[0m - global step 960, epoch: 3, loss: 0.00106, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:00:12,725] [    INFO]#033[0m - global step 970, epoch: 4, loss: 0.00106, speed: 0.80 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:00:25,727] [    INFO]#033[0m - global step 980, epoch: 4, loss: 0.00106, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:00:38,727] [    INFO]#033[0m - global step 990, epoch: 4, loss: 0.00106, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:00:51,711] [    INFO]#033[0m - global step 1000, epoch: 4, loss: 0.00105, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:01:12,651] [    INFO]#033[0m - Evaluation precision: 0.39091, recall: 0.38393, F1: 0.38739#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:01:12,651] [    INFO]#033[0m - best F1 performence has been updated: 0.00000 --> 0.38739#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:01:13,445] [    INFO]#033[0m - tokenizer config file saved in /opt/ml/model/model_best/tokenizer_config.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:01:13,445] [    INFO]#033[0m - Special tokens file saved in /opt/ml/model/model_best/special_tokens_map.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:01:26,432] [    INFO]#033[0m - global step 1010, epoch: 4, loss: 0.00105, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:01:39,446] [    INFO]#033[0m - global step 1020, epoch: 4, loss: 0.00104, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:01:52,426] [    INFO]#033[0m - global step 1030, epoch: 4, loss: 0.00104, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:02:05,420] [    INFO]#033[0m - global step 1040, epoch: 4, loss: 0.00104, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:02:18,405] [    INFO]#033[0m - global step 1050, epoch: 4, loss: 0.00103, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:02:31,413] [    INFO]#033[0m - global step 1060, epoch: 4, loss: 0.00103, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:02:44,398] [    INFO]#033[0m - global step 1070, epoch: 4, loss: 0.00103, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:02:57,386] [    INFO]#033[0m - global step 1080, epoch: 4, loss: 0.00102, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:03:10,395] [    INFO]#033[0m - global step 1090, epoch: 4, loss: 0.00102, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:03:23,373] [    INFO]#033[0m - global step 1100, epoch: 4, loss: 0.00101, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:03:36,397] [    INFO]#033[0m - global step 1110, epoch: 4, loss: 0.00101, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:03:49,443] [    INFO]#033[0m - global step 1120, epoch: 4, loss: 0.00101, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:04:02,462] [    INFO]#033[0m - global step 1130, epoch: 4, loss: 0.00100, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:04:15,477] [    INFO]#033[0m - global step 1140, epoch: 4, loss: 0.00100, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:04:28,517] [    INFO]#033[0m - global step 1150, epoch: 4, loss: 0.00100, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:04:41,538] [    INFO]#033[0m - global step 1160, epoch: 4, loss: 0.00099, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:04:54,562] [    INFO]#033[0m - global step 1170, epoch: 4, loss: 0.00099, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:05:07,558] [    INFO]#033[0m - global step 1180, epoch: 4, loss: 0.00099, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:05:20,554] [    INFO]#033[0m - global step 1190, epoch: 4, loss: 0.00098, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:05:33,552] [    INFO]#033[0m - global step 1200, epoch: 4, loss: 0.00098, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:05:46,529] [    INFO]#033[0m - global step 1210, epoch: 4, loss: 0.00098, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:05:59,544] [    INFO]#033[0m - global step 1220, epoch: 4, loss: 0.00098, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:06:12,577] [    INFO]#033[0m - global step 1230, epoch: 4, loss: 0.00097, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:06:25,567] [    INFO]#033[0m - global step 1240, epoch: 4, loss: 0.00097, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:06:38,551] [    INFO]#033[0m - global step 1250, epoch: 4, loss: 0.00097, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:06:51,564] [    INFO]#033[0m - global step 1260, epoch: 4, loss: 0.00097, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:07:04,578] [    INFO]#033[0m - global step 1270, epoch: 4, loss: 0.00097, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:07:17,610] [    INFO]#033[0m - global step 1280, epoch: 4, loss: 0.00096, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:07:30,089] [    INFO]#033[0m - global step 1290, epoch: 5, loss: 0.00096, speed: 0.80 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:07:43,093] [    INFO]#033[0m - global step 1300, epoch: 5, loss: 0.00096, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:07:56,080] [    INFO]#033[0m - global step 1310, epoch: 5, loss: 0.00096, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:08:09,074] [    INFO]#033[0m - global step 1320, epoch: 5, loss: 0.00095, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:08:22,083] [    INFO]#033[0m - global step 1330, epoch: 5, loss: 0.00095, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:08:35,086] [    INFO]#033[0m - global step 1340, epoch: 5, loss: 0.00095, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:08:48,080] [    INFO]#033[0m - global step 1350, epoch: 5, loss: 0.00094, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:09:01,082] [    INFO]#033[0m - global step 1360, epoch: 5, loss: 0.00094, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:09:14,072] [    INFO]#033[0m - global step 1370, epoch: 5, loss: 0.00094, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:09:27,095] [    INFO]#033[0m - global step 1380, epoch: 5, loss: 0.00094, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:09:40,112] [    INFO]#033[0m - global step 1390, epoch: 5, loss: 0.00093, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:09:53,139] [    INFO]#033[0m - global step 1400, epoch: 5, loss: 0.00093, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:10:06,158] [    INFO]#033[0m - global step 1410, epoch: 5, loss: 0.00093, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:10:19,133] [    INFO]#033[0m - global step 1420, epoch: 5, loss: 0.00093, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:10:32,156] [    INFO]#033[0m - global step 1430, epoch: 5, loss: 0.00093, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:10:45,157] [    INFO]#033[0m - global step 1440, epoch: 5, loss: 0.00092, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:10:58,174] [    INFO]#033[0m - global step 1450, epoch: 5, loss: 0.00092, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:11:11,179] [    INFO]#033[0m - global step 1460, epoch: 5, loss: 0.00092, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:11:24,208] [    INFO]#033[0m - global step 1470, epoch: 5, loss: 0.00092, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:11:37,203] [    INFO]#033[0m - global step 1480, epoch: 5, loss: 0.00091, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:11:50,213] [    INFO]#033[0m - global step 1490, epoch: 5, loss: 0.00091, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:12:03,197] [    INFO]#033[0m - global step 1500, epoch: 5, loss: 0.00091, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:12:16,188] [    INFO]#033[0m - global step 1510, epoch: 5, loss: 0.00091, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:12:29,185] [    INFO]#033[0m - global step 1520, epoch: 5, loss: 0.00090, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:12:42,177] [    INFO]#033[0m - global step 1530, epoch: 5, loss: 0.00090, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:12:55,182] [    INFO]#033[0m - global step 1540, epoch: 5, loss: 0.00090, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:13:08,164] [    INFO]#033[0m - global step 1550, epoch: 5, loss: 0.00090, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:13:21,171] [    INFO]#033[0m - global step 1560, epoch: 5, loss: 0.00089, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:13:34,182] [    INFO]#033[0m - global step 1570, epoch: 5, loss: 0.00089, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:13:47,184] [    INFO]#033[0m - global step 1580, epoch: 5, loss: 0.00089, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:14:00,172] [    INFO]#033[0m - global step 1590, epoch: 5, loss: 0.00089, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:14:13,169] [    INFO]#033[0m - global step 1600, epoch: 5, loss: 0.00089, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:14:25,462] [    INFO]#033[0m - global step 1610, epoch: 5, loss: 0.00088, speed: 0.81 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:14:38,639] [    INFO]#033[0m - global step 1620, epoch: 6, loss: 0.00088, speed: 0.76 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:14:51,635] [    INFO]#033[0m - global step 1630, epoch: 6, loss: 0.00088, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:15:04,629] [    INFO]#033[0m - global step 1640, epoch: 6, loss: 0.00088, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:15:17,619] [    INFO]#033[0m - global step 1650, epoch: 6, loss: 0.00087, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:15:30,656] [    INFO]#033[0m - global step 1660, epoch: 6, loss: 0.00087, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:15:43,701] [    INFO]#033[0m - global step 1670, epoch: 6, loss: 0.00087, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:15:56,699] [    INFO]#033[0m - global step 1680, epoch: 6, loss: 0.00087, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:16:09,718] [    INFO]#033[0m - global step 1690, epoch: 6, loss: 0.00087, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:16:22,719] [    INFO]#033[0m - global step 1700, epoch: 6, loss: 0.00087, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:16:35,701] [    INFO]#033[0m - global step 1710, epoch: 6, loss: 0.00086, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:16:48,683] [    INFO]#033[0m - global step 1720, epoch: 6, loss: 0.00086, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:17:01,685] [    INFO]#033[0m - global step 1730, epoch: 6, loss: 0.00086, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:17:14,690] [    INFO]#033[0m - global step 1740, epoch: 6, loss: 0.00086, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:17:27,682] [    INFO]#033[0m - global step 1750, epoch: 6, loss: 0.00085, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:17:40,673] [    INFO]#033[0m - global step 1760, epoch: 6, loss: 0.00085, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:17:53,661] [    INFO]#033[0m - global step 1770, epoch: 6, loss: 0.00085, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:18:06,667] [    INFO]#033[0m - global step 1780, epoch: 6, loss: 0.00085, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:18:19,671] [    INFO]#033[0m - global step 1790, epoch: 6, loss: 0.00084, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:18:32,697] [    INFO]#033[0m - global step 1800, epoch: 6, loss: 0.00084, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:18:45,715] [    INFO]#033[0m - global step 1810, epoch: 6, loss: 0.00084, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:18:58,718] [    INFO]#033[0m - global step 1820, epoch: 6, loss: 0.00084, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:19:11,699] [    INFO]#033[0m - global step 1830, epoch: 6, loss: 0.00084, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:19:24,703] [    INFO]#033[0m - global step 1840, epoch: 6, loss: 0.00084, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:19:37,717] [    INFO]#033[0m - global step 1850, epoch: 6, loss: 0.00084, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:19:50,723] [    INFO]#033[0m - global step 1860, epoch: 6, loss: 0.00083, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:20:03,714] [    INFO]#033[0m - global step 1870, epoch: 6, loss: 0.00083, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:20:16,713] [    INFO]#033[0m - global step 1880, epoch: 6, loss: 0.00083, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:20:29,716] [    INFO]#033[0m - global step 1890, epoch: 6, loss: 0.00083, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:20:42,722] [    INFO]#033[0m - global step 1900, epoch: 6, loss: 0.00083, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:20:55,714] [    INFO]#033[0m - global step 1910, epoch: 6, loss: 0.00083, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:21:08,717] [    INFO]#033[0m - global step 1920, epoch: 6, loss: 0.00083, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:21:21,610] [    INFO]#033[0m - global step 1930, epoch: 6, loss: 0.00082, speed: 0.78 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:21:34,244] [    INFO]#033[0m - global step 1940, epoch: 7, loss: 0.00082, speed: 0.79 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:21:47,242] [    INFO]#033[0m - global step 1950, epoch: 7, loss: 0.00082, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:22:00,252] [    INFO]#033[0m - global step 1960, epoch: 7, loss: 0.00082, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:22:13,269] [    INFO]#033[0m - global step 1970, epoch: 7, loss: 0.00082, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:22:26,275] [    INFO]#033[0m - global step 1980, epoch: 7, loss: 0.00082, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:22:39,274] [    INFO]#033[0m - global step 1990, epoch: 7, loss: 0.00081, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:22:52,284] [    INFO]#033[0m - global step 2000, epoch: 7, loss: 0.00081, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:23:13,256] [    INFO]#033[0m - Evaluation precision: 0.41593, recall: 0.41964, F1: 0.41778#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:23:13,256] [    INFO]#033[0m - best F1 performence has been updated: 0.38739 --> 0.41778#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:23:14,485] [    INFO]#033[0m - tokenizer config file saved in /opt/ml/model/model_best/tokenizer_config.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:23:14,485] [    INFO]#033[0m - Special tokens file saved in /opt/ml/model/model_best/special_tokens_map.json#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:23:27,464] [    INFO]#033[0m - global step 2010, epoch: 7, loss: 0.00081, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:23:40,444] [    INFO]#033[0m - global step 2020, epoch: 7, loss: 0.00081, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:23:53,452] [    INFO]#033[0m - global step 2030, epoch: 7, loss: 0.00081, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:24:06,442] [    INFO]#033[0m - global step 2040, epoch: 7, loss: 0.00080, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:24:19,429] [    INFO]#033[0m - global step 2050, epoch: 7, loss: 0.00080, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:24:32,446] [    INFO]#033[0m - global step 2060, epoch: 7, loss: 0.00080, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:24:45,444] [    INFO]#033[0m - global step 2070, epoch: 7, loss: 0.00080, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:24:58,453] [    INFO]#033[0m - global step 2080, epoch: 7, loss: 0.00080, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:25:11,462] [    INFO]#033[0m - global step 2090, epoch: 7, loss: 0.00079, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:25:24,458] [    INFO]#033[0m - global step 2100, epoch: 7, loss: 0.00079, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:25:37,460] [    INFO]#033[0m - global step 2110, epoch: 7, loss: 0.00079, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:25:50,445] [    INFO]#033[0m - global step 2120, epoch: 7, loss: 0.00079, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:26:03,428] [    INFO]#033[0m - global step 2130, epoch: 7, loss: 0.00079, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:26:16,456] [    INFO]#033[0m - global step 2140, epoch: 7, loss: 0.00079, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:26:29,440] [    INFO]#033[0m - global step 2150, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:26:42,455] [    INFO]#033[0m - global step 2160, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:26:55,451] [    INFO]#033[0m - global step 2170, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:27:08,406] [    INFO]#033[0m - global step 2180, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:27:21,361] [    INFO]#033[0m - global step 2190, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:27:34,358] [    INFO]#033[0m - global step 2200, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:27:47,371] [    INFO]#033[0m - global step 2210, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:28:00,388] [    INFO]#033[0m - global step 2220, epoch: 7, loss: 0.00078, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:28:13,405] [    INFO]#033[0m - global step 2230, epoch: 7, loss: 0.00077, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:28:26,425] [    INFO]#033[0m - global step 2240, epoch: 7, loss: 0.00077, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:28:39,378] [    INFO]#033[0m - global step 2250, epoch: 7, loss: 0.00077, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:28:51,948] [    INFO]#033[0m - global step 2260, epoch: 8, loss: 0.00077, speed: 0.80 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:29:04,947] [    INFO]#033[0m - global step 2270, epoch: 8, loss: 0.00077, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:29:17,971] [    INFO]#033[0m - global step 2280, epoch: 8, loss: 0.00077, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:29:30,990] [    INFO]#033[0m - global step 2290, epoch: 8, loss: 0.00076, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:29:44,018] [    INFO]#033[0m - global step 2300, epoch: 8, loss: 0.00076, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:29:57,031] [    INFO]#033[0m - global step 2310, epoch: 8, loss: 0.00076, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:30:10,057] [    INFO]#033[0m - global step 2320, epoch: 8, loss: 0.00076, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:30:23,081] [    INFO]#033[0m - global step 2330, epoch: 8, loss: 0.00076, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:30:36,068] [    INFO]#033[0m - global step 2340, epoch: 8, loss: 0.00075, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:30:49,046] [    INFO]#033[0m - global step 2350, epoch: 8, loss: 0.00075, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:31:02,043] [    INFO]#033[0m - global step 2360, epoch: 8, loss: 0.00075, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:31:15,056] [    INFO]#033[0m - global step 2370, epoch: 8, loss: 0.00075, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:31:28,064] [    INFO]#033[0m - global step 2380, epoch: 8, loss: 0.00075, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:31:41,078] [    INFO]#033[0m - global step 2390, epoch: 8, loss: 0.00075, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:31:54,046] [    INFO]#033[0m - global step 2400, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:32:07,079] [    INFO]#033[0m - global step 2410, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:32:20,116] [    INFO]#033[0m - global step 2420, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:32:33,111] [    INFO]#033[0m - global step 2430, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:32:46,090] [    INFO]#033[0m - global step 2440, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:32:59,088] [    INFO]#033[0m - global step 2450, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:33:12,066] [    INFO]#033[0m - global step 2460, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:33:25,067] [    INFO]#033[0m - global step 2470, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:33:38,067] [    INFO]#033[0m - global step 2480, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:33:51,098] [    INFO]#033[0m - global step 2490, epoch: 8, loss: 0.00074, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:34:04,087] [    INFO]#033[0m - global step 2500, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:34:17,079] [    INFO]#033[0m - global step 2510, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:34:30,066] [    INFO]#033[0m - global step 2520, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:34:43,087] [    INFO]#033[0m - global step 2530, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:34:56,082] [    INFO]#033[0m - global step 2540, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:35:09,064] [    INFO]#033[0m - global step 2550, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:35:22,046] [    INFO]#033[0m - global step 2560, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:35:35,053] [    INFO]#033[0m - global step 2570, epoch: 8, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:35:47,505] [    INFO]#033[0m - global step 2580, epoch: 9, loss: 0.00073, speed: 0.80 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:36:00,488] [    INFO]#033[0m - global step 2590, epoch: 9, loss: 0.00073, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:36:13,490] [    INFO]#033[0m - global step 2600, epoch: 9, loss: 0.00072, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:36:26,522] [    INFO]#033[0m - global step 2610, epoch: 9, loss: 0.00072, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:36:39,526] [    INFO]#033[0m - global step 2620, epoch: 9, loss: 0.00072, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:36:52,524] [    INFO]#033[0m - global step 2630, epoch: 9, loss: 0.00072, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:46:58,371] [    INFO]#033[0m - global step 3080, epoch: 10, loss: 0.00067, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:47:11,379] [    INFO]#033[0m - global step 3090, epoch: 10, loss: 0.00067, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:47:24,383] [    INFO]#033[0m - global step 3100, epoch: 10, loss: 0.00067, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:47:37,396] [    INFO]#033[0m - global step 3110, epoch: 10, loss: 0.00067, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:47:50,390] [    INFO]#033[0m - global step 3120, epoch: 10, loss: 0.00067, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:48:03,385] [    INFO]#033[0m - global step 3130, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:48:16,365] [    INFO]#033[0m - global step 3140, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:48:29,364] [    INFO]#033[0m - global step 3150, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:48:42,365] [    INFO]#033[0m - global step 3160, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:48:55,357] [    INFO]#033[0m - global step 3170, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:49:08,341] [    INFO]#033[0m - global step 3180, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:49:21,359] [    INFO]#033[0m - global step 3190, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:49:34,340] [    INFO]#033[0m - global step 3200, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:49:47,348] [    INFO]#033[0m - global step 3210, epoch: 10, loss: 0.00066, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:49:59,640] [    INFO]#033[0m - global step 3220, epoch: 10, loss: 0.00066, speed: 0.81 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:50:12,810] [    INFO]#033[0m - global step 3230, epoch: 11, loss: 0.00066, speed: 0.76 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:50:25,822] [    INFO]#033[0m - global step 3240, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:50:38,828] [    INFO]#033[0m - global step 3250, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:50:51,812] [    INFO]#033[0m - global step 3260, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:51:04,817] [    INFO]#033[0m - global step 3270, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:51:17,827] [    INFO]#033[0m - global step 3280, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:51:30,842] [    INFO]#033[0m - global step 3290, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:51:43,824] [    INFO]#033[0m - global step 3300, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:51:56,812] [    INFO]#033[0m - global step 3310, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:52:09,786] [    INFO]#033[0m - global step 3320, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:52:22,772] [    INFO]#033[0m - global step 3330, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:52:35,772] [    INFO]#033[0m - global step 3340, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:52:48,786] [    INFO]#033[0m - global step 3350, epoch: 11, loss: 0.00065, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:53:01,785] [    INFO]#033[0m - global step 3360, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:53:14,789] [    INFO]#033[0m - global step 3370, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:53:27,789] [    INFO]#033[0m - global step 3380, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:53:40,810] [    INFO]#033[0m - global step 3390, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:53:53,809] [    INFO]#033[0m - global step 3400, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:54:06,827] [    INFO]#033[0m - global step 3410, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:54:19,826] [    INFO]#033[0m - global step 3420, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:54:32,824] [    INFO]#033[0m - global step 3430, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:54:45,801] [    INFO]#033[0m - global step 3440, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:54:58,824] [    INFO]#033[0m - global step 3450, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:55:11,826] [    INFO]#033[0m - global step 3460, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:55:24,847] [    INFO]#033[0m - global step 3470, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:55:37,849] [    INFO]#033[0m - global step 3480, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:55:50,861] [    INFO]#033[0m - global step 3490, epoch: 11, loss: 0.00064, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:56:03,869] [    INFO]#033[0m - global step 3500, epoch: 11, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:56:16,865] [    INFO]#033[0m - global step 3510, epoch: 11, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:56:29,868] [    INFO]#033[0m - global step 3520, epoch: 11, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:56:42,870] [    INFO]#033[0m - global step 3530, epoch: 11, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:56:55,733] [    INFO]#033[0m - global step 3540, epoch: 11, loss: 0.00063, speed: 0.78 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:57:08,336] [    INFO]#033[0m - global step 3550, epoch: 12, loss: 0.00063, speed: 0.79 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:57:21,336] [    INFO]#033[0m - global step 3560, epoch: 12, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:57:34,316] [    INFO]#033[0m - global step 3570, epoch: 12, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:57:47,306] [    INFO]#033[0m - global step 3580, epoch: 12, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:58:00,315] [    INFO]#033[0m - global step 3590, epoch: 12, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:58:13,305] [    INFO]#033[0m - global step 3600, epoch: 12, loss: 0.00063, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:58:26,277] [    INFO]#033[0m - global step 3610, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:58:39,272] [    INFO]#033[0m - global step 3620, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:58:52,304] [    INFO]#033[0m - global step 3630, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:59:05,295] [    INFO]#033[0m - global step 3640, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:59:18,286] [    INFO]#033[0m - global step 3650, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:59:31,285] [    INFO]#033[0m - global step 3660, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:59:44,269] [    INFO]#033[0m - global step 3670, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 09:59:57,294] [    INFO]#033[0m - global step 3680, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:00:10,278] [    INFO]#033[0m - global step 3690, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:00:23,326] [    INFO]#033[0m - global step 3700, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:00:36,335] [    INFO]#033[0m - global step 3710, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:00:49,340] [    INFO]#033[0m - global step 3720, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:01:02,320] [    INFO]#033[0m - global step 3730, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:01:15,308] [    INFO]#033[0m - global step 3740, epoch: 12, loss: 0.00062, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:01:28,321] [    INFO]#033[0m - global step 3750, epoch: 12, loss: 0.00061, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:01:41,323] [    INFO]#033[0m - global step 3760, epoch: 12, loss: 0.00061, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:01:54,308] [    INFO]#033[0m - global step 3770, epoch: 12, loss: 0.00061, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:02:07,304] [    INFO]#033[0m - global step 3780, epoch: 12, loss: 0.00061, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:02:20,300] [    INFO]#033[0m - global step 3790, epoch: 12, loss: 0.00061, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:02:33,282] [    INFO]#033[0m - global step 3800, epoch: 12, loss: 0.00061, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:02:46,273] [    INFO]#033[0m - global step 3810, epoch: 12, loss: 0.00061, speed: 0.77 step/s#033[0m\u001b[0m\n",
      "\u001b[34m#033[32m[2022-10-11 10:50:12,613] [    INFO]#033[0m - global step 5970, epoch: 19, loss: 0.00051, speed: 0.77 step/s#033[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyperparameters = {'train_path': '/opt/ml/input/data/training/train.txt', \n",
    "                   'dev_path': '/opt/ml/input/data/training/dev.txt', \n",
    "                   'save_dir': '/opt/ml/model', \n",
    "                   'learning_rate': 1e-5, \n",
    "                   'batch_size': 16, \n",
    "                   'max_seq_len':512, \n",
    "                   'num_epochs': 20, \n",
    "                   'model': 'uie-base',\n",
    "                   'seed': 1000,\n",
    "                   'logging_steps': 10,\n",
    "                   'valid_steps': 1000,\n",
    "                   'device': 'gpu',\n",
    "                   'freeze': True}\n",
    "\n",
    "instance_type = 'ml.g4dn.12xlarge'  # 'ml.p3.2xlarge' or 'ml.p3.8xlarge' or ...\n",
    "\n",
    "#git_config = {'repo': 'https://github.com/whn09/paddlenlp_sagemaker.git', 'branch': 'main'}\n",
    "\n",
    "estimator = PyTorch(entry_point='finetune.py',\n",
    "                    source_dir='./',\n",
    "                           # git_config=git_config,\n",
    "                    role=role,\n",
    "                    hyperparameters=hyperparameters,\n",
    "                    framework_version='1.9.1',\n",
    "                    py_version='py38',\n",
    "                    script_mode=True,\n",
    "                    instance_count=1,  # 1 or 2 or ...\n",
    "                    instance_type=instance_type,\n",
    "                    # Parameters required to enable checkpointing\n",
    "                    checkpoint_s3_uri=uie_en_model_s3, #使用你自己用来保存/加载模型的s3桶地址, 注意桶需要在us-east-1\n",
    "                    checkpoint_local_path=\"/opt/ml/checkpoints\")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-064542430558/pytorch-training-2022-10-11-07-37-29-125/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "training_job_name = estimator.model_data\n",
    "# training_job_name = 'xxx'\n",
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1000/\n",
      "model_6000/\n",
      "model_2000/\n",
      "model_5000/\n",
      "model_best/\n",
      "model_best/model_state.pdparams\n",
      "model_best/vocab.txt\n",
      "model_best/tokenizer_config.json\n",
      "model_best/special_tokens_map.json\n",
      "model_best/model_config.json\n",
      "inference.pdiparams.info\n",
      "model_3000/\n",
      "inference.pdiparams\n",
      "inference.pdmodel\n",
      "model_4000/\n"
     ]
    }
   ],
   "source": [
    "#!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz ../\n",
    "!tar -zxvf ../model.tar.gz -C ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-09-23 03:00:09,151] [    INFO]\u001b[0m - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load '../model_best'.\u001b[0m\n",
      "W0923 03:00:09.174229 30833 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.6, Runtime API Version: 11.1\n",
      "W0923 03:00:09.176781 30833 gpu_resources.cc:91] device: 0, cuDNN Version: 8.0.\n",
      "<<<< class dict: dict_keys(['royal', 'family', 'personality', 'person', 'occupation', 'pregnant', 'status', 'parts of body', 'origanization', 'supernature', 'color', 'hobby', 'body type', 'age', 'event', 'race', 'location', 'size', 'Sexual description', 'sexual description', 'gender', 'facility', 'office-work', 'cheating', 'high-tech', 'height', 'love stage', 'shape', 'campus', 'abuse'])\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "W0923 03:00:11.774816 30833 gpu_resources.cc:201] WARNING: device: \u0000. The installed Paddle is compiled with CUDNN 8.1, but CUDNN version in your machine is 8.0, which may cause serious incompatible bug. Please recompile or reinstall Paddle with compatible CUDNN version.\n",
      "predict_start_ids[52, 62] predict_end_ids[52, 62]\n",
      "pred_set {(52, 52), (62, 62)}\n",
      "predict_start_ids[43] predict_end_ids[45]\n",
      "pred_set {(43, 45)}\n",
      "predict_start_ids[33] predict_end_ids[33]\n",
      "pred_set {(33, 33)}\n",
      "predict_start_ids[62] predict_end_ids[64]\n",
      "pred_set {(62, 64)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[9] predict_end_ids[14]\n",
      "pred_set {(9, 14)}\n",
      "predict_start_ids[91] predict_end_ids[91]\n",
      "pred_set {(91, 91)}\n",
      "predict_start_ids[4] predict_end_ids[5]\n",
      "pred_set {(4, 5)}\n",
      "predict_start_ids[10] predict_end_ids[11]\n",
      "pred_set {(10, 11)}\n",
      "num_correct: 3, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[14] predict_end_ids[15]\n",
      "pred_set {(14, 15)}\n",
      "predict_start_ids[63, 83, 86, 97, 100] predict_end_ids[63, 83, 88, 97, 102]\n",
      "pred_set {(86, 88), (63, 63), (97, 97), (83, 83), (100, 102)}\n",
      "predict_start_ids[34] predict_end_ids[41]\n",
      "pred_set {(34, 41)}\n",
      "predict_start_ids[] predict_end_ids[41]\n",
      "pred_set set()\n",
      "num_correct: 5, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[42] predict_end_ids[42]\n",
      "pred_set {(42, 42)}\n",
      "predict_start_ids[17] predict_end_ids[18]\n",
      "pred_set {(17, 18)}\n",
      "predict_start_ids[25] predict_end_ids[26]\n",
      "pred_set {(25, 26)}\n",
      "predict_start_ids[] predict_end_ids[28]\n",
      "pred_set set()\n",
      "num_correct: 2, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[5, 10]\n",
      "pred_set {(3, 5)}\n",
      "predict_start_ids[18] predict_end_ids[19]\n",
      "pred_set {(18, 19)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[40, 53] predict_end_ids[40, 53]\n",
      "pred_set {(40, 40), (53, 53)}\n",
      "num_correct: 2, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[5] predict_end_ids[11, 16]\n",
      "pred_set {(5, 11)}\n",
      "predict_start_ids[47] predict_end_ids[49]\n",
      "pred_set {(47, 49)}\n",
      "predict_start_ids[42] predict_end_ids[44, 65]\n",
      "pred_set {(42, 44)}\n",
      "predict_start_ids[6, 9] predict_end_ids[7, 9, 35]\n",
      "pred_set {(6, 7), (9, 9)}\n",
      "num_correct: 4, num_infer: 5, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[19] predict_end_ids[19]\n",
      "pred_set {(19, 19)}\n",
      "predict_start_ids[8] predict_end_ids[10]\n",
      "pred_set {(8, 10)}\n",
      "predict_start_ids[] predict_end_ids[33]\n",
      "pred_set set()\n",
      "predict_start_ids[13, 23] predict_end_ids[13, 23]\n",
      "pred_set {(23, 23), (13, 13)}\n",
      "num_correct: 1, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[61] predict_end_ids[61]\n",
      "pred_set {(61, 61)}\n",
      "predict_start_ids[27] predict_end_ids[18, 24, 29]\n",
      "pred_set {(27, 29)}\n",
      "predict_start_ids[16] predict_end_ids[17]\n",
      "pred_set {(16, 17)}\n",
      "predict_start_ids[] predict_end_ids[14]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 3, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[32, 35] predict_end_ids[32, 35]\n",
      "pred_set {(32, 32), (35, 35)}\n",
      "predict_start_ids[23] predict_end_ids[24]\n",
      "pred_set {(23, 24)}\n",
      "predict_start_ids[22] predict_end_ids[23]\n",
      "pred_set {(22, 23)}\n",
      "predict_start_ids[6] predict_end_ids[6]\n",
      "pred_set {(6, 6)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[31, 41] predict_end_ids[32, 42]\n",
      "pred_set {(41, 42), (31, 32)}\n",
      "predict_start_ids[39] predict_end_ids[27, 44]\n",
      "pred_set {(39, 44)}\n",
      "predict_start_ids[4] predict_end_ids[5]\n",
      "pred_set {(4, 5)}\n",
      "predict_start_ids[13] predict_end_ids[13]\n",
      "pred_set {(13, 13)}\n",
      "num_correct: 4, num_infer: 5, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[15] predict_end_ids[16]\n",
      "pred_set {(15, 16)}\n",
      "predict_start_ids[28] predict_end_ids[29]\n",
      "pred_set {(28, 29)}\n",
      "predict_start_ids[] predict_end_ids[4]\n",
      "pred_set set()\n",
      "predict_start_ids[18] predict_end_ids[19]\n",
      "pred_set {(18, 19)}\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[56] predict_end_ids[56]\n",
      "pred_set {(56, 56)}\n",
      "predict_start_ids[] predict_end_ids[61]\n",
      "pred_set set()\n",
      "num_correct: 1, num_infer: 1, num_label 2\n",
      "\u001b[32m[2022-09-23 03:00:12,904] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:12,904] [    INFO]\u001b[0m - Class Name: royal\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:12,905] [    INFO]\u001b[0m - Class length: 46\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:12,905] [    INFO]\u001b[0m - Evaluation Precision: 0.73469 | Recall: 0.60000 | F1: 0.66055\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[85] predict_end_ids[85]\n",
      "pred_set {(85, 85)}\n",
      "predict_start_ids[] predict_end_ids[13]\n",
      "pred_set set()\n",
      "predict_start_ids[31, 98] predict_end_ids[32, 99]\n",
      "pred_set {(98, 99), (31, 32)}\n",
      "num_correct: 3, num_infer: 3, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[36]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[56] predict_end_ids[56]\n",
      "pred_set {(56, 56)}\n",
      "num_correct: 1, num_infer: 1, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[10]\n",
      "pred_set set()\n",
      "predict_start_ids[60, 62] predict_end_ids[60, 62]\n",
      "pred_set {(60, 60), (62, 62)}\n",
      "predict_start_ids[] predict_end_ids[9]\n",
      "pred_set set()\n",
      "predict_start_ids[8] predict_end_ids[8]\n",
      "pred_set {(8, 8)}\n",
      "num_correct: 3, num_infer: 3, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[12]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[14]\n",
      "pred_set set()\n",
      "predict_start_ids[22] predict_end_ids[22]\n",
      "pred_set {(22, 22)}\n",
      "num_correct: 1, num_infer: 1, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:13,182] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:13,183] [    INFO]\u001b[0m - Class Name: family\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:13,183] [    INFO]\u001b[0m - Class length: 15\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:13,183] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 0.42105 | F1: 0.59259\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[6] predict_end_ids[10]\n",
      "pred_set {(6, 10)}\n",
      "predict_start_ids[] predict_end_ids[47]\n",
      "pred_set set()\n",
      "predict_start_ids[8] predict_end_ids[8]\n",
      "pred_set {(8, 8)}\n",
      "predict_start_ids[55] predict_end_ids[55]\n",
      "pred_set {(55, 55)}\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[21] predict_end_ids[22]\n",
      "pred_set {(21, 22)}\n",
      "predict_start_ids[12, 19, 22] predict_end_ids[12, 20, 22, 29]\n",
      "pred_set {(19, 20), (12, 12), (22, 22)}\n",
      "predict_start_ids[70, 72] predict_end_ids[70, 72]\n",
      "pred_set {(72, 72), (70, 70)}\n",
      "predict_start_ids[11, 28, 30] predict_end_ids[11, 28, 30]\n",
      "pred_set {(28, 28), (30, 30), (11, 11)}\n",
      "num_correct: 7, num_infer: 9, num_label 9\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[5]\n",
      "pred_set {(3, 5)}\n",
      "predict_start_ids[91] predict_end_ids[91]\n",
      "pred_set {(91, 91)}\n",
      "predict_start_ids[] predict_end_ids[48]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 2, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[19] predict_end_ids[8, 19]\n",
      "pred_set {(19, 19)}\n",
      "predict_start_ids[29, 31, 110] predict_end_ids[31, 110]\n",
      "pred_set {(31, 31), (110, 110)}\n",
      "predict_start_ids[] predict_end_ids[13]\n",
      "pred_set set()\n",
      "predict_start_ids[27] predict_end_ids[28]\n",
      "pred_set {(27, 28)}\n",
      "num_correct: 4, num_infer: 4, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[17] predict_end_ids[17]\n",
      "pred_set {(17, 17)}\n",
      "predict_start_ids[109] predict_end_ids[109]\n",
      "pred_set {(109, 109)}\n",
      "predict_start_ids[24, 25] predict_end_ids[25]\n",
      "pred_set {(25, 25)}\n",
      "predict_start_ids[32] predict_end_ids[36]\n",
      "pred_set {(32, 36)}\n",
      "num_correct: 4, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[34, 36] predict_end_ids[34, 36]\n",
      "pred_set {(34, 34), (36, 36)}\n",
      "predict_start_ids[24, 26, 39, 41] predict_end_ids[24, 26, 39, 41]\n",
      "pred_set {(39, 39), (26, 26), (41, 41), (24, 24)}\n",
      "predict_start_ids[34, 36, 38, 40, 42, 44] predict_end_ids[34, 36, 38, 40, 42, 45]\n",
      "pred_set {(44, 45), (36, 36), (38, 38), (34, 34), (40, 40), (42, 42)}\n",
      "predict_start_ids[72] predict_end_ids[74]\n",
      "pred_set {(72, 74)}\n",
      "num_correct: 10, num_infer: 13, num_label 13\n",
      "<<< batch 6\n",
      "predict_start_ids[30] predict_end_ids[32]\n",
      "pred_set {(30, 32)}\n",
      "predict_start_ids[6] predict_end_ids[6]\n",
      "pred_set {(6, 6)}\n",
      "predict_start_ids[53] predict_end_ids[53]\n",
      "pred_set {(53, 53)}\n",
      "predict_start_ids[37, 73, 108] predict_end_ids[38, 73, 108]\n",
      "pred_set {(37, 38), (73, 73), (108, 108)}\n",
      "num_correct: 5, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[34, 41] predict_end_ids[36, 41]\n",
      "pred_set {(41, 41), (34, 36)}\n",
      "predict_start_ids[8] predict_end_ids[8]\n",
      "pred_set {(8, 8)}\n",
      "predict_start_ids[4] predict_end_ids[6]\n",
      "pred_set {(4, 6)}\n",
      "predict_start_ids[52] predict_end_ids[52]\n",
      "pred_set {(52, 52)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[43] predict_end_ids[45]\n",
      "pred_set {(43, 45)}\n",
      "predict_start_ids[20, 22] predict_end_ids[20, 22]\n",
      "pred_set {(20, 20), (22, 22)}\n",
      "predict_start_ids[63] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "\u001b[32m[2022-09-23 03:00:13,854] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:13,854] [    INFO]\u001b[0m - Class Name: personality\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:13,855] [    INFO]\u001b[0m - Class length: 35\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:13,855] [    INFO]\u001b[0m - Evaluation Precision: 0.81633 | Recall: 0.71429 | F1: 0.76190\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[3, 6, 11] predict_end_ids[4, 6, 12]\n",
      "pred_set {(6, 6), (3, 4), (11, 12)}\n",
      "predict_start_ids[28] predict_end_ids[29, 36, 50]\n",
      "pred_set {(28, 29)}\n",
      "predict_start_ids[13] predict_end_ids[17]\n",
      "pred_set {(13, 17)}\n",
      "predict_start_ids[42] predict_end_ids[42]\n",
      "pred_set {(42, 42)}\n",
      "num_correct: 4, num_infer: 6, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "predict_start_ids[6, 8, 16, 30] predict_end_ids[6, 9, 17, 30]\n",
      "pred_set {(6, 6), (30, 30), (8, 9), (16, 17)}\n",
      "predict_start_ids[64] predict_end_ids[64]\n",
      "pred_set {(64, 64)}\n",
      "predict_start_ids[3, 33] predict_end_ids[4, 34, 36]\n",
      "pred_set {(33, 34), (3, 4)}\n",
      "num_correct: 5, num_infer: 8, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[4, 34] predict_end_ids[5, 35]\n",
      "pred_set {(4, 5), (34, 35)}\n",
      "predict_start_ids[26] predict_end_ids[26]\n",
      "pred_set {(26, 26)}\n",
      "predict_start_ids[10] predict_end_ids[10]\n",
      "pred_set {(10, 10)}\n",
      "predict_start_ids[13] predict_end_ids[15]\n",
      "pred_set {(13, 15)}\n",
      "num_correct: 4, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[10] predict_end_ids[11]\n",
      "pred_set {(10, 11)}\n",
      "predict_start_ids[7, 15] predict_end_ids[7, 15]\n",
      "pred_set {(7, 7), (15, 15)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[13] predict_end_ids[13]\n",
      "pred_set {(13, 13)}\n",
      "num_correct: 5, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[17] predict_end_ids[17]\n",
      "pred_set {(17, 17)}\n",
      "predict_start_ids[25, 40] predict_end_ids[25, 40]\n",
      "pred_set {(25, 25), (40, 40)}\n",
      "predict_start_ids[7] predict_end_ids[7]\n",
      "pred_set {(7, 7)}\n",
      "predict_start_ids[3, 16, 46] predict_end_ids[3, 16, 46]\n",
      "pred_set {(3, 3), (16, 16), (46, 46)}\n",
      "num_correct: 5, num_infer: 7, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[12] predict_end_ids[12, 21, 30]\n",
      "pred_set {(12, 12)}\n",
      "predict_start_ids[20, 33, 37] predict_end_ids[21, 35, 38]\n",
      "pred_set {(37, 38), (33, 35), (20, 21)}\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[3, 13] predict_end_ids[4, 13]\n",
      "pred_set {(3, 4), (13, 13)}\n",
      "num_correct: 6, num_infer: 7, num_label 9\n",
      "<<< batch 6\n",
      "predict_start_ids[63] predict_end_ids[64]\n",
      "pred_set {(63, 64)}\n",
      "predict_start_ids[22] predict_end_ids[23]\n",
      "pred_set {(22, 23)}\n",
      "predict_start_ids[51, 102] predict_end_ids[52, 102]\n",
      "pred_set {(102, 102), (51, 52)}\n",
      "predict_start_ids[19, 25] predict_end_ids[22, 29]\n",
      "pred_set {(25, 29), (19, 22)}\n",
      "num_correct: 5, num_infer: 6, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3, 25] predict_end_ids[4, 26]\n",
      "pred_set {(3, 4), (25, 26)}\n",
      "num_correct: 2, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[47] predict_end_ids[47]\n",
      "pred_set {(47, 47)}\n",
      "predict_start_ids[] predict_end_ids[11]\n",
      "pred_set set()\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[42, 60] predict_end_ids[3, 43, 60]\n",
      "pred_set {(42, 43), (60, 60)}\n",
      "num_correct: 2, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[41] predict_end_ids[45]\n",
      "pred_set {(41, 45)}\n",
      "predict_start_ids[4] predict_end_ids[5]\n",
      "pred_set {(4, 5)}\n",
      "predict_start_ids[3, 14] predict_end_ids[3, 15]\n",
      "pred_set {(3, 3), (14, 15)}\n",
      "predict_start_ids[34, 101] predict_end_ids[35, 105]\n",
      "pred_set {(34, 35), (101, 105)}\n",
      "num_correct: 6, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[29, 38, 54] predict_end_ids[29, 39, 55]\n",
      "pred_set {(54, 55), (29, 29), (38, 39)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[52, 100, 108] predict_end_ids[9, 52, 101, 108]\n",
      "pred_set {(52, 52), (100, 101), (108, 108)}\n",
      "predict_start_ids[6, 21, 37] predict_end_ids[8, 22, 37]\n",
      "pred_set {(37, 37), (6, 8), (21, 22)}\n",
      "num_correct: 8, num_infer: 10, num_label 9\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4, 16]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[6] predict_end_ids[6]\n",
      "pred_set {(6, 6)}\n",
      "predict_start_ids[22] predict_end_ids[23]\n",
      "pred_set {(22, 23)}\n",
      "num_correct: 1, num_infer: 3, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[4, 47, 57] predict_end_ids[5, 49, 58]\n",
      "pred_set {(57, 58), (4, 5), (47, 49)}\n",
      "predict_start_ids[3, 6, 38, 50] predict_end_ids[3, 6, 38, 50, 104]\n",
      "pred_set {(6, 6), (50, 50), (3, 3), (38, 38)}\n",
      "predict_start_ids[29, 46, 49, 55, 71] predict_end_ids[46, 49, 55, 66, 71]\n",
      "pred_set {(55, 55), (71, 71), (49, 49), (46, 46)}\n",
      "predict_start_ids[24] predict_end_ids[24]\n",
      "pred_set {(24, 24)}\n",
      "num_correct: 10, num_infer: 12, num_label 11\n",
      "<<< batch 6\n",
      "predict_start_ids[30] predict_end_ids[31]\n",
      "pred_set {(30, 31)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[8] predict_end_ids[11]\n",
      "pred_set {(8, 11)}\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[9, 16] predict_end_ids[9, 18, 32]\n",
      "pred_set {(16, 18), (9, 9)}\n",
      "predict_start_ids[13, 33, 47] predict_end_ids[13, 34, 47]\n",
      "pred_set {(33, 34), (47, 47), (13, 13)}\n",
      "predict_start_ids[37] predict_end_ids[38]\n",
      "pred_set {(37, 38)}\n",
      "predict_start_ids[12, 14] predict_end_ids[12, 18]\n",
      "pred_set {(14, 18), (12, 12)}\n",
      "num_correct: 6, num_infer: 8, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[8] predict_end_ids[9]\n",
      "pred_set {(8, 9)}\n",
      "predict_start_ids[22] predict_end_ids[22]\n",
      "pred_set {(22, 22)}\n",
      "predict_start_ids[6] predict_end_ids[7]\n",
      "pred_set {(6, 7)}\n",
      "predict_start_ids[85] predict_end_ids[86]\n",
      "pred_set {(85, 86)}\n",
      "num_correct: 3, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[51, 85] predict_end_ids[51, 85]\n",
      "pred_set {(85, 85), (51, 51)}\n",
      "predict_start_ids[21] predict_end_ids[22]\n",
      "pred_set {(21, 22)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[3, 17, 31, 61]\n",
      "pred_set {(3, 3)}\n",
      "num_correct: 2, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[7, 16, 22] predict_end_ids[7, 16, 22]\n",
      "pred_set {(16, 16), (7, 7), (22, 22)}\n",
      "predict_start_ids[9] predict_end_ids[14, 22]\n",
      "pred_set {(9, 14)}\n",
      "predict_start_ids[30, 77] predict_end_ids[31, 79]\n",
      "pred_set {(77, 79), (30, 31)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "num_correct: 5, num_infer: 7, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[3, 7] predict_end_ids[4, 7]\n",
      "pred_set {(3, 4), (7, 7)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[11] predict_end_ids[11]\n",
      "pred_set {(11, 11)}\n",
      "predict_start_ids[3, 19] predict_end_ids[4, 19]\n",
      "pred_set {(19, 19), (3, 4)}\n",
      "num_correct: 4, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[25] predict_end_ids[26]\n",
      "pred_set {(25, 26)}\n",
      "predict_start_ids[3, 12, 38] predict_end_ids[3, 12, 38]\n",
      "pred_set {(12, 12), (3, 3), (38, 38)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "num_correct: 5, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[4] predict_end_ids[5]\n",
      "pred_set {(4, 5)}\n",
      "predict_start_ids[6] predict_end_ids[6]\n",
      "pred_set {(6, 6)}\n",
      "num_correct: 4, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[8, 14, 31] predict_end_ids[11, 15, 31]\n",
      "pred_set {(14, 15), (31, 31), (8, 11)}\n",
      "predict_start_ids[39] predict_end_ids[40]\n",
      "pred_set {(39, 40)}\n",
      "predict_start_ids[30, 35] predict_end_ids[33, 38]\n",
      "pred_set {(35, 38), (30, 33)}\n",
      "num_correct: 5, num_infer: 7, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[17] predict_end_ids[17]\n",
      "pred_set {(17, 17)}\n",
      "predict_start_ids[14] predict_end_ids[15]\n",
      "pred_set {(14, 15)}\n",
      "predict_start_ids[27] predict_end_ids[29]\n",
      "pred_set {(27, 29)}\n",
      "predict_start_ids[18] predict_end_ids[19]\n",
      "pred_set {(18, 19)}\n",
      "num_correct: 3, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[4] predict_end_ids[6]\n",
      "pred_set {(4, 6)}\n",
      "predict_start_ids[3, 12] predict_end_ids[3, 14]\n",
      "pred_set {(3, 3), (12, 14)}\n",
      "predict_start_ids[8, 36] predict_end_ids[9, 37]\n",
      "pred_set {(8, 9), (36, 37)}\n",
      "predict_start_ids[11] predict_end_ids[13]\n",
      "pred_set {(11, 13)}\n",
      "num_correct: 6, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[74] predict_end_ids[79]\n",
      "pred_set {(74, 79)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 3, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[17] predict_end_ids[18]\n",
      "pred_set {(17, 18)}\n",
      "predict_start_ids[3, 77, 90] predict_end_ids[3, 77, 90]\n",
      "pred_set {(3, 3), (77, 77), (90, 90)}\n",
      "predict_start_ids[32] predict_end_ids[32]\n",
      "pred_set {(32, 32)}\n",
      "predict_start_ids[37] predict_end_ids[37]\n",
      "pred_set {(37, 37)}\n",
      "num_correct: 5, num_infer: 6, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[7] predict_end_ids[8]\n",
      "pred_set {(7, 8)}\n",
      "predict_start_ids[15, 106] predict_end_ids[15, 107]\n",
      "pred_set {(106, 107), (15, 15)}\n",
      "predict_start_ids[14] predict_end_ids[14, 18, 20]\n",
      "pred_set {(14, 14)}\n",
      "predict_start_ids[41] predict_end_ids[41]\n",
      "pred_set {(41, 41)}\n",
      "num_correct: 3, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[12] predict_end_ids[12]\n",
      "pred_set {(12, 12)}\n",
      "predict_start_ids[53] predict_end_ids[53]\n",
      "pred_set {(53, 53)}\n",
      "num_correct: 4, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[10] predict_end_ids[5, 10]\n",
      "pred_set {(10, 10)}\n",
      "predict_start_ids[5] predict_end_ids[7]\n",
      "pred_set {(5, 7)}\n",
      "predict_start_ids[18] predict_end_ids[18]\n",
      "pred_set {(18, 18)}\n",
      "predict_start_ids[7, 15] predict_end_ids[7, 15]\n",
      "pred_set {(7, 7), (15, 15)}\n",
      "num_correct: 5, num_infer: 5, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[23, 46] predict_end_ids[23, 47]\n",
      "pred_set {(46, 47), (23, 23)}\n",
      "predict_start_ids[3] predict_end_ids[6]\n",
      "pred_set {(3, 6)}\n",
      "predict_start_ids[78] predict_end_ids[79]\n",
      "pred_set {(78, 79)}\n",
      "predict_start_ids[3, 6] predict_end_ids[4, 7]\n",
      "pred_set {(6, 7), (3, 4)}\n",
      "num_correct: 5, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[17, 20] predict_end_ids[18, 21]\n",
      "pred_set {(17, 18), (20, 21)}\n",
      "predict_start_ids[43, 45, 49] predict_end_ids[43, 47, 51]\n",
      "pred_set {(43, 43), (45, 47), (49, 51)}\n",
      "predict_start_ids[26, 34] predict_end_ids[26, 34]\n",
      "pred_set {(34, 34), (26, 26)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "num_correct: 5, num_infer: 8, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[44] predict_end_ids[45]\n",
      "pred_set {(44, 45)}\n",
      "predict_start_ids[23] predict_end_ids[23]\n",
      "pred_set {(23, 23)}\n",
      "predict_start_ids[3, 22] predict_end_ids[3, 23]\n",
      "pred_set {(3, 3), (22, 23)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[12] predict_end_ids[13]\n",
      "pred_set {(12, 13)}\n",
      "predict_start_ids[4, 17] predict_end_ids[5, 17]\n",
      "pred_set {(17, 17), (4, 5)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[3, 14]\n",
      "pred_set {(3, 3)}\n",
      "num_correct: 5, num_infer: 5, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[32] predict_end_ids[33, 62]\n",
      "pred_set {(32, 33)}\n",
      "predict_start_ids[14, 19, 29] predict_end_ids[14, 19, 29]\n",
      "pred_set {(19, 19), (14, 14), (29, 29)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[9, 24] predict_end_ids[9, 25]\n",
      "pred_set {(24, 25), (9, 9)}\n",
      "num_correct: 4, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[99] predict_end_ids[99]\n",
      "pred_set {(99, 99)}\n",
      "predict_start_ids[5] predict_end_ids[7]\n",
      "pred_set {(5, 7)}\n",
      "predict_start_ids[4, 18] predict_end_ids[7, 21]\n",
      "pred_set {(18, 21), (4, 7)}\n",
      "num_correct: 3, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3, 6, 54, 60] predict_end_ids[4, 6, 54, 60]\n",
      "pred_set {(6, 6), (54, 54), (60, 60), (3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[6, 9, 22, 24] predict_end_ids[7, 9, 22, 24]\n",
      "pred_set {(6, 7), (24, 24), (22, 22), (9, 9)}\n",
      "num_correct: 9, num_infer: 10, num_label 10\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[18] predict_end_ids[18]\n",
      "pred_set {(18, 18)}\n",
      "predict_start_ids[] predict_end_ids[6, 13]\n",
      "pred_set set()\n",
      "num_correct: 2, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[11] predict_end_ids[12]\n",
      "pred_set {(11, 12)}\n",
      "predict_start_ids[16] predict_end_ids[16]\n",
      "pred_set {(16, 16)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[5] predict_end_ids[8]\n",
      "pred_set {(5, 8)}\n",
      "num_correct: 3, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[30] predict_end_ids[31]\n",
      "pred_set {(30, 31)}\n",
      "predict_start_ids[26] predict_end_ids[27]\n",
      "pred_set {(26, 27)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "num_correct: 3, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[24, 60] predict_end_ids[25, 61]\n",
      "pred_set {(24, 25), (60, 61)}\n",
      "predict_start_ids[8] predict_end_ids[9]\n",
      "pred_set {(8, 9)}\n",
      "predict_start_ids[82, 90, 102] predict_end_ids[83, 90, 102]\n",
      "pred_set {(102, 102), (82, 83), (90, 90)}\n",
      "predict_start_ids[6, 32, 45, 84] predict_end_ids[8, 34, 46, 85]\n",
      "pred_set {(45, 46), (6, 8), (32, 34), (84, 85)}\n",
      "num_correct: 8, num_infer: 10, num_label 10\n",
      "<<< batch 6\n",
      "predict_start_ids[11] predict_end_ids[12]\n",
      "pred_set {(11, 12)}\n",
      "predict_start_ids[14] predict_end_ids[15]\n",
      "pred_set {(14, 15)}\n",
      "predict_start_ids[90] predict_end_ids[90]\n",
      "pred_set {(90, 90)}\n",
      "predict_start_ids[] predict_end_ids[10, 58]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 3, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[9] predict_end_ids[9, 27]\n",
      "pred_set {(9, 9)}\n",
      "predict_start_ids[13] predict_end_ids[17, 23]\n",
      "pred_set {(13, 17)}\n",
      "num_correct: 2, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[8] predict_end_ids[9]\n",
      "pred_set {(8, 9)}\n",
      "predict_start_ids[5] predict_end_ids[5]\n",
      "pred_set {(5, 5)}\n",
      "predict_start_ids[19, 34, 50, 52, 55, 61] predict_end_ids[19, 36, 50, 52, 55, 61]\n",
      "pred_set {(34, 36), (52, 52), (61, 61), (19, 19), (55, 55), (50, 50)}\n",
      "predict_start_ids[20] predict_end_ids[20]\n",
      "pred_set {(20, 20)}\n",
      "num_correct: 8, num_infer: 9, num_label 9\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[33, 58, 63] predict_end_ids[33, 58, 63]\n",
      "pred_set {(63, 63), (58, 58), (33, 33)}\n",
      "predict_start_ids[4] predict_end_ids[6]\n",
      "pred_set {(4, 6)}\n",
      "predict_start_ids[] predict_end_ids[68]\n",
      "pred_set set()\n",
      "num_correct: 4, num_infer: 5, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[3, 32] predict_end_ids[4, 33]\n",
      "pred_set {(32, 33), (3, 4)}\n",
      "predict_start_ids[4] predict_end_ids[5]\n",
      "pred_set {(4, 5)}\n",
      "predict_start_ids[6] predict_end_ids[6]\n",
      "pred_set {(6, 6)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "num_correct: 4, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[52] predict_end_ids[52]\n",
      "pred_set {(52, 52)}\n",
      "predict_start_ids[6] predict_end_ids[8]\n",
      "pred_set {(6, 8)}\n",
      "predict_start_ids[6] predict_end_ids[10]\n",
      "pred_set {(6, 10)}\n",
      "predict_start_ids[3, 12] predict_end_ids[3, 12]\n",
      "pred_set {(12, 12), (3, 3)}\n",
      "num_correct: 4, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[9] predict_end_ids[12]\n",
      "pred_set {(9, 12)}\n",
      "predict_start_ids[15] predict_end_ids[15]\n",
      "pred_set {(15, 15)}\n",
      "predict_start_ids[10] predict_end_ids[11]\n",
      "pred_set {(10, 11)}\n",
      "predict_start_ids[4, 34] predict_end_ids[5, 34]\n",
      "pred_set {(4, 5), (34, 34)}\n",
      "num_correct: 2, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[10] predict_end_ids[10]\n",
      "pred_set {(10, 10)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[31, 41, 52] predict_end_ids[29, 32, 37, 42, 47, 52]\n",
      "pred_set {(52, 52), (41, 42), (31, 32)}\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "num_correct: 5, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[34, 64] predict_end_ids[34, 64]\n",
      "pred_set {(34, 34), (64, 64)}\n",
      "predict_start_ids[3, 9] predict_end_ids[4, 9]\n",
      "pred_set {(3, 4), (9, 9)}\n",
      "predict_start_ids[28] predict_end_ids[29]\n",
      "pred_set {(28, 29)}\n",
      "predict_start_ids[4, 18] predict_end_ids[4, 19]\n",
      "pred_set {(4, 4), (18, 19)}\n",
      "num_correct: 6, num_infer: 7, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[15] predict_end_ids[15]\n",
      "pred_set {(15, 15)}\n",
      "predict_start_ids[23] predict_end_ids[23]\n",
      "pred_set {(23, 23)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[21] predict_end_ids[22]\n",
      "pred_set {(21, 22)}\n",
      "num_correct: 3, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[27, 31] predict_end_ids[27, 32]\n",
      "pred_set {(27, 27), (31, 32)}\n",
      "predict_start_ids[8, 10] predict_end_ids[8, 11]\n",
      "pred_set {(8, 8), (10, 11)}\n",
      "predict_start_ids[21, 39] predict_end_ids[21, 40]\n",
      "pred_set {(39, 40), (21, 21)}\n",
      "num_correct: 7, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[26] predict_end_ids[26]\n",
      "pred_set {(26, 26)}\n",
      "predict_start_ids[6] predict_end_ids[7]\n",
      "pred_set {(6, 7)}\n",
      "predict_start_ids[28, 35, 58] predict_end_ids[32, 39, 58]\n",
      "pred_set {(58, 58), (35, 39), (28, 32)}\n",
      "predict_start_ids[] predict_end_ids[17]\n",
      "pred_set set()\n",
      "num_correct: 5, num_infer: 5, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[26, 89]\n",
      "pred_set set()\n",
      "predict_start_ids[63, 100, 109] predict_end_ids[63, 101, 109]\n",
      "pred_set {(63, 63), (100, 101), (109, 109)}\n",
      "predict_start_ids[4, 8] predict_end_ids[5, 9]\n",
      "pred_set {(4, 5), (8, 9)}\n",
      "predict_start_ids[3, 7] predict_end_ids[4, 8]\n",
      "pred_set {(3, 4), (7, 8)}\n",
      "num_correct: 6, num_infer: 7, num_label 10\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[12] predict_end_ids[12]\n",
      "pred_set {(12, 12)}\n",
      "predict_start_ids[27] predict_end_ids[28]\n",
      "pred_set {(27, 28)}\n",
      "predict_start_ids[18, 27, 48] predict_end_ids[19, 28, 49, 76]\n",
      "pred_set {(48, 49), (27, 28), (18, 19)}\n",
      "num_correct: 4, num_infer: 6, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[8] predict_end_ids[9]\n",
      "pred_set {(8, 9)}\n",
      "predict_start_ids[] predict_end_ids[61]\n",
      "pred_set set()\n",
      "predict_start_ids[10, 41] predict_end_ids[11, 42]\n",
      "pred_set {(41, 42), (10, 11)}\n",
      "predict_start_ids[21] predict_end_ids[22]\n",
      "pred_set {(21, 22)}\n",
      "num_correct: 3, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[3, 16] predict_end_ids[4, 16]\n",
      "pred_set {(16, 16), (3, 4)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "predict_start_ids[42] predict_end_ids[42]\n",
      "pred_set {(42, 42)}\n",
      "num_correct: 3, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[6, 18] predict_end_ids[6, 21]\n",
      "pred_set {(6, 6), (18, 21)}\n",
      "predict_start_ids[3, 5] predict_end_ids[3, 5]\n",
      "pred_set {(3, 3), (5, 5)}\n",
      "predict_start_ids[11, 22] predict_end_ids[14, 22]\n",
      "pred_set {(11, 14), (22, 22)}\n",
      "predict_start_ids[10] predict_end_ids[11]\n",
      "pred_set {(10, 11)}\n",
      "num_correct: 3, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[3, 9, 37, 79] predict_end_ids[4, 9, 38, 79]\n",
      "pred_set {(79, 79), (37, 38), (3, 4), (9, 9)}\n",
      "predict_start_ids[] predict_end_ids[4, 14, 24, 30]\n",
      "pred_set set()\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[18] predict_end_ids[18]\n",
      "pred_set {(18, 18)}\n",
      "num_correct: 3, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[20] predict_end_ids[21]\n",
      "pred_set {(20, 21)}\n",
      "predict_start_ids[64, 84, 98] predict_end_ids[64, 67, 84, 98]\n",
      "pred_set {(98, 98), (64, 64), (84, 84)}\n",
      "predict_start_ids[3, 12] predict_end_ids[4, 13]\n",
      "pred_set {(12, 13), (3, 4)}\n",
      "predict_start_ids[13] predict_end_ids[16]\n",
      "pred_set {(13, 16)}\n",
      "num_correct: 4, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[11] predict_end_ids[12]\n",
      "pred_set {(11, 12)}\n",
      "predict_start_ids[3] predict_end_ids[3]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[3, 30] predict_end_ids[4, 31]\n",
      "pred_set {(30, 31), (3, 4)}\n",
      "predict_start_ids[3, 7] predict_end_ids[5, 9]\n",
      "pred_set {(7, 9), (3, 5)}\n",
      "num_correct: 3, num_infer: 6, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[3, 17] predict_end_ids[4, 18]\n",
      "pred_set {(17, 18), (3, 4)}\n",
      "predict_start_ids[12] predict_end_ids[13]\n",
      "pred_set {(12, 13)}\n",
      "predict_start_ids[3, 5, 24, 26] predict_end_ids[3, 6, 24, 27]\n",
      "pred_set {(26, 27), (3, 3), (5, 6), (24, 24)}\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "num_correct: 6, num_infer: 8, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[23, 28] predict_end_ids[23, 29]\n",
      "pred_set {(28, 29), (23, 23)}\n",
      "predict_start_ids[5, 15] predict_end_ids[11, 16]\n",
      "pred_set {(15, 16), (5, 11)}\n",
      "predict_start_ids[3, 5, 14] predict_end_ids[3, 5, 14]\n",
      "pred_set {(3, 3), (14, 14), (5, 5)}\n",
      "num_correct: 4, num_infer: 7, num_label 5\n",
      "\u001b[32m[2022-09-23 03:00:18,190] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:18,191] [    INFO]\u001b[0m - Class Name: person\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:18,191] [    INFO]\u001b[0m - Class length: 247\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:18,191] [    INFO]\u001b[0m - Evaluation Precision: 0.75138 | Recall: 0.74114 | F1: 0.74623\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[60] predict_end_ids[60]\n",
      "pred_set {(60, 60)}\n",
      "predict_start_ids[23] predict_end_ids[23]\n",
      "pred_set {(23, 23)}\n",
      "predict_start_ids[10] predict_end_ids[10]\n",
      "pred_set {(10, 10)}\n",
      "predict_start_ids[39, 41] predict_end_ids[39, 41]\n",
      "pred_set {(39, 39), (41, 41)}\n",
      "num_correct: 3, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[37, 39] predict_end_ids[37, 40]\n",
      "pred_set {(37, 37), (39, 40)}\n",
      "predict_start_ids[21] predict_end_ids[22]\n",
      "pred_set {(21, 22)}\n",
      "predict_start_ids[107] predict_end_ids[108]\n",
      "pred_set {(107, 108)}\n",
      "predict_start_ids[5] predict_end_ids[5]\n",
      "pred_set {(5, 5)}\n",
      "num_correct: 5, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[37] predict_end_ids[37]\n",
      "pred_set {(37, 37)}\n",
      "predict_start_ids[32, 34] predict_end_ids[32, 34]\n",
      "pred_set {(32, 32), (34, 34)}\n",
      "predict_start_ids[19] predict_end_ids[19]\n",
      "pred_set {(19, 19)}\n",
      "predict_start_ids[54] predict_end_ids[54]\n",
      "pred_set {(54, 54)}\n",
      "num_correct: 3, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[3, 6] predict_end_ids[3, 6]\n",
      "pred_set {(6, 6), (3, 3)}\n",
      "predict_start_ids[] predict_end_ids[19]\n",
      "pred_set set()\n",
      "predict_start_ids[7] predict_end_ids[7]\n",
      "pred_set {(7, 7)}\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "num_correct: 4, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[17] predict_end_ids[19]\n",
      "pred_set {(17, 19)}\n",
      "predict_start_ids[6] predict_end_ids[8]\n",
      "pred_set {(6, 8)}\n",
      "predict_start_ids[] predict_end_ids[5]\n",
      "pred_set set()\n",
      "predict_start_ids[14] predict_end_ids[14]\n",
      "pred_set {(14, 14)}\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[7] predict_end_ids[7]\n",
      "pred_set {(7, 7)}\n",
      "predict_start_ids[] predict_end_ids[14]\n",
      "pred_set set()\n",
      "predict_start_ids[9, 36] predict_end_ids[9, 36]\n",
      "pred_set {(36, 36), (9, 9)}\n",
      "predict_start_ids[24] predict_end_ids[24]\n",
      "pred_set {(24, 24)}\n",
      "num_correct: 4, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[49, 51, 68] predict_end_ids[49, 52, 68]\n",
      "pred_set {(49, 49), (68, 68), (51, 52)}\n",
      "predict_start_ids[13] predict_end_ids[13]\n",
      "pred_set {(13, 13)}\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "num_correct: 3, num_infer: 6, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[3] predict_end_ids[3, 62]\n",
      "pred_set {(3, 3)}\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[3] predict_end_ids[4]\n",
      "pred_set {(3, 4)}\n",
      "num_correct: 4, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[4, 7, 17] predict_end_ids[4, 7, 17]\n",
      "pred_set {(4, 4), (17, 17), (7, 7)}\n",
      "predict_start_ids[] predict_end_ids[17]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[41] predict_end_ids[41]\n",
      "pred_set {(41, 41)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[4, 35] predict_end_ids[6, 35]\n",
      "pred_set {(4, 6), (35, 35)}\n",
      "predict_start_ids[21] predict_end_ids[21]\n",
      "pred_set {(21, 21)}\n",
      "num_correct: 4, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[35] predict_end_ids[35]\n",
      "pred_set {(35, 35)}\n",
      "predict_start_ids[13, 16] predict_end_ids[13, 16]\n",
      "pred_set {(16, 16), (13, 13)}\n",
      "predict_start_ids[110] predict_end_ids[110]\n",
      "pred_set {(110, 110)}\n",
      "predict_start_ids[80] predict_end_ids[81]\n",
      "pred_set {(80, 81)}\n",
      "num_correct: 5, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[5]\n",
      "pred_set set()\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "num_correct: 0, num_infer: 2, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:19,022] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:19,022] [    INFO]\u001b[0m - Class Name: occupation\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:19,022] [    INFO]\u001b[0m - Class length: 47\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:19,022] [    INFO]\u001b[0m - Evaluation Precision: 0.80392 | Recall: 0.69492 | F1: 0.74545\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[6]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 0, num_label 1\n",
      "\u001b[32m[2022-09-23 03:00:19,060] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:19,060] [    INFO]\u001b[0m - Class Name: pregnant\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:19,060] [    INFO]\u001b[0m - Class length: 1\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:19,060] [    INFO]\u001b[0m - Evaluation Precision: 0.00000 | Recall: 0.00000 | F1: 0.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[8] predict_end_ids[10]\n",
      "pred_set {(8, 10)}\n",
      "predict_start_ids[56] predict_end_ids[56]\n",
      "pred_set {(56, 56)}\n",
      "predict_start_ids[] predict_end_ids[45]\n",
      "pred_set set()\n",
      "predict_start_ids[7] predict_end_ids[7]\n",
      "pred_set {(7, 7)}\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[6] predict_end_ids[6, 27]\n",
      "pred_set {(6, 6)}\n",
      "predict_start_ids[13] predict_end_ids[13]\n",
      "pred_set {(13, 13)}\n",
      "predict_start_ids[5] predict_end_ids[11]\n",
      "pred_set {(5, 11)}\n",
      "predict_start_ids[37] predict_end_ids[37]\n",
      "pred_set {(37, 37)}\n",
      "num_correct: 2, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[33]\n",
      "pred_set set()\n",
      "predict_start_ids[39] predict_end_ids[4, 15, 39]\n",
      "pred_set {(39, 39)}\n",
      "predict_start_ids[] predict_end_ids[42]\n",
      "pred_set set()\n",
      "num_correct: 1, num_infer: 1, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[34] predict_end_ids[41]\n",
      "pred_set {(34, 41)}\n",
      "predict_start_ids[21] predict_end_ids[22]\n",
      "pred_set {(21, 22)}\n",
      "predict_start_ids[4] predict_end_ids[4, 8]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[18, 27] predict_end_ids[18, 27]\n",
      "pred_set {(27, 27), (18, 18)}\n",
      "num_correct: 5, num_infer: 5, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[52, 62] predict_end_ids[52, 62, 95]\n",
      "pred_set {(52, 52), (62, 62)}\n",
      "predict_start_ids[30] predict_end_ids[30]\n",
      "pred_set {(30, 30)}\n",
      "predict_start_ids[] predict_end_ids[18]\n",
      "pred_set set()\n",
      "predict_start_ids[88] predict_end_ids[88]\n",
      "pred_set {(88, 88)}\n",
      "num_correct: 3, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[25] predict_end_ids[30]\n",
      "pred_set {(25, 30)}\n",
      "predict_start_ids[42] predict_end_ids[42]\n",
      "pred_set {(42, 42)}\n",
      "predict_start_ids[11] predict_end_ids[11]\n",
      "pred_set {(11, 11)}\n",
      "predict_start_ids[40] predict_end_ids[40]\n",
      "pred_set {(40, 40)}\n",
      "num_correct: 4, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[44, 59] predict_end_ids[48, 59]\n",
      "pred_set {(59, 59), (44, 48)}\n",
      "predict_start_ids[28] predict_end_ids[28]\n",
      "pred_set {(28, 28)}\n",
      "predict_start_ids[61, 70] predict_end_ids[61, 70]\n",
      "pred_set {(61, 61), (70, 70)}\n",
      "predict_start_ids[35] predict_end_ids[11, 35]\n",
      "pred_set {(35, 35)}\n",
      "num_correct: 6, num_infer: 6, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[30]\n",
      "pred_set set()\n",
      "predict_start_ids[61] predict_end_ids[61]\n",
      "pred_set {(61, 61)}\n",
      "predict_start_ids[9] predict_end_ids[13]\n",
      "pred_set {(9, 13)}\n",
      "predict_start_ids[85] predict_end_ids[85]\n",
      "pred_set {(85, 85)}\n",
      "num_correct: 1, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[92] predict_end_ids[92]\n",
      "pred_set {(92, 92)}\n",
      "predict_start_ids[25] predict_end_ids[27]\n",
      "pred_set {(25, 27)}\n",
      "predict_start_ids[8] predict_end_ids[8]\n",
      "pred_set {(8, 8)}\n",
      "predict_start_ids[18, 32, 48, 56] predict_end_ids[18, 32, 48, 56]\n",
      "pred_set {(32, 32), (56, 56), (18, 18), (48, 48)}\n",
      "num_correct: 4, num_infer: 7, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[28] predict_end_ids[29]\n",
      "pred_set {(28, 29)}\n",
      "predict_start_ids[9] predict_end_ids[14]\n",
      "pred_set {(9, 14)}\n",
      "predict_start_ids[] predict_end_ids[23]\n",
      "pred_set set()\n",
      "predict_start_ids[9, 43] predict_end_ids[10, 44]\n",
      "pred_set {(9, 10), (43, 44)}\n",
      "num_correct: 3, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[58] predict_end_ids[58]\n",
      "pred_set {(58, 58)}\n",
      "predict_start_ids[6] predict_end_ids[6, 61, 73]\n",
      "pred_set {(6, 6)}\n",
      "predict_start_ids[47] predict_end_ids[49]\n",
      "pred_set {(47, 49)}\n",
      "predict_start_ids[] predict_end_ids[20]\n",
      "pred_set set()\n",
      "num_correct: 2, num_infer: 3, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[23]\n",
      "pred_set set()\n",
      "predict_start_ids[51] predict_end_ids[52]\n",
      "pred_set {(51, 52)}\n",
      "predict_start_ids[43] predict_end_ids[45]\n",
      "pred_set {(43, 45)}\n",
      "predict_start_ids[28] predict_end_ids[28]\n",
      "pred_set {(28, 28)}\n",
      "num_correct: 2, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[13] predict_end_ids[13]\n",
      "pred_set {(13, 13)}\n",
      "predict_start_ids[52] predict_end_ids[52]\n",
      "pred_set {(52, 52)}\n",
      "predict_start_ids[11] predict_end_ids[11]\n",
      "pred_set {(11, 11)}\n",
      "predict_start_ids[] predict_end_ids[19]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[63, 83, 86, 97, 100] predict_end_ids[63, 83, 88, 97, 102]\n",
      "pred_set {(86, 88), (63, 63), (97, 97), (83, 83), (100, 102)}\n",
      "predict_start_ids[] predict_end_ids[36]\n",
      "pred_set set()\n",
      "predict_start_ids[13, 27, 34, 45, 47, 93, 103] predict_end_ids[13, 27, 34, 45, 47, 93, 103]\n",
      "pred_set {(34, 34), (27, 27), (45, 45), (13, 13), (103, 103), (93, 93), (47, 47)}\n",
      "predict_start_ids[9] predict_end_ids[7, 9, 35]\n",
      "pred_set {(9, 9)}\n",
      "num_correct: 12, num_infer: 13, num_label 14\n",
      "<<< batch 6\n",
      "predict_start_ids[15, 47] predict_end_ids[15, 47]\n",
      "pred_set {(47, 47), (15, 15)}\n",
      "predict_start_ids[54, 58, 62, 65, 85] predict_end_ids[54, 58, 62, 65, 85]\n",
      "pred_set {(85, 85), (62, 62), (65, 65), (54, 54), (58, 58)}\n",
      "predict_start_ids[5, 20] predict_end_ids[5, 20]\n",
      "pred_set {(5, 5), (20, 20)}\n",
      "predict_start_ids[7] predict_end_ids[7]\n",
      "pred_set {(7, 7)}\n",
      "num_correct: 7, num_infer: 10, num_label 9\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[15]\n",
      "pred_set set()\n",
      "predict_start_ids[40] predict_end_ids[42]\n",
      "pred_set {(40, 42)}\n",
      "predict_start_ids[5] predict_end_ids[5]\n",
      "pred_set {(5, 5)}\n",
      "predict_start_ids[49] predict_end_ids[49]\n",
      "pred_set {(49, 49)}\n",
      "num_correct: 1, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[61]\n",
      "pred_set set()\n",
      "predict_start_ids[6] predict_end_ids[6]\n",
      "pred_set {(6, 6)}\n",
      "predict_start_ids[17, 20] predict_end_ids[17, 20]\n",
      "pred_set {(17, 17), (20, 20)}\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "num_correct: 3, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[31, 41] predict_end_ids[32, 42]\n",
      "pred_set {(41, 42), (31, 32)}\n",
      "predict_start_ids[23] predict_end_ids[23]\n",
      "pred_set {(23, 23)}\n",
      "predict_start_ids[20] predict_end_ids[22]\n",
      "pred_set {(20, 22)}\n",
      "predict_start_ids[] predict_end_ids[15, 24]\n",
      "pred_set set()\n",
      "num_correct: 2, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[28]\n",
      "pred_set set()\n",
      "predict_start_ids[28] predict_end_ids[29]\n",
      "pred_set {(28, 29)}\n",
      "predict_start_ids[] predict_end_ids[31]\n",
      "pred_set set()\n",
      "predict_start_ids[24] predict_end_ids[24]\n",
      "pred_set {(24, 24)}\n",
      "num_correct: 1, num_infer: 2, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[82, 91] predict_end_ids[82, 91]\n",
      "pred_set {(91, 91), (82, 82)}\n",
      "predict_start_ids[35] predict_end_ids[36]\n",
      "pred_set {(35, 36)}\n",
      "predict_start_ids[107, 109] predict_end_ids[107, 109]\n",
      "pred_set {(107, 107), (109, 109)}\n",
      "predict_start_ids[33, 69] predict_end_ids[39, 75]\n",
      "pred_set {(69, 75), (33, 39)}\n",
      "num_correct: 6, num_infer: 7, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[8]\n",
      "pred_set set()\n",
      "predict_start_ids[18] predict_end_ids[18]\n",
      "pred_set {(18, 18)}\n",
      "predict_start_ids[] predict_end_ids[14]\n",
      "pred_set set()\n",
      "predict_start_ids[39] predict_end_ids[27, 44]\n",
      "pred_set {(39, 44)}\n",
      "num_correct: 1, num_infer: 2, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[5] predict_end_ids[8]\n",
      "pred_set {(5, 8)}\n",
      "predict_start_ids[27] predict_end_ids[27, 31]\n",
      "pred_set {(27, 27)}\n",
      "num_correct: 2, num_infer: 2, num_label 2\n",
      "\u001b[32m[2022-09-23 03:00:20,643] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:20,643] [    INFO]\u001b[0m - Class Name: status\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:20,643] [    INFO]\u001b[0m - Class length: 86\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:20,643] [    INFO]\u001b[0m - Evaluation Precision: 0.76289 | Recall: 0.59677 | F1: 0.66968\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[12, 15] predict_end_ids[12, 15]\n",
      "pred_set {(12, 12), (15, 15)}\n",
      "predict_start_ids[27] predict_end_ids[27]\n",
      "pred_set {(27, 27)}\n",
      "predict_start_ids[27, 31, 34, 39] predict_end_ids[27, 31, 34, 39]\n",
      "pred_set {(39, 39), (34, 34), (27, 27), (31, 31)}\n",
      "predict_start_ids[107] predict_end_ids[107]\n",
      "pred_set {(107, 107)}\n",
      "num_correct: 7, num_infer: 8, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[5] predict_end_ids[6]\n",
      "pred_set {(5, 6)}\n",
      "predict_start_ids[47] predict_end_ids[47]\n",
      "pred_set {(47, 47)}\n",
      "predict_start_ids[29, 32, 35] predict_end_ids[29, 32, 35]\n",
      "pred_set {(32, 32), (29, 29), (35, 35)}\n",
      "predict_start_ids[5] predict_end_ids[6]\n",
      "pred_set {(5, 6)}\n",
      "num_correct: 5, num_infer: 6, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[16] predict_end_ids[16, 23]\n",
      "pred_set {(16, 16)}\n",
      "predict_start_ids[37, 47, 58] predict_end_ids[37, 47, 58]\n",
      "pred_set {(37, 37), (47, 47), (58, 58)}\n",
      "predict_start_ids[15, 27, 55, 59, 63, 66] predict_end_ids[15, 27, 55, 59, 63, 66]\n",
      "pred_set {(27, 27), (63, 63), (55, 55), (66, 66), (59, 59), (15, 15)}\n",
      "predict_start_ids[15] predict_end_ids[15]\n",
      "pred_set {(15, 15)}\n",
      "num_correct: 6, num_infer: 11, num_label 12\n",
      "<<< batch 6\n",
      "predict_start_ids[39] predict_end_ids[40]\n",
      "pred_set {(39, 40)}\n",
      "predict_start_ids[47, 49, 62] predict_end_ids[47, 49, 62]\n",
      "pred_set {(47, 47), (49, 49), (62, 62)}\n",
      "predict_start_ids[60] predict_end_ids[60]\n",
      "pred_set {(60, 60)}\n",
      "predict_start_ids[5, 23] predict_end_ids[6, 24]\n",
      "pred_set {(23, 24), (5, 6)}\n",
      "num_correct: 4, num_infer: 7, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[27]\n",
      "pred_set set()\n",
      "predict_start_ids[98, 109] predict_end_ids[65, 67, 70, 98, 109]\n",
      "pred_set {(98, 98), (109, 109)}\n",
      "predict_start_ids[] predict_end_ids[32]\n",
      "pred_set set()\n",
      "predict_start_ids[52, 63] predict_end_ids[52, 63]\n",
      "pred_set {(52, 52), (63, 63)}\n",
      "num_correct: 4, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[64, 68] predict_end_ids[64, 68]\n",
      "pred_set {(64, 64), (68, 68)}\n",
      "predict_start_ids[50, 54] predict_end_ids[50, 54]\n",
      "pred_set {(50, 50), (54, 54)}\n",
      "predict_start_ids[26, 29] predict_end_ids[26, 29]\n",
      "pred_set {(29, 29), (26, 26)}\n",
      "predict_start_ids[8] predict_end_ids[8, 36]\n",
      "pred_set {(8, 8)}\n",
      "num_correct: 6, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[45]\n",
      "pred_set set()\n",
      "predict_start_ids[9, 63, 73] predict_end_ids[9, 63, 73]\n",
      "pred_set {(63, 63), (73, 73), (9, 9)}\n",
      "predict_start_ids[70] predict_end_ids[48, 71, 96]\n",
      "pred_set {(70, 71)}\n",
      "predict_start_ids[] predict_end_ids[26]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[43, 55] predict_end_ids[43, 55]\n",
      "pred_set {(43, 43), (55, 55)}\n",
      "predict_start_ids[40] predict_end_ids[31, 40]\n",
      "pred_set {(40, 40)}\n",
      "predict_start_ids[41, 44, 48] predict_end_ids[41, 44, 48]\n",
      "pred_set {(48, 48), (41, 41), (44, 44)}\n",
      "predict_start_ids[47, 55] predict_end_ids[47, 55]\n",
      "pred_set {(47, 47), (55, 55)}\n",
      "num_correct: 7, num_infer: 8, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[62] predict_end_ids[45, 62]\n",
      "pred_set {(62, 62)}\n",
      "predict_start_ids[5] predict_end_ids[7]\n",
      "pred_set {(5, 7)}\n",
      "predict_start_ids[12, 24] predict_end_ids[12, 24]\n",
      "pred_set {(12, 12), (24, 24)}\n",
      "num_correct: 2, num_infer: 4, num_label 4\n",
      "\u001b[32m[2022-09-23 03:00:21,304] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,304] [    INFO]\u001b[0m - Class Name: parts of body\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,304] [    INFO]\u001b[0m - Class length: 35\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,304] [    INFO]\u001b[0m - Evaluation Precision: 0.74576 | Recall: 0.70968 | F1: 0.72727\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[6] predict_end_ids[7]\n",
      "pred_set {(6, 7)}\n",
      "predict_start_ids[55] predict_end_ids[55]\n",
      "pred_set {(55, 55)}\n",
      "predict_start_ids[20, 29] predict_end_ids[21, 30]\n",
      "pred_set {(29, 30), (20, 21)}\n",
      "predict_start_ids[78] predict_end_ids[69, 80]\n",
      "pred_set {(78, 80)}\n",
      "num_correct: 5, num_infer: 5, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[5] predict_end_ids[9]\n",
      "pred_set {(5, 9)}\n",
      "predict_start_ids[46] predict_end_ids[46]\n",
      "pred_set {(46, 46)}\n",
      "predict_start_ids[24] predict_end_ids[25]\n",
      "pred_set {(24, 25)}\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[23] predict_end_ids[23]\n",
      "pred_set {(23, 23)}\n",
      "predict_start_ids[102] predict_end_ids[103]\n",
      "pred_set {(102, 103)}\n",
      "predict_start_ids[7] predict_end_ids[7]\n",
      "pred_set {(7, 7)}\n",
      "predict_start_ids[15] predict_end_ids[18]\n",
      "pred_set {(15, 18)}\n",
      "num_correct: 4, num_infer: 4, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[99] predict_end_ids[102]\n",
      "pred_set {(99, 102)}\n",
      "predict_start_ids[8] predict_end_ids[8]\n",
      "pred_set {(8, 8)}\n",
      "predict_start_ids[94, 99] predict_end_ids[97, 102]\n",
      "pred_set {(99, 102), (94, 97)}\n",
      "num_correct: 3, num_infer: 4, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:21,588] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,588] [    INFO]\u001b[0m - Class Name: origanization\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,588] [    INFO]\u001b[0m - Class length: 15\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,588] [    INFO]\u001b[0m - Evaluation Precision: 0.93750 | Recall: 0.78947 | F1: 0.85714\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[5] predict_end_ids[7]\n",
      "pred_set {(5, 7)}\n",
      "predict_start_ids[34] predict_end_ids[35]\n",
      "pred_set {(34, 35)}\n",
      "predict_start_ids[78] predict_end_ids[80, 89]\n",
      "pred_set {(78, 80)}\n",
      "num_correct: 3, num_infer: 3, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[5] predict_end_ids[8, 14]\n",
      "pred_set {(5, 8)}\n",
      "num_correct: 1, num_infer: 1, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:21,705] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,705] [    INFO]\u001b[0m - Class Name: supernature\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,705] [    INFO]\u001b[0m - Class length: 5\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:21,706] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 0.50000 | F1: 0.66667\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[47] predict_end_ids[48, 52]\n",
      "pred_set {(47, 48)}\n",
      "predict_start_ids[6, 20] predict_end_ids[9, 21]\n",
      "pred_set {(6, 9), (20, 21)}\n",
      "predict_start_ids[] predict_end_ids[57]\n",
      "pred_set set()\n",
      "predict_start_ids[63] predict_end_ids[66, 70]\n",
      "pred_set {(63, 66)}\n",
      "num_correct: 4, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[4] predict_end_ids[4]\n",
      "pred_set {(4, 4)}\n",
      "predict_start_ids[44, 54] predict_end_ids[44, 55]\n",
      "pred_set {(54, 55), (44, 44)}\n",
      "predict_start_ids[24, 27, 31, 35, 36] predict_end_ids[24, 28, 31, 36]\n",
      "pred_set {(31, 31), (27, 28), (36, 36), (24, 24)}\n",
      "predict_start_ids[44] predict_end_ids[44]\n",
      "pred_set {(44, 44)}\n",
      "num_correct: 4, num_infer: 8, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[104]\n",
      "pred_set set()\n",
      "predict_start_ids[61, 65] predict_end_ids[61, 65]\n",
      "pred_set {(61, 61), (65, 65)}\n",
      "predict_start_ids[107] predict_end_ids[107]\n",
      "pred_set {(107, 107)}\n",
      "predict_start_ids[42, 45] predict_end_ids[42, 46]\n",
      "pred_set {(45, 46), (42, 42)}\n",
      "num_correct: 5, num_infer: 5, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[15, 18, 24] predict_end_ids[15, 18, 24]\n",
      "pred_set {(24, 24), (18, 18), (15, 15)}\n",
      "predict_start_ids[23] predict_end_ids[23]\n",
      "pred_set {(23, 23)}\n",
      "predict_start_ids[129, 136] predict_end_ids[129, 137]\n",
      "pred_set {(136, 137), (129, 129)}\n",
      "predict_start_ids[29] predict_end_ids[29]\n",
      "pred_set {(29, 29)}\n",
      "num_correct: 6, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[93, 95, 104] predict_end_ids[93, 95, 106]\n",
      "pred_set {(104, 106), (93, 93), (95, 95)}\n",
      "predict_start_ids[51, 56, 59, 63] predict_end_ids[52, 56, 60, 63]\n",
      "pred_set {(59, 60), (56, 56), (63, 63), (51, 52)}\n",
      "predict_start_ids[9] predict_end_ids[11]\n",
      "pred_set {(9, 11)}\n",
      "predict_start_ids[32] predict_end_ids[34]\n",
      "pred_set {(32, 34)}\n",
      "num_correct: 7, num_infer: 9, num_label 9\n",
      "<<< batch 6\n",
      "predict_start_ids[39, 51] predict_end_ids[40, 52]\n",
      "pred_set {(39, 40), (51, 52)}\n",
      "predict_start_ids[45, 47, 58] predict_end_ids[45, 48, 59]\n",
      "pred_set {(45, 45), (47, 48), (58, 59)}\n",
      "predict_start_ids[38, 41] predict_end_ids[38, 41]\n",
      "pred_set {(41, 41), (38, 38)}\n",
      "predict_start_ids[41, 51] predict_end_ids[43, 51]\n",
      "pred_set {(41, 43), (51, 51)}\n",
      "num_correct: 9, num_infer: 9, num_label 9\n",
      "\u001b[32m[2022-09-23 03:00:22,166] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,166] [    INFO]\u001b[0m - Class Name: color\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,166] [    INFO]\u001b[0m - Class length: 24\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,166] [    INFO]\u001b[0m - Evaluation Precision: 0.83333 | Recall: 0.79545 | F1: 0.81395\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[32, 35] predict_end_ids[32, 35]\n",
      "pred_set {(32, 32), (35, 35)}\n",
      "predict_start_ids[27] predict_end_ids[27]\n",
      "pred_set {(27, 27)}\n",
      "predict_start_ids[52] predict_end_ids[52]\n",
      "pred_set {(52, 52)}\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "num_correct: 5, num_infer: 5, num_label 5\n",
      "\u001b[32m[2022-09-23 03:00:22,243] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,243] [    INFO]\u001b[0m - Class Name: hobby\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,243] [    INFO]\u001b[0m - Class length: 4\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,243] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 1.00000 | F1: 1.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[61] predict_end_ids[53, 61]\n",
      "pred_set {(61, 61)}\n",
      "predict_start_ids[36, 55, 57] predict_end_ids[36, 45, 46, 56, 57]\n",
      "pred_set {(36, 36), (57, 57), (55, 56)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[10]\n",
      "pred_set set()\n",
      "num_correct: 1, num_infer: 4, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[25] predict_end_ids[25, 30]\n",
      "pred_set {(25, 25)}\n",
      "predict_start_ids[59] predict_end_ids[60]\n",
      "pred_set {(59, 60)}\n",
      "predict_start_ids[56] predict_end_ids[56]\n",
      "pred_set {(56, 56)}\n",
      "predict_start_ids[23, 24] predict_end_ids[23, 24]\n",
      "pred_set {(23, 23), (24, 24)}\n",
      "num_correct: 3, num_infer: 5, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[14] predict_end_ids[14]\n",
      "pred_set {(14, 14)}\n",
      "predict_start_ids[6, 8, 18, 20] predict_end_ids[6, 8, 18, 21]\n",
      "pred_set {(6, 6), (8, 8), (18, 18), (20, 21)}\n",
      "predict_start_ids[103] predict_end_ids[104]\n",
      "pred_set {(103, 104)}\n",
      "predict_start_ids[46] predict_end_ids[47]\n",
      "pred_set {(46, 47)}\n",
      "num_correct: 4, num_infer: 7, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[64] predict_end_ids[65]\n",
      "pred_set {(64, 65)}\n",
      "predict_start_ids[57] predict_end_ids[59, 61]\n",
      "pred_set {(57, 59)}\n",
      "predict_start_ids[27, 33] predict_end_ids[27, 33]\n",
      "pred_set {(27, 27), (33, 33)}\n",
      "predict_start_ids[57] predict_end_ids[57]\n",
      "pred_set {(57, 57)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[20, 32] predict_end_ids[21, 34]\n",
      "pred_set {(32, 34), (20, 21)}\n",
      "predict_start_ids[38, 41] predict_end_ids[38, 42]\n",
      "pred_set {(41, 42), (38, 38)}\n",
      "num_correct: 3, num_infer: 4, num_label 4\n",
      "\u001b[32m[2022-09-23 03:00:22,581] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,582] [    INFO]\u001b[0m - Class Name: body type\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,582] [    INFO]\u001b[0m - Class length: 18\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,582] [    INFO]\u001b[0m - Evaluation Precision: 0.60000 | Recall: 0.57692 | F1: 0.58824\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[10] predict_end_ids[13]\n",
      "pred_set {(10, 13)}\n",
      "predict_start_ids[82] predict_end_ids[82]\n",
      "pred_set {(82, 82)}\n",
      "predict_start_ids[11] predict_end_ids[11]\n",
      "pred_set {(11, 11)}\n",
      "predict_start_ids[70, 77] predict_end_ids[70, 77]\n",
      "pred_set {(70, 70), (77, 77)}\n",
      "num_correct: 5, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[9, 21] predict_end_ids[9, 25]\n",
      "pred_set {(21, 25), (9, 9)}\n",
      "predict_start_ids[] predict_end_ids[39, 59]\n",
      "pred_set set()\n",
      "predict_start_ids[60] predict_end_ids[60]\n",
      "pred_set {(60, 60)}\n",
      "predict_start_ids[18, 31] predict_end_ids[21, 33]\n",
      "pred_set {(31, 33), (18, 21)}\n",
      "num_correct: 4, num_infer: 5, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[28]\n",
      "pred_set set()\n",
      "predict_start_ids[5] predict_end_ids[5]\n",
      "pred_set {(5, 5)}\n",
      "predict_start_ids[] predict_end_ids[19]\n",
      "pred_set set()\n",
      "predict_start_ids[24] predict_end_ids[24]\n",
      "pred_set {(24, 24)}\n",
      "num_correct: 2, num_infer: 2, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[87] predict_end_ids[87]\n",
      "pred_set {(87, 87)}\n",
      "predict_start_ids[4] predict_end_ids[8]\n",
      "pred_set {(4, 8)}\n",
      "predict_start_ids[62] predict_end_ids[62]\n",
      "pred_set {(62, 62)}\n",
      "predict_start_ids[32] predict_end_ids[34]\n",
      "pred_set {(32, 34)}\n",
      "num_correct: 4, num_infer: 4, num_label 4\n",
      "\u001b[32m[2022-09-23 03:00:22,891] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,891] [    INFO]\u001b[0m - Class Name: age\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,892] [    INFO]\u001b[0m - Class length: 16\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:22,892] [    INFO]\u001b[0m - Evaluation Precision: 0.93750 | Recall: 0.78947 | F1: 0.85714\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 0, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[65] predict_end_ids[68]\n",
      "pred_set {(65, 68)}\n",
      "predict_start_ids[] predict_end_ids[9]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 1, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:23,035] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,036] [    INFO]\u001b[0m - Class Name: event\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,036] [    INFO]\u001b[0m - Class length: 7\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,036] [    INFO]\u001b[0m - Evaluation Precision: 0.00000 | Recall: 0.00000 | F1: 0.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[45] predict_end_ids[45]\n",
      "pred_set {(45, 45)}\n",
      "predict_start_ids[] predict_end_ids[48]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[20] predict_end_ids[20]\n",
      "pred_set {(20, 20)}\n",
      "num_correct: 2, num_infer: 2, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[17, 84, 96] predict_end_ids[17, 84, 96]\n",
      "pred_set {(17, 17), (96, 96), (84, 84)}\n",
      "predict_start_ids[91] predict_end_ids[91]\n",
      "pred_set {(91, 91)}\n",
      "predict_start_ids[58] predict_end_ids[58, 62]\n",
      "pred_set {(58, 58)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "\u001b[32m[2022-09-23 03:00:23,176] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,176] [    INFO]\u001b[0m - Class Name: race\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,176] [    INFO]\u001b[0m - Class length: 7\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,176] [    INFO]\u001b[0m - Evaluation Precision: 0.85714 | Recall: 0.66667 | F1: 0.75000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[7] predict_end_ids[7, 33]\n",
      "pred_set {(7, 7)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[31, 46]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[33]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 1, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[42] predict_end_ids[44]\n",
      "pred_set {(42, 44)}\n",
      "predict_start_ids[62] predict_end_ids[64]\n",
      "pred_set {(62, 64)}\n",
      "predict_start_ids[18] predict_end_ids[18]\n",
      "pred_set {(18, 18)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 1, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[3] predict_end_ids[5]\n",
      "pred_set {(3, 5)}\n",
      "predict_start_ids[73, 89, 102, 109] predict_end_ids[74, 90, 107, 110]\n",
      "pred_set {(102, 107), (89, 90), (109, 110), (73, 74)}\n",
      "predict_start_ids[] predict_end_ids[15, 29]\n",
      "pred_set set()\n",
      "predict_start_ids[8] predict_end_ids[10]\n",
      "pred_set {(8, 10)}\n",
      "num_correct: 6, num_infer: 6, num_label 8\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[17] predict_end_ids[18]\n",
      "pred_set {(17, 18)}\n",
      "predict_start_ids[] predict_end_ids[12]\n",
      "pred_set set()\n",
      "num_correct: 1, num_infer: 1, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[3, 37, 48, 57] predict_end_ids[5, 37, 48, 57, 85]\n",
      "pred_set {(37, 37), (57, 57), (3, 5), (48, 48)}\n",
      "predict_start_ids[] predict_end_ids[7]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[6]\n",
      "pred_set set()\n",
      "num_correct: 3, num_infer: 4, num_label 9\n",
      "<<< batch 6\n",
      "predict_start_ids[94, 104] predict_end_ids[95, 104]\n",
      "pred_set {(94, 95), (104, 104)}\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[8, 17] predict_end_ids[8, 19]\n",
      "pred_set {(8, 8), (17, 19)}\n",
      "predict_start_ids[] predict_end_ids[43]\n",
      "pred_set set()\n",
      "num_correct: 4, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[82]\n",
      "pred_set set()\n",
      "predict_start_ids[80] predict_end_ids[23, 84, 85]\n",
      "pred_set {(80, 84)}\n",
      "predict_start_ids[] predict_end_ids[54]\n",
      "pred_set set()\n",
      "predict_start_ids[18, 21, 26, 34, 44, 52] predict_end_ids[19, 21, 30, 35, 45, 53]\n",
      "pred_set {(52, 53), (26, 30), (44, 45), (34, 35), (18, 19), (21, 21)}\n",
      "num_correct: 4, num_infer: 7, num_label 7\n",
      "<<< batch 6\n",
      "predict_start_ids[23] predict_end_ids[24]\n",
      "pred_set {(23, 24)}\n",
      "predict_start_ids[87] predict_end_ids[88]\n",
      "pred_set {(87, 88)}\n",
      "num_correct: 2, num_infer: 2, num_label 2\n",
      "\u001b[32m[2022-09-23 03:00:23,734] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,734] [    INFO]\u001b[0m - Class Name: location\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,734] [    INFO]\u001b[0m - Class length: 30\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,734] [    INFO]\u001b[0m - Evaluation Precision: 0.75000 | Recall: 0.44681 | F1: 0.56000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[5] predict_end_ids[5]\n",
      "pred_set {(5, 5)}\n",
      "predict_start_ids[51] predict_end_ids[51]\n",
      "pred_set {(51, 51)}\n",
      "predict_start_ids[60] predict_end_ids[60]\n",
      "pred_set {(60, 60)}\n",
      "num_correct: 3, num_infer: 3, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:23,798] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,799] [    INFO]\u001b[0m - Class Name: size\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,799] [    INFO]\u001b[0m - Class length: 3\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,799] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 1.00000 | F1: 1.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[11, 17, 23, 47, 53]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[17, 24, 33]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 0, num_label 8\n",
      "\u001b[32m[2022-09-23 03:00:23,845] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,845] [    INFO]\u001b[0m - Class Name: Sexual description\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,845] [    INFO]\u001b[0m - Class length: 2\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,845] [    INFO]\u001b[0m - Evaluation Precision: 0.00000 | Recall: 0.00000 | F1: 0.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[31]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[18]\n",
      "pred_set set()\n",
      "predict_start_ids[9, 19] predict_end_ids[25]\n",
      "pred_set {(19, 25)}\n",
      "num_correct: 1, num_infer: 1, num_label 6\n",
      "\u001b[32m[2022-09-23 03:00:23,914] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,915] [    INFO]\u001b[0m - Class Name: sexual description\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,915] [    INFO]\u001b[0m - Class length: 4\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:23,915] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 0.16667 | F1: 0.28571\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[42] predict_end_ids[42]\n",
      "pred_set {(42, 42)}\n",
      "predict_start_ids[10] predict_end_ids[10]\n",
      "pred_set {(10, 10)}\n",
      "predict_start_ids[63] predict_end_ids[63]\n",
      "pred_set {(63, 63)}\n",
      "predict_start_ids[26] predict_end_ids[26]\n",
      "pred_set {(26, 26)}\n",
      "num_correct: 4, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[13]\n",
      "pred_set set()\n",
      "predict_start_ids[10] predict_end_ids[10]\n",
      "pred_set {(10, 10)}\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "predict_start_ids[26, 32] predict_end_ids[26, 32]\n",
      "pred_set {(32, 32), (26, 26)}\n",
      "num_correct: 4, num_infer: 4, num_label 5\n",
      "\u001b[32m[2022-09-23 03:00:24,060] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,060] [    INFO]\u001b[0m - Class Name: gender\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,060] [    INFO]\u001b[0m - Class length: 8\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,060] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 0.88889 | F1: 0.94118\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[110] predict_end_ids[110]\n",
      "pred_set {(110, 110)}\n",
      "predict_start_ids[17] predict_end_ids[17]\n",
      "pred_set {(17, 17)}\n",
      "predict_start_ids[94] predict_end_ids[94]\n",
      "pred_set {(94, 94)}\n",
      "num_correct: 3, num_infer: 3, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[63] predict_end_ids[63]\n",
      "pred_set {(63, 63)}\n",
      "predict_start_ids[16] predict_end_ids[16]\n",
      "pred_set {(16, 16)}\n",
      "predict_start_ids[] predict_end_ids[133]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[15, 45]\n",
      "pred_set set()\n",
      "num_correct: 2, num_infer: 2, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[53] predict_end_ids[53]\n",
      "pred_set {(53, 53)}\n",
      "predict_start_ids[12] predict_end_ids[12]\n",
      "pred_set {(12, 12)}\n",
      "predict_start_ids[51] predict_end_ids[51]\n",
      "pred_set {(51, 51)}\n",
      "predict_start_ids[32, 35] predict_end_ids[32, 35]\n",
      "pred_set {(32, 32), (35, 35)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[41] predict_end_ids[41]\n",
      "pred_set {(41, 41)}\n",
      "num_correct: 1, num_infer: 1, num_label 1\n",
      "\u001b[32m[2022-09-23 03:00:24,326] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,326] [    INFO]\u001b[0m - Class Name: facility\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,326] [    INFO]\u001b[0m - Class length: 13\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,326] [    INFO]\u001b[0m - Evaluation Precision: 0.90909 | Recall: 0.62500 | F1: 0.74074\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[35]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 0, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:24,375] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,375] [    INFO]\u001b[0m - Class Name: office-work\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,375] [    INFO]\u001b[0m - Class length: 2\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,376] [    INFO]\u001b[0m - Evaluation Precision: 0.00000 | Recall: 0.00000 | F1: 0.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[17]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[33]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 0, num_label 2\n",
      "\u001b[32m[2022-09-23 03:00:24,418] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,419] [    INFO]\u001b[0m - Class Name: cheating\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,419] [    INFO]\u001b[0m - Class length: 2\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,419] [    INFO]\u001b[0m - Evaluation Precision: 0.00000 | Recall: 0.00000 | F1: 0.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[20] predict_end_ids[21, 22]\n",
      "pred_set {(20, 21)}\n",
      "predict_start_ids[42] predict_end_ids[47]\n",
      "pred_set {(42, 47)}\n",
      "predict_start_ids[60] predict_end_ids[61]\n",
      "pred_set {(60, 61)}\n",
      "num_correct: 2, num_infer: 3, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:24,481] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,481] [    INFO]\u001b[0m - Class Name: high-tech\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,481] [    INFO]\u001b[0m - Class length: 3\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,481] [    INFO]\u001b[0m - Evaluation Precision: 0.66667 | Recall: 0.66667 | F1: 0.66667\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[5, 17] predict_end_ids[5, 17]\n",
      "pred_set {(17, 17), (5, 5)}\n",
      "predict_start_ids[48] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[38] predict_end_ids[41]\n",
      "pred_set {(38, 41)}\n",
      "predict_start_ids[28] predict_end_ids[29]\n",
      "pred_set {(28, 29)}\n",
      "num_correct: 4, num_infer: 4, num_label 6\n",
      "<<< batch 6\n",
      "predict_start_ids[70] predict_end_ids[73, 74]\n",
      "pred_set {(70, 73)}\n",
      "predict_start_ids[67, 70] predict_end_ids[67, 73]\n",
      "pred_set {(67, 67), (70, 73)}\n",
      "predict_start_ids[57] predict_end_ids[59, 60]\n",
      "pred_set {(57, 59)}\n",
      "predict_start_ids[57] predict_end_ids[58]\n",
      "pred_set {(57, 58)}\n",
      "num_correct: 4, num_infer: 5, num_label 5\n",
      "<<< batch 6\n",
      "predict_start_ids[17] predict_end_ids[22]\n",
      "pred_set {(17, 22)}\n",
      "num_correct: 1, num_infer: 1, num_label 1\n",
      "\u001b[32m[2022-09-23 03:00:24,670] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,670] [    INFO]\u001b[0m - Class Name: height\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,670] [    INFO]\u001b[0m - Class length: 9\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,670] [    INFO]\u001b[0m - Evaluation Precision: 0.90000 | Recall: 0.75000 | F1: 0.81818\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[9] predict_end_ids[9]\n",
      "pred_set {(9, 9)}\n",
      "predict_start_ids[10] predict_end_ids[10]\n",
      "pred_set {(10, 10)}\n",
      "predict_start_ids[18] predict_end_ids[18]\n",
      "pred_set {(18, 18)}\n",
      "predict_start_ids[9] predict_end_ids[10]\n",
      "pred_set {(9, 10)}\n",
      "num_correct: 4, num_infer: 4, num_label 4\n",
      "<<< batch 6\n",
      "predict_start_ids[16] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 0, num_label 1\n",
      "\u001b[32m[2022-09-23 03:00:24,777] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,777] [    INFO]\u001b[0m - Class Name: love stage\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,777] [    INFO]\u001b[0m - Class length: 5\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,777] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 0.80000 | F1: 0.88889\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[52] predict_end_ids[52, 54]\n",
      "pred_set {(52, 52)}\n",
      "predict_start_ids[50] predict_end_ids[48, 52]\n",
      "pred_set {(50, 52)}\n",
      "num_correct: 1, num_infer: 2, num_label 3\n",
      "\u001b[32m[2022-09-23 03:00:24,838] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,838] [    INFO]\u001b[0m - Class Name: shape\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,839] [    INFO]\u001b[0m - Class length: 3\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,839] [    INFO]\u001b[0m - Evaluation Precision: 0.50000 | Recall: 0.33333 | F1: 0.40000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "predict_start_ids[] predict_end_ids[]\n",
      "pred_set set()\n",
      "num_correct: 0, num_infer: 0, num_label 2\n",
      "\u001b[32m[2022-09-23 03:00:24,889] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,890] [    INFO]\u001b[0m - Class Name: campus\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,890] [    INFO]\u001b[0m - Class length: 2\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,890] [    INFO]\u001b[0m - Evaluation Precision: 0.00000 | Recall: 0.00000 | F1: 0.00000\u001b[0m\n",
      "<<< start evaluate\n",
      "<<< batch 6\n",
      "predict_start_ids[94] predict_end_ids[94]\n",
      "pred_set {(94, 94)}\n",
      "num_correct: 1, num_infer: 1, num_label 1\n",
      "\u001b[32m[2022-09-23 03:00:24,931] [    INFO]\u001b[0m - -----------------------------\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,931] [    INFO]\u001b[0m - Class Name: abuse\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,931] [    INFO]\u001b[0m - Class length: 1\u001b[0m\n",
      "\u001b[32m[2022-09-23 03:00:24,931] [    INFO]\u001b[0m - Evaluation Precision: 1.00000 | Recall: 1.00000 | F1: 1.00000\u001b[0m\n",
      "Exception in thread Thread-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/paddle/fluid/dataloader/dataloader_iter.py\", line 217, in _thread_loop\n",
      "    batch = self._dataset_fetcher.fetch(indices,\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/paddle/fluid/dataloader/fetcher.py\", line 121, in fetch\n",
      "    data.append(self.dataset[idx])\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/paddlenlp/datasets/dataset.py\", line 276, in __getitem__\n",
      "    self.new_data[idx]\n",
      "KeyError: 0\n"
     ]
    }
   ],
   "source": [
    "! python evaluate.py \\\n",
    "--model_path ../model_best \\\n",
    "--test_path ./data/test.txt \\\n",
    "--batch_size 4 \\\n",
    "--debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the trained model to prepare for predictions\n",
    "\n",
    "The deploy() method creates an endpoint (in this case locally) which serves prediction requests in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-west-2-064542430558/pytorch-training-2022-10-11-07-37-29-125/output/model.tar.gz to ../../../../../../tmp/model.tar.gz\n",
      "model_200/\n",
      "model_300/\n",
      "inference.pdmodel\n",
      "model_best/\n",
      "model_best/tokenizer_config.json\n",
      "model_best/vocab.txt\n",
      "model_best/model_state.pdparams\n",
      "model_best/special_tokens_map.json\n",
      "model_best/model_config.json\n",
      "inference.pdiparams\n",
      "inference.pdiparams.info\n",
      "model_100/\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://sagemaker-us-west-2-064542430558/pytorch-training-2022-10-11-07-37-29-125/output/model.tar.gz /tmp/\n",
    "!tar -zxvf /tmp/model.tar.gz -C /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code/\n",
      "code/infer.py\n",
      "code/.ipynb_checkpoints/\n",
      "code/.ipynb_checkpoints/infer_gpu-checkpoint.py\n",
      "code/uie_predictor.py\n",
      "code/infer_cpu.py\n",
      "code/requirements.txt\n",
      "code/requirements_gpu.txt\n",
      "code/model.py\n",
      "code/infer_gpu.py\n",
      "code/requirements_cpu.txt\n",
      "inference.pdiparams\n",
      "inference.pdiparams.info\n",
      "inference.pdmodel\n",
      "model_config.json\n",
      "model_state.pdparams\n",
      "special_tokens_map.json\n",
      "tokenizer_config.json\n",
      "vocab.txt\n"
     ]
    }
   ],
   "source": [
    "!cp /tmp/inference.* model/\n",
    "!cp /tmp/model_best/* model/\n",
    "!cp model/code/requirements_gpu.txt model/code/requirements.txt\n",
    "!cd model && tar -czvf ../model-inference-gpu.tar.gz *\n",
    "\n",
    "#!aws s3 cp model-inference-gpu.tar.gz s3://$bucket/output/model-inference-gpu.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model-inference-gpu.tar.gz to s3://sagemaker-us-west-2-064542430558/output/model-inference-gpu.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model-inference-gpu.tar.gz s3://$bucket/output/model-inference-gpu.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "# instance_type = 'local'\n",
    "# instance_type = 'ml.m5.xlarge'\n",
    "instance_type = 'ml.g4dn.xlarge'\n",
    "\n",
    "# predictor = estimator.deploy(initial_instance_count=1, instance_type=instance_type)\n",
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data='s3://{}/output/model-inference-gpu.tar.gz'.format(bucket), role=role,\n",
    "                             entry_point='infer_gpu.py', framework_version='1.9.0', py_version='py38', model_server_workers=4)  # TODO [For GPU], model_server_workers=6\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # endpoint_name = 'pytorch-inference-2022-07-05-07-28-16-183'  # m5.2xlarge\n",
    "# # endpoint_name = 'pytorch-inference-2022-07-06-04-02-11-091'  # g4dn.xlarge, 6 threads\n",
    "# endpoint_name = 'pytorch-inference-2022-07-06-06-19-21-855'  # g4dn.xlarge, 4 threads\n",
    "# predictor = sagemaker.predictor.Predictor(endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invoking the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "predictor.serializer = JSONSerializer()\n",
    "predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs:  [{'person': [{'text': 'Helios', 'start': 52, 'end': 58, 'probability': 0.9983993172645569}, {'text': 'Selene', 'start': 34, 'end': 40, 'probability': 0.9956828355789185}, {'text': 'Selene', 'start': 97, 'end': 103, 'probability': 0.9991198182106018}, {'text': 'Selene', 'start': 441, 'end': 447, 'probability': 0.9987065196037292}], 'status': [{'text': 'Moon Princess', 'start': 265, 'end': 278, 'probability': 0.7326385974884033}], 'personality': [{'text': 'pure-hearted', 'start': 234, 'end': 246, 'probability': 0.8689507246017456}]}]\n",
      "time: 0.8999683856964111\n"
     ]
    }
   ],
   "source": [
    "texts = [\"After a long discussion about it. Selene's brother, Helios, came up with a compromise. 'Alright, Selene, they shall have a chance for change. For now, you will pair them with their own races, but when the time comes you will choose a pure-hearted female to be your Moon Princess. She will have three mates, one of her own kind and two of different races. If she can bring three races together with her mates, then we will not destroy them.' Selene was happy that her children were given a chance. A chan\"]\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "outputs = predictor.predict(texts)\n",
    "end = time.time()\n",
    "print('outputs: ', outputs)\n",
    "print('time:', end-start)\n",
    "\n",
    "# for i in range(1000):\n",
    "#     start = time.time()\n",
    "#     outputs = predictor.predict(texts)\n",
    "#     end = time.time()\n",
    "#     print('time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean-up\n",
    "\n",
    "Deleting the local endpoint when you're finished is important since you can only run one local endpoint at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.delete_endpoint()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"I wipe whatever tears had trickled down my face, removing my rings from my fingers and clutching them in my hands.\\nThe hallway seems longer than normal but I walk briskly to the office where I find Christian, the elders, the lawyer, Jordan, Derek and Vanessa waiting for me.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
