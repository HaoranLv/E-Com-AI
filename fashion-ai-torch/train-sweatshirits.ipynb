{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c4bf629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64ba7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: openpyxl in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from openpyxl) (1.0.1)\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f7436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "#!mkdir data_0731\n",
    "#!aws s3 cp s3://jackie-test/bumingjueli/data0731/ ./data_0731/ --recursive\n",
    "#!unzip ./data_0731/Sports.zip -d ./data_0731"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe783a8",
   "metadata": {},
   "source": [
    "# data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56b9ba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< predict for keys:  Warm Lined,Details,Type,Composition,Quantity,Belt,Fit Type,Length,Sleeve Length,Pattern Type,Color,Lining,Sleeve Type,Pockets,Sheer,Size Fit,Neckline,Fabric,Material,Hem Shaped,Care Instructions,Body,Arabian Clothing,Style\n",
      "path of ./train_data_sample/Women-Sweatshirts is build\n",
      "train size (150, 33), test size(50, 33)\n"
     ]
    }
   ],
   "source": [
    "#filter not 13 list\n",
    "def get_feature_len(x):\n",
    "    t = json.loads(x)\n",
    "    return len(t)\n",
    "\n",
    "def get_key_list(x):\n",
    "    # get key dictionary\n",
    "    t = json.loads(x)\n",
    "    res = [i for i in list(t.values())]\n",
    "    res = [list(i.keys())[0] for i in res]\n",
    "    return res\n",
    "\n",
    "def get_keys(df):\n",
    "    lst = list(df['feature_dict'])\n",
    "    myList = [x for j in lst for x in j]\n",
    "    res = list(set(myList))\n",
    "    #res_str = ','.join(res)\n",
    "    return res\n",
    "    \n",
    "def map_feature(x,leng):\n",
    "    t = json.loads(x)\n",
    "    for i in range(leng):\n",
    "        if str(i) in t.keys():\n",
    "            continue\n",
    "        else:\n",
    "            t[str(i)] = ''\n",
    "    return t\n",
    "\n",
    "def get_res(x):\n",
    "    try:\n",
    "        a = ast.literal_eval(str(x))\n",
    "        return a\n",
    "    except:\n",
    "        return {'res':'others'}\n",
    "        \n",
    "#map back labels\n",
    "def get_label_txt():\n",
    "    with open('./data/label.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    keys =  [i.split('\\t')[0] for i in lines]\n",
    "    keys_update = [str(int(i)-1) for i in keys]\n",
    "    res = [i.split('\\t')[1][:-1] for i in lines ]\n",
    "    dict_res = dict(zip(keys_update, res))\n",
    "    return dict_res\n",
    "\n",
    "def get_key_value(x,i):\n",
    "#x = df['data'][59335]\n",
    "\n",
    "    t = json.loads(x)\n",
    "\n",
    "    res = [i for i in list(t.values())]\n",
    "    keys = [list(i.keys())[0] for i in res]\n",
    "    values = [list(i.values())[0] for i in res]\n",
    "    dict_res = dict(zip(keys, values))\n",
    "    if i in dict_res.keys():\n",
    "        return dict_res[i]\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "def test_path(x,category):\n",
    "    root_path = os.path.join('/home/ec2-user/SageMaker/bumingjueli/img-cls/data/data_0731',category)\n",
    "    img_name = os.path.join(root_path,str(x)+'.png')\n",
    "    #print ('img_name',img_name)\n",
    "    if os.path.exists(img_name):  \n",
    "        # for local training\n",
    "        #return img_name\n",
    "        # for sagemaker only\n",
    "        img = Image.open(img_name)\n",
    "        if len(img.getbands())==3:\n",
    "            return os.path.join('/opt/ml/input/data/training',str(x)+'.png')\n",
    "        else:\n",
    "            return 'none'\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "def self_mkdir(folder):\n",
    "    isExists = os.path.exists(folder)\n",
    "    if not isExists:\n",
    "        os.makedirs(folder)\n",
    "        print('path of %s is build' % (folder))\n",
    "\n",
    "def copy_files(df,category,output_dir):\n",
    "    for i in df['md5_url']:\n",
    "        copyfile(os.path.join('./data_0731',category,i+'.png'),os.path.join(output_dir,i+'.png'))\n",
    "        \n",
    "        \n",
    "def get_data(path,category,output_dir):\n",
    "    df = pd.read_excel(path,engine=\"openpyxl\")\n",
    "    df = df[df['creg']==category]\n",
    "    #df['feature_len'] = df['data'].map(lambda x: get_feature_len(x))\n",
    "    #leng = max(df['feature_len'])\n",
    "    df['feature_dict'] = df['data'].map(lambda x: get_key_list(x))\n",
    "    res_keys = get_keys(df)\n",
    "    print (\"<<< predict for keys: \", ','.join(res_keys))\n",
    "    \n",
    "    for i in res_keys:\n",
    "        df[i] = df['data'].map(lambda x: get_key_value(x,i))\n",
    "    \n",
    "    #repath\n",
    "    df['image_path'] = df['md5_url'].map(lambda x: test_path(x,category))\n",
    "    df = df[df['image_path']!='none']\n",
    "    \n",
    "    #make dir if not exist\n",
    "    self_mkdir(output_dir)\n",
    "    #save data\n",
    "    df[res_keys].to_csv(os.path.join(output_dir, 'total.csv'),index=False)\n",
    "    \n",
    "    #sample\n",
    "    df = df.head(200)\n",
    "    #copy images\n",
    "    copy_files(df,category,output_dir)\n",
    "    \n",
    "    train, test = train_test_split(df,test_size=0.25,random_state=0)\n",
    "    train.to_csv(os.path.join(output_dir, 'train.csv'))\n",
    "    test.to_csv(os.path.join(output_dir, 'test.csv'))\n",
    "    print (\"train size {}, test size{}\".format(train.shape,test.shape))\n",
    "    \n",
    "    return df\n",
    "\n",
    "category = 'Women-Sweatshirts'\n",
    "output_dir = os.path.join(\"./train_data_sample\",category)\n",
    "df = get_data('./data_0731/shein_info.xlsx',category=category,output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a229a895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train_data_sample/Women-Sweatshirts'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccfc4f6",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "061fd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sess = sage.Session()\n",
    "\n",
    "WORK_DIRECTORY = output_dir\n",
    "\n",
    "# S3 prefix\n",
    "prefix = \"bmjl-train-\"+category\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b27f74dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirts'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66273081",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epoch\":1,\n",
    "    \"batch_size\":4,\n",
    "    \"num_workers\":8,  \n",
    "    'val_epoch':1,\n",
    "    'save_epoch':1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5dfda14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'train_general_sagemaker.py'\n",
    "source_dir = './code'\n",
    "git_config = None\n",
    "role = get_execution_role()\n",
    "framework_version = '1.7.1'\n",
    "py_version='py36'\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#instance_type='local_gpu'\n",
    "instance_count=1\n",
    "volume_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f195a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    "    git_config = git_config,\n",
    "    role = role,\n",
    "    debugger_hook_config=False,\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    instance_type = instance_type,\n",
    "    instance_count = instance_count,\n",
    "    base_job_name = prefix,\n",
    "    volume_size=volume_size,\n",
    "    # Parameters required to enable checkpointing\n",
    "    checkpoint_s3_uri=\"s3://726335585155-sagemaker-us-east-1/bmjl_models\", #使用你自己用来保存/加载模型的s3桶地址, 注意桶需要在us-east-1\n",
    "    checkpoint_local_path=\"/opt/ml/checkpoints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c322989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-10 07:48:47 Starting - Starting the training job...\n",
      "2022-08-10 07:49:14 Starting - Preparing the instances for trainingProfilerReport-1660117727: InProgress\n",
      ".........\n",
      "2022-08-10 07:50:37 Downloading - Downloading input data......\n",
      "2022-08-10 07:51:37 Training - Downloading the training image.................\u001B[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001B[0m\n",
      "\u001B[34mbash: no job control in this shell\u001B[0m\n",
      "\u001B[34m2022-08-10 07:54:26,087 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001B[0m\n",
      "\u001B[34m2022-08-10 07:54:26,110 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001B[0m\n",
      "\u001B[34m2022-08-10 07:54:26,117 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001B[0m\n",
      "\u001B[34m2022-08-10 07:54:26,499 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (3.3.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.19.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (8.2.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.24.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.8.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (4.51.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (2.1.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (3.10.0.0)\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m2022-08-10 07:54:28,636 sagemaker-training-toolkit INFO     Invoking user script\u001B[0m\n",
      "\u001B[34mTraining Env:\u001B[0m\n",
      "\u001B[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch_size\": 4,\n",
      "        \"epoch\": 1,\n",
      "        \"num_workers\": 8,\n",
      "        \"save_epoch\": 1,\n",
      "        \"val_epoch\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"bmjl-train-Women-Sweatshirts-2022-08-10-07-48-46-806\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirts-2022-08-10-07-48-46-806/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_general_sagemaker\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_general_sagemaker.py\"\u001B[0m\n",
      "\u001B[34m}\u001B[0m\n",
      "\u001B[34mEnvironment variables:\u001B[0m\n",
      "\u001B[34mSM_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_NETWORK_INTERFACE_NAME=eth0\u001B[0m\n",
      "\u001B[34mSM_HPS={\"batch_size\":4,\"epoch\":1,\"num_workers\":8,\"save_epoch\":1,\"val_epoch\":1}\u001B[0m\n",
      "\u001B[34mSM_USER_ENTRY_POINT=train_general_sagemaker.py\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_PARAMS={}\u001B[0m\n",
      "\u001B[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001B[0m\n",
      "\u001B[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001B[0m\n",
      "\u001B[34mSM_CHANNELS=[\"training\"]\u001B[0m\n",
      "\u001B[34mSM_CURRENT_HOST=algo-1\u001B[0m\n",
      "\u001B[34mSM_MODULE_NAME=train_general_sagemaker\u001B[0m\n",
      "\u001B[34mSM_LOG_LEVEL=20\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001B[0m\n",
      "\u001B[34mSM_INPUT_DIR=/opt/ml/input\u001B[0m\n",
      "\u001B[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DIR=/opt/ml/output\u001B[0m\n",
      "\u001B[34mSM_NUM_CPUS=8\u001B[0m\n",
      "\u001B[34mSM_NUM_GPUS=1\u001B[0m\n",
      "\u001B[34mSM_MODEL_DIR=/opt/ml/model\u001B[0m\n",
      "\u001B[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirts-2022-08-10-07-48-46-806/source/sourcedir.tar.gz\u001B[0m\n",
      "\u001B[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch_size\":4,\"epoch\":1,\"num_workers\":8,\"save_epoch\":1,\"val_epoch\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"bmjl-train-Women-Sweatshirts-2022-08-10-07-48-46-806\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-726335585155/bmjl-train-Women-Sweatshirts-2022-08-10-07-48-46-806/source/sourcedir.tar.gz\",\"module_name\":\"train_general_sagemaker\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_general_sagemaker.py\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ARGS=[\"--batch_size\",\"4\",\"--epoch\",\"1\",\"--num_workers\",\"8\",\"--save_epoch\",\"1\",\"--val_epoch\",\"1\"]\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001B[0m\n",
      "\u001B[34mSM_HP_BATCH_SIZE=4\u001B[0m\n",
      "\u001B[34mSM_HP_EPOCH=1\u001B[0m\n",
      "\u001B[34mSM_HP_NUM_WORKERS=8\u001B[0m\n",
      "\u001B[34mSM_HP_SAVE_EPOCH=1\u001B[0m\n",
      "\u001B[34mSM_HP_VAL_EPOCH=1\u001B[0m\n",
      "\u001B[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001B[0m\n",
      "\u001B[34mInvoking script with the following command:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.6 train_general_sagemaker.py --batch_size 4 --epoch 1 --num_workers 8 --save_epoch 1 --val_epoch 1\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (3.3.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.19.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (8.2.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.24.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.8.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 7)) (4.51.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (0.10.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->-r requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (2.1.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (3.10.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r requirements.txt (line 5)) (0.8)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\u001B[0m\n",
      "\u001B[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.25.1)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.35.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001B[0m\n",
      "\u001B[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.0.1)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001B[0m\n",
      "\u001B[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001B[0m\n",
      "\u001B[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (3.17.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.10.0-py2.py3-none-any.whl (167 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.16.0)\u001B[0m\n",
      "\u001B[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\u001B[0m\n",
      "\u001B[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001B[0m\n",
      "\u001B[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001B[0m\n",
      "\u001B[34mCollecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001B[0m\n",
      "\u001B[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001B[0m\n",
      "\u001B[34mInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001B[0m\n",
      "\u001B[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\u001B[0m\n",
      "\u001B[34mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 google-auth-2.10.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 importlib-metadata-4.8.3 markdown-3.3.7 oauthlib-3.2.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\u001B[0m\n",
      "\n",
      "2022-08-10 07:54:32 Training - Training image download completed. Training in progress.\u001B[34m<<< num workers:  8\u001B[0m\n",
      "\u001B[34m<<< train key list:  ['Warm Lined', 'Details', 'Type', 'Composition', 'Quantity', 'Belt', 'Fit Type', 'Length', 'Sleeve Length', 'Pattern Type', 'Color', 'Lining', 'Sleeve Type', 'Pockets', 'Sheer', 'Size Fit', 'Neckline', 'Fabric', 'Material', 'Hem Shaped', 'Care Instructions', 'Body', 'Arabian Clothing', 'Style']\u001B[0m\n",
      "\u001B[34m<<< self.key_ls:  ['Warm Lined', 'Details', 'Type', 'Composition', 'Quantity', 'Belt', 'Fit Type', 'Length', 'Sleeve Length', 'Pattern Type', 'Color', 'Lining', 'Sleeve Type', 'Pockets', 'Sheer', 'Size Fit', 'Neckline', 'Fabric', 'Material', 'Hem Shaped', 'Care Instructions', 'Body', 'Arabian Clothing', 'Style']\u001B[0m\n",
      "\u001B[34m<<< self.class_len_ls:  [3, 47, 5, 96, 9, 3, 4, 4, 6, 44, 55, 3, 10, 3, 4, 2, 21, 4, 21, 4, 5, 2, 2, 7]\u001B[0m\n",
      "\u001B[34mStarting training ...\u001B[0m\n",
      "\u001B[34mepoch    1, loss: 23.6148, n_train_samples:   38\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Warm Lined is 0.8070175438596491\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Details is 0.2192982456140351\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Type is 0.6008771929824562\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Composition is 0.35526315789473695\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Quantity is 0.8947368421052632\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Belt is 0.9342105263157895\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Fit Type is 0.6600877192982456\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Length is 0.5043859649122807\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Sleeve Length is 0.8486842105263158\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Pattern Type is 0.25438596491228066\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Color is 0.15789473684210525\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Lining is 0.9802631578947368\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Sleeve Type is 0.6030701754385964\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Pockets is 0.9210526315789473\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Sheer is 0.9539473684210527\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Size Fit is 0.9736842105263158\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Neckline is 0.3881578947368421\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Fabric is 0.557017543859649\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Material is 0.6666666666666666\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Hem Shaped is 0.9605263157894737\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Care Instructions is 0.5701754385964913\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Body is 0.8552631578947368\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Arabian Clothing is 0.9605263157894737\u001B[0m\n",
      "\u001B[34mepoch    1, accuracy for Style is 0.9166666666666665\u001B[0m\n",
      "\u001B[34m------------------------------------------------------------------------\u001B[0m\n",
      "\u001B[34mValidation  loss: 22.0698 \u001B[0m\n",
      "\u001B[34maccuracy for Warm Lined is 0.8846153846153846 \u001B[0m\n",
      "\u001B[34maccuracy for Details is 0.10897435897435896 \u001B[0m\n",
      "\u001B[34maccuracy for Type is 0.6282051282051282 \u001B[0m\n",
      "\u001B[34maccuracy for Composition is 0.3846153846153847 \u001B[0m\n",
      "\u001B[34maccuracy for Quantity is 0.9102564102564101 \u001B[0m\n",
      "\u001B[34maccuracy for Belt is 1.0 \u001B[0m\n",
      "\u001B[34maccuracy for Fit Type is 0.6538461538461539 \u001B[0m\n",
      "\u001B[34maccuracy for Length is 0.5512820512820513 \u001B[0m\n",
      "\u001B[34maccuracy for Sleeve Length is 1.0 \u001B[0m\n",
      "\u001B[34maccuracy for Pattern Type is 0.17948717948717946 \u001B[0m\n",
      "\u001B[34maccuracy for Color is 0.17948717948717946 \u001B[0m\n",
      "\u001B[34maccuracy for Lining is 1.0 \u001B[0m\n",
      "\u001B[34maccuracy for Sleeve Type is 0.6666666666666666 \u001B[0m\n",
      "\u001B[34maccuracy for Pockets is 1.0 \u001B[0m\n",
      "\u001B[34maccuracy for Sheer is 0.9615384615384616 \u001B[0m\n",
      "\u001B[34maccuracy for Size Fit is 1.0 \u001B[0m\n",
      "\u001B[34maccuracy for Neckline is 0.34615384615384615 \u001B[0m\n",
      "\u001B[34maccuracy for Fabric is 0.6025641025641025 \u001B[0m\n",
      "\u001B[34maccuracy for Material is 0.717948717948718 \u001B[0m\n",
      "\u001B[34maccuracy for Hem Shaped is 0.9615384615384616 \u001B[0m\n",
      "\u001B[34maccuracy for Care Instructions is 0.6666666666666666 \u001B[0m\n",
      "\u001B[34maccuracy for Body is 0.9230769230769231 \u001B[0m\n",
      "\u001B[34maccuracy for Arabian Clothing is 1.0 \u001B[0m\n",
      "\u001B[34maccuracy for Style is 0.8461538461538461 \u001B[0m\n",
      "\u001B[34mSaved checkpoint: /opt/ml/model/checkpoint-000001.pth\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m#015  0%|          | 0/38 [00:00<?, ?it/s]#015Epoch 1:   0%|          | 0/38 [00:01<?, ?it/s]#015Epoch 1:   0%|          | 0/38 [00:10<?, ?it/s, loss=47.6]#015Epoch 1:   3%|▎         | 1/38 [00:10<06:45, 10.96s/it, loss=47.6]#015Epoch 1:   3%|▎         | 1/38 [00:10<06:45, 10.96s/it, loss=47.6]#015Epoch 1:   3%|▎         | 1/38 [00:11<06:45, 10.96s/it, loss=37.2]#015Epoch 1:   5%|▌         | 2/38 [00:11<04:41,  7.81s/it, loss=37.2]#015Epoch 1:   5%|▌         | 2/38 [00:11<04:41,  7.81s/it, loss=37.2]#015Epoch 1:   5%|▌         | 2/38 [00:11<04:41,  7.81s/it, loss=32]  #015Epoch 1:   8%|▊         | 3/38 [00:11<03:16,  5.62s/it, loss=32]#015Epoch 1:   8%|▊         | 3/38 [00:11<03:16,  5.62s/it, loss=32]#015Epoch 1:   8%|▊         | 3/38 [00:12<03:16,  5.62s/it, loss=27.8]#015Epoch 1:  11%|█         | 4/38 [00:12<02:18,  4.07s/it, loss=27.8]#015Epoch 1:  11%|█         | 4/38 [00:12<02:18,  4.07s/it, loss=27.8]#015Epoch 1:  11%|█         | 4/38 [00:12<02:18,  4.07s/it, loss=23]  #015Epoch 1:  13%|█▎        | 5/38 [00:12<01:38,  2.98s/it, loss=23]#015Epoch 1:  13%|█▎        | 5/38 [00:12<01:38,  2.98s/it, loss=23]#015Epoch 1:  13%|█▎        | 5/38 [00:13<01:38,  2.98s/it, loss=23]#015Epoch 1:  16%|█▌        | 6/38 [00:13<01:11,  2.22s/it, loss=23]#015Epoch 1:  16%|█▌        | 6/38 [00:13<01:11,  2.22s/it, loss=23]#015Epoch 1:  16%|█▌        | 6/38 [00:13<01:11,  2.22s/it, loss=18.4]#015Epoch 1:  18%|█▊        | 7/38 [00:13<00:52,  1.70s/it, loss=18.4]#015Epoch 1:  18%|█▊        | 7/38 [00:13<00:52,  1.70s/it, loss=18.4]#015Epoch 1:  18%|█▊        | 7/38 [00:14<00:52,  1.70s/it, loss=19.7]#015Epoch 1:  21%|██        | 8/38 [00:14<00:39,  1.32s/it, loss=19.7]#015Epoch 1:  21%|██        | 8/38 [00:14<00:39,  1.32s/it, loss=19.7]#015Epoch 1:  21%|██        | 8/38 [00:14<00:39,  1.32s/it, loss=22.8]#015Epoch 1:  24%|██▎       | 9/38 [00:14<00:30,  1.07s/it, loss=22.8]#015Epoch 1:  24%|██▎       | 9/38 [00:14<00:30,  1.07s/it, loss=22.8]#015Epoch 1:  24%|██▎       | 9/38 [00:15<00:30,  1.07s/it, loss=19.1]#015Epoch 1:  26%|██▋       | 10/38 [00:15<00:25,  1.08it/s, loss=19.1]#015Epoch 1:  26%|██▋       | 10/38 [00:15<00:25,  1.08it/s, loss=19.1]#015Epoch 1:  26%|██▋       | 10/38 [00:15<00:25,  1.08it/s, loss=23.9]#015Epoch 1:  29%|██▉       | 11/38 [00:15<00:21,  1.28it/s, loss=23.9]#015Epoch 1:  29%|██▉       | 11/38 [00:15<00:21,  1.28it/s, loss=23.9]#015Epoch 1:  29%|██▉       | 11/38 [00:16<00:21,  1.28it/s, loss=27]  #015Epoch 1:  32%|███▏      | 12/38 [00:16<00:17,  1.46it/s, loss=27]#015Epoch 1:  32%|███▏      | 12/38 [00:16<00:17,  1.46it/s, loss=27]#015Epoch 1:  32%|███▏      | 12/38 [00:16<00:17,  1.46it/s, loss=29.8]#015Epoch 1:  34%|███▍      | 13/38 [00:16<00:15,  1.64it/s, loss=29.8]#015Epoch 1:  34%|███▍      | 13/38 [00:16<00:15,  1.64it/s, loss=29.8]#015Epoch 1:  34%|███▍      | 13/38 [00:16<00:15,  1.64it/s, loss=19.8]#015Epoch 1:  37%|███▋      | 14/38 [00:17<00:13,  1.79it/s, loss=19.8]#015Epoch 1:  37%|███▋      | 14/38 [00:17<00:13,  1.79it/s, loss=19.8]#015Epoch 1:  37%|███▋      | 14/38 [00:17<00:13,  1.79it/s, loss=24]  #015Epoch 1:  39%|███▉      | 15/38 [00:17<00:11,  1.92it/s, loss=24]#015Epoch 1:  39%|███▉      | 15/38 [00:17<00:11,  1.92it/s, loss=24]#015Epoch 1:  39%|███▉      | 15/38 [00:17<00:11,  1.92it/s, loss=23.3]#015Epoch 1:  42%|████▏     | 16/38 [00:17<00:10,  2.00it/s, loss=23.3]#015Epoch 1:  42%|████▏     | 16/38 [00:17<00:10,  2.00it/s, loss=23.3]#015Epoch 1:  42%|████▏     | 16/38 [00:18<00:10,  2.00it/s, loss=19.4]#015Epoch 1:  45%|████▍     | 17/38 [00:18<00:10,  2.04it/s, loss=19.4]#015Epoch 1:  45%|████▍     | 17/38 [00:18<00:10,  2.04it/s, loss=19.4]#015Epoch 1:  45%|████▍     | 17/38 [00:18<00:10,  2.04it/s, loss=21.2]#015Epoch 1:  47%|████▋     | 18/38 [00:18<00:09,  2.08it/s, loss=21.2]#015Epoch 1:  47%|████▋     | 18/38 [00:18<00:09,  2.08it/s, loss=21.2]#015Epoch 1:  47%|████▋     | 18/38 [00:19<00:09,  2.08it/s, loss=17.1]#015Epoch 1:  50%|█████     | 19/38 [00:19<00:09,  2.10it/s, loss=17.1]#015Epoch 1:  50%|█████     | 19/38 [00:19<00:09,  2.10it/s, loss=17.1]#015Epoch 1:  50%|█████     | 19/38 [00:19<00:09,  2.10it/s, loss=23.7]#015Epoch 1:  53%|█████▎    | 20/38 [00:19<00:08,  2.11it/s, loss=23.7]#015Epoch 1:  53%|█████▎    | 20/38 [00:19<00:08,  2.11it/s, loss=23.7]#015Epoch 1:  53%|█████▎    | 20/38 [00:20<00:08,  2.11it/s, loss=22.3]#015Epoch 1:  55%|█████▌    | 21/38 [00:20<00:08,  2.11it/s, loss=22.3]#015Epoch 1:  55%|█████▌    | 21/38 [00:20<00:08,  2.11it/s, loss=22.3]#015Epoch 1:  55%|█████▌    | 21/38 [00:20<00:08,  2.11it/s, loss=21.6]#015Epoch 1:  58%|█████▊    | 22/38 [00:20<00:07,  2.12it/s, loss=21.6]#015Epoch 1:  58%|█████▊    | 22/38 [00:20<00:07,  2.12it/s, loss=21.6]#015Epoch 1:  58%|█████▊    | 22/38 [00:21<00:07,  2.12it/s, loss=17.8]#015Epoch 1:  61%|██████    | 23/38 [00:21<00:07,  2.13it/s, loss=17.8]#015Epoch 1:  61%|██████    | 23/38 [00:21<00:07,  2.13it/s, loss=17.8]#015Epoch 1:  61%|██████    | 23/38 [00:21<00:07,  2.13it/s, loss=22.7]#015Epoch 1:  63%|██████▎   | 24/38 [00:21<00:06,  2.17it/s, loss=22.7]#015Epoch 1:  63%|██████▎   | 24/38 [00:21<00:06,  2.17it/s, loss=22.7]#015Epoch 1:  63%|██████▎   | 24/38 [00:21<00:06,  2.17it/s, loss=24.7]#015Epoch 1:  66%|██████▌   | 25/38 [00:22<00:05,  2.21it/s, loss=24.7]#015Epoch 1:  66%|██████▌   | 25/38 [00:22<00:05,  2.21it/s, loss=24.7]#015Epoch 1:  66%|██████▌   | 25/38 [00:22<00:05,  2.21it/s, loss=26.2]#015Epoch 1:  68%|██████▊   | 26/38 [00:22<00:05,  2.24it/s, loss=26.2]#015Epoch 1:  68%|██████▊   | 26/38 [00:22<00:05,  2.24it/s, loss=26.2]#015Epoch 1:  68%|██████▊   | 26/38 [00:22<00:05,  2.24it/s, loss=20.8]#015Epoch 1:  71%|███████   | 27/38 [00:22<00:04,  2.26it/s, loss=20.8]#015Epoch 1:  71%|███████   | 27/38 [00:22<00:04,  2.26it/s, loss=20.8]#015Epoch 1:  71%|███████   | 27/38 [00:23<00:04,  2.26it/s, loss=28]  #015Epoch 1:  74%|███████▎  | 28/38 [00:23<00:04,  2.27it/s, loss=28]#015Epoch 1:  74%|███████▎  | 28/38 [00:23<00:04,  2.27it/s, loss=28]#015Epoch 1:  74%|███████▎  | 28/38 [00:23<00:04,  2.27it/s, loss=20.5]#015Epoch 1:  76%|███████▋  | 29/38 [00:23<00:03,  2.28it/s, loss=20.5]#015Epoch 1:  76%|███████▋  | 29/38 [00:23<00:03,  2.28it/s, loss=20.5]#015Epoch 1:  76%|███████▋  | 29/38 [00:24<00:03,  2.28it/s, loss=21.9]#015Epoch 1:  79%|███████▉  | 30/38 [00:24<00:03,  2.30it/s, loss=21.9]#015Epoch 1:  79%|███████▉  | 30/38 [00:24<00:03,  2.30it/s, loss=21.9]#015Epoch 1:  79%|███████▉  | 30/38 [00:24<00:03,  2.30it/s, loss=20.1]#015Epoch 1:  82%|████████▏ | 31/38 [00:24<00:03,  2.30it/s, loss=20.1]#015Epoch 1:  82%|████████▏ | 31/38 [00:24<00:03,  2.30it/s, loss=20.1]#015Epoch 1:  82%|████████▏ | 31/38 [00:24<00:03,  2.30it/s, loss=23.4]#015Epoch 1:  84%|████████▍ | 32/38 [00:25<00:02,  2.31it/s, loss=23.4]#015Epoch 1:  84%|████████▍ | 32/38 [00:25<00:02,  2.31it/s, loss=23.4]#015Epoch 1:  84%|████████▍ | 32/38 [00:25<00:02,  2.31it/s, loss=20.4]#015Epoch 1:  87%|████████▋ | 33/38 [00:25<00:02,  2.31it/s, loss=20.4]#015Epoch 1:  87%|████████▋ | 33/38 [00:25<00:02,  2.31it/s, loss=20.4]#015Epoch 1:  87%|████████▋ | 33/38 [00:25<00:02,  2.31it/s, loss=18.5]#015Epoch 1:  89%|████████▉ | 34/38 [00:25<00:01,  2.31it/s, loss=18.5]#015Epoch 1:  89%|████████▉ | 34/38 [00:25<00:01,  2.31it/s, loss=18.5]#015Epoch 1:  89%|████████▉ | 34/38 [00:26<00:01,  2.31it/s, loss=21]  #015Epoch 1:  92%|█████████▏| 35/38 [00:26<00:01,  2.31it/s, loss=21]#015Epoch 1:  92%|█████████▏| 35/38 [00:26<00:01,  2.31it/s, loss=21]#015Epoch 1:  92%|█████████▏| 35/38 [00:26<00:01,  2.31it/s, loss=19.4]#015Epoch 1:  95%|█████████▍| 36/38 [00:26<00:00,  2.29it/s, loss=19.4]#015Epoch 1:  95%|█████████▍| 36/38 [00:26<00:00,  2.29it/s, loss=19.4]#015Epoch 1:  95%|█████████▍| 36/38 [00:27<00:00,  2.29it/s, loss=26.1]#015Epoch 1:  97%|█████████▋| 37/38 [00:27<00:00,  2.27it/s, loss=26.1]#015Epoch 1:  97%|█████████▋| 37/38 [00:27<00:00,  2.27it/s, loss=26.1]#015Epoch 1:  97%|█████████▋| 37/38 [00:27<00:00,  2.27it/s, loss=22.3]#015Epoch 1: 100%|██████████| 38/38 [00:27<00:00,  2.48it/s, loss=22.3]#015Epoch 1: 100%|██████████| 38/38 [00:27<00:00,  1.38it/s, loss=22.3]\u001B[0m\n",
      "\u001B[34m2022-08-10 07:55:17,256 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001B[0m\n",
      "\n",
      "2022-08-10 07:55:34 Uploading - Uploading generated training model\n",
      "2022-08-10 07:55:34 Completed - Training job completed\n",
      "Training seconds: 297\n",
      "Billable seconds: 297\n"
     ]
    }
   ],
   "source": [
    "response = estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162706a4",
   "metadata": {},
   "source": [
    "# endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61be6e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "s3_model = estimator.model_data \n",
    "#s3_model = \"s3://sagemaker-us-east-1-726335585155/bmjl-train-Bottoms-2022-08-08-10-34-18-585/output/model.tar.gz\"\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=s3_model, \n",
    "                             role=role,\n",
    "                             entry_point='inference.py', \n",
    "                             source_dir='./code', \n",
    "                             framework_version='1.7.1', \n",
    "                             py_version='py36'\n",
    "                ) # TODO set model_server_workers=1 to avoid torchhub bug\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec2cc58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from boto3.session import Session\n",
    "\n",
    "session = Session()\n",
    "runtime = session.client(\"runtime.sagemaker\")\n",
    "\n",
    "with open('train_data/Women-Bottoms/00017534ec95a66ab3518dc71bbc970d.html.png', \"rb\") as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    \n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName='pytorch-inference-2022-08-10-08-15-19-340', ContentType=\"application/x-image\", Body=payload\n",
    ")\n",
    "\n",
    "result = response[\"Body\"].read()\n",
    "# result will be in json format and convert it to ndarray\n",
    "result = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "130e5044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': {'Warm Lined': 'other',\n",
       "  'Details': 'Zipper',\n",
       "  'Type': 'Pullovers',\n",
       "  'Composition': '100% Polyester',\n",
       "  'Quantity': '1 piece',\n",
       "  'Belt': 'other',\n",
       "  'Fit Type': 'Regular Fit',\n",
       "  'Length': 'Regular',\n",
       "  'Sleeve Length': 'Long Sleeve',\n",
       "  'Pattern Type': 'Plain',\n",
       "  'Color': 'Black',\n",
       "  'Lining': 'other',\n",
       "  'Sleeve Type': 'Drop Shoulder',\n",
       "  'Pockets': 'other',\n",
       "  'Sheer': 'No',\n",
       "  'Size Fit': 'other',\n",
       "  'Neckline': 'Hooded',\n",
       "  'Fabric': 'Slight Stretch',\n",
       "  'Material': 'Polyester',\n",
       "  'Hem Shaped': 'other',\n",
       "  'Care Instructions': 'Machine wash or professional dry clean',\n",
       "  'Body': 'other',\n",
       "  'Arabian Clothing': 'other',\n",
       "  'Style': 'Casual'}}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb01fc3",
   "metadata": {},
   "source": [
    "# batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fc313e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input S3 path: s3://sagemaker-us-east-1-726335585155/batch_transform\n"
     ]
    }
   ],
   "source": [
    "image_dir = './test'\n",
    "inference_prefix = \"batch_transform\"\n",
    "inference_inputs = sess.upload_data(\n",
    "    path=image_dir, key_prefix=inference_prefix\n",
    ")\n",
    "print(\"Input S3 path: {}\".format(inference_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67356eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transformer from PyTorchModel object\n",
    "transformer = pytorch_model.transformer(instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4321a117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................\n",
      "\u001B[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 1)) (3.3.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 2)) (1.19.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 3)) (8.4.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 4)) (0.21.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 5)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 6)) (0.8.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 7)) (4.62.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (1.3.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (0.11.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.3.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (4.0.0)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 1)) (3.3.4)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 2)) (1.19.1)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: pillow in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 3)) (8.4.0)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 4)) (0.21.2)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 5)) (1.7.1)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: torchvision in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 6)) (0.8.2)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 7)) (4.62.3)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8.2)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (1.3.1)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (0.11.0)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.3.0)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->-r /opt/ml/model/code/requirements.txt (line 4)) (1.0.1)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (0.8)\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch->-r /opt/ml/model/code/requirements.txt (line 5)) (4.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,084 [INFO ] main org.pytorch.serve.ModelServer - \u001B[0m\n",
      "\u001B[34mTorchserve version: 0.3.1\u001B[0m\n",
      "\u001B[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001B[0m\n",
      "\u001B[34mCurrent directory: /\u001B[0m\n",
      "\u001B[34mTemp directory: /home/model-server/tmp\u001B[0m\n",
      "\u001B[34mNumber of GPUs: 0\u001B[0m\n",
      "\u001B[34mNumber of CPUs: 4\u001B[0m\n",
      "\u001B[34mMax heap size: 2950 M\u001B[0m\n",
      "\u001B[34mPython executable: /opt/conda/bin/python3.6\u001B[0m\n",
      "\u001B[34mConfig file: /etc/sagemaker-ts.properties\u001B[0m\n",
      "\u001B[34mInference address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34mManagement address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34mMetrics address: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[34mModel Store: /.sagemaker/ts/models\u001B[0m\n",
      "\u001B[34mInitial Models: model.mar\u001B[0m\n",
      "\u001B[34mLog dir: /logs\u001B[0m\n",
      "\u001B[34mMetrics dir: /logs\u001B[0m\n",
      "\u001B[34mNetty threads: 0\u001B[0m\n",
      "\u001B[34mNetty client threads: 0\u001B[0m\n",
      "\u001B[34mDefault workers per model: 4\u001B[0m\n",
      "\u001B[34mBlacklist Regex: N/A\u001B[0m\n",
      "\u001B[34mMaximum Response Size: 6553500\u001B[0m\n",
      "\u001B[34mMaximum Request Size: 6553500\u001B[0m\n",
      "\u001B[34mPrefer direct buffer: false\u001B[0m\n",
      "\u001B[34mAllowed Urls: [file://.*|http(s)?://.*]\u001B[0m\n",
      "\u001B[34mCustom python dependency for model allowed: false\u001B[0m\n",
      "\u001B[34mMetrics report format: prometheus\u001B[0m\n",
      "\u001B[34mEnable metrics API: true\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,125 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,454 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag e7ee78ee13834363b08b0a433df33154\u001B[0m\n",
      "\u001B[35mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib->-r /opt/ml/model/code/requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,084 [INFO ] main org.pytorch.serve.ModelServer - \u001B[0m\n",
      "\u001B[35mTorchserve version: 0.3.1\u001B[0m\n",
      "\u001B[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001B[0m\n",
      "\u001B[35mCurrent directory: /\u001B[0m\n",
      "\u001B[35mTemp directory: /home/model-server/tmp\u001B[0m\n",
      "\u001B[35mNumber of GPUs: 0\u001B[0m\n",
      "\u001B[35mNumber of CPUs: 4\u001B[0m\n",
      "\u001B[35mMax heap size: 2950 M\u001B[0m\n",
      "\u001B[35mPython executable: /opt/conda/bin/python3.6\u001B[0m\n",
      "\u001B[35mConfig file: /etc/sagemaker-ts.properties\u001B[0m\n",
      "\u001B[35mInference address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[35mManagement address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[35mMetrics address: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[35mModel Store: /.sagemaker/ts/models\u001B[0m\n",
      "\u001B[35mInitial Models: model.mar\u001B[0m\n",
      "\u001B[35mLog dir: /logs\u001B[0m\n",
      "\u001B[35mMetrics dir: /logs\u001B[0m\n",
      "\u001B[35mNetty threads: 0\u001B[0m\n",
      "\u001B[35mNetty client threads: 0\u001B[0m\n",
      "\u001B[35mDefault workers per model: 4\u001B[0m\n",
      "\u001B[35mBlacklist Regex: N/A\u001B[0m\n",
      "\u001B[35mMaximum Response Size: 6553500\u001B[0m\n",
      "\u001B[35mMaximum Request Size: 6553500\u001B[0m\n",
      "\u001B[35mPrefer direct buffer: false\u001B[0m\n",
      "\u001B[35mAllowed Urls: [file://.*|http(s)?://.*]\u001B[0m\n",
      "\u001B[35mCustom python dependency for model allowed: false\u001B[0m\n",
      "\u001B[35mMetrics report format: prometheus\u001B[0m\n",
      "\u001B[35mEnable metrics API: true\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,125 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,454 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag e7ee78ee13834363b08b0a433df33154\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,467 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,502 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,772 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]58\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,779 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,779 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,781 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,803 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,806 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]60\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,806 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,806 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,807 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,807 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,813 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]56\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,814 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,818 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,830 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]57\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,830 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,831 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,851 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,851 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,851 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:58,853 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,467 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,502 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,772 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]58\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,779 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,779 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,781 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,803 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,806 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]60\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,806 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,806 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,807 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,807 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,813 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]56\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,814 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,818 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,830 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]57\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,830 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,831 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,851 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,851 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,851 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:58,853 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001B[0m\n",
      "\u001B[34mModel server started.\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:59,606 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:59,609 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.03485870361328|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:59,610 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.830272674560547|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:59,611 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.0|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:59,612 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14165.2890625|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:59,613 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1081.95703125|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[34m2022-08-10 08:58:59,613 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:9.1|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[35mModel server started.\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:59,606 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:59,609 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:48.03485870361328|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:59,610 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:7.830272674560547|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:59,611 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.0|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:59,612 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14165.2890625|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:59,613 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1081.95703125|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[35m2022-08-10 08:58:59,613 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:9.1|#Level:Host|#hostname:ddc095260043,timestamp:1660121939\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1736\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,721 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:2223|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1736\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,721 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:2223|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,722 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:114|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,744 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1742\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,745 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:2247|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,745 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:131|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,877 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1875\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,877 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:2394|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,877 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:130|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,884 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1882\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,884 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:2394|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:00,884 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:130|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,722 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:114|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,744 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1742\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,745 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:2247|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,745 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:131|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,877 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1875\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,877 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:2394|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,877 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:130|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,884 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1882\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,884 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:2394|#Level:Host|#hostname:ddc095260043,timestamp:1660121940\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:00,884 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:130|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:03,036 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:53106 \"GET /ping HTTP/1.1\" 200 13\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:03,037 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:03,036 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:53106 \"GET /ping HTTP/1.1\" 200 13\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:03,037 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:03,056 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:53108 \"GET /execution-parameters HTTP/1.1\" 404 1\u001B[0m\n",
      "\u001B[34m2022-08-10 08:59:03,056 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:03,056 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:53108 \"GET /execution-parameters HTTP/1.1\" 404 1\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:03,056 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[32m2022-08-10T08:59:03.063:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,886 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,886 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2670\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,886 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.key_ls:  ['Warm Lined', 'Details', 'Type', 'Composition', 'Quantity', 'Belt', 'Fit Type', 'Length', 'Sleeve Length', 'Pattern Type', 'Color', 'Lining', 'Sleeve Type', 'Pockets', 'Sheer', 'Size Fit', 'Neckline', 'Fabric', 'Material', 'Hem Shaped', 'Care Instructions', 'Body', 'Arabian Clothing', 'Style']\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,886 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.class_len_ls:  [3, 47, 5, 96, 9, 3, 4, 4, 6, 44, 55, 3, 10, 3, 4, 2, 21, 4, 21, 4, 5, 2, 2, 7]\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,886 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53124 \"POST /invocations HTTP/1.1\" 200 2677\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,886 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2668.95|#ModelName:model,Level:Model|#hostname:ddc095260043,requestID:160c994b-5ed0-4e26-914b-ead18cdda2a4,timestamp:1660121945\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,887 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,887 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:05,887 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,483 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2531\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53124 \"POST /invocations HTTP/1.1\" 200 2534\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/checkpoint-000001.pth']\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.key_ls:  ['Warm Lined', 'Details', 'Type', 'Composition', 'Quantity', 'Belt', 'Fit Type', 'Length', 'Sleeve Length', 'Pattern Type', 'Color', 'Lining', 'Sleeve Type', 'Pockets', 'Sheer', 'Size Fit', 'Neckline', 'Fabric', 'Material', 'Hem Shaped', 'Care Instructions', 'Body', 'Arabian Clothing', 'Style']\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<< self.class_len_ls:  [3, 47, 5, 96, 9, 3, 4, 4, 6, 44, 55, 3, 10, 3, 4, 2, 21, 4, 21, 4, 5, 2, 2, 7]\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:ddc095260043,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-10 08:59:08,484 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2530.23|#ModelName:model,Level:Model|#hostname:ddc095260043,requestID:12b419a0-597b-4506-830e-557e16afe416,timestamp:1660121948\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(\n",
    "    data=inference_inputs,\n",
    "    data_type=\"S3Prefix\",\n",
    "    content_type=\"application/x-image\",\n",
    "    wait=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "681380f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 8, 10, 8, 54, 8, 975000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2022, 8, 10, 8, 59, 9, 644000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 10, 8, 59, 9, 265000, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-10-08-54-08-963',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-10-08-54-08-963',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2020, 1, 7, 8, 6, 7, 55000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2020, 1, 7, 8, 11, 17, 354000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2020, 1, 7, 8, 11, 17, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/image-classification-model-2020-01-07-08-06-02',\n",
      " 'TransformJobName': 'image-classification-model-2020-01-07-08-06-02',\n",
      " 'TransformJobStatus': 'Completed'}\n",
      "{'CreationTime': datetime.datetime(2020, 1, 7, 7, 41, 38, 806000, tzinfo=tzlocal()),\n",
      " 'FailureReason': 'ClientError: See job logs for more information',\n",
      " 'LastModifiedTime': datetime.datetime(2020, 1, 7, 7, 46, 43, 466000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2020, 1, 7, 7, 46, 43, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/image-classification-model-2020-01-07-07-41-18',\n",
      " 'TransformJobName': 'image-classification-model-2020-01-07-07-41-18',\n",
      " 'TransformJobStatus': 'Failed'}\n",
      "{'CreationTime': datetime.datetime(2020, 1, 6, 8, 16, 47, 650000, tzinfo=tzlocal()),\n",
      " 'LastModifiedTime': datetime.datetime(2020, 1, 6, 8, 22, 33, 342000, tzinfo=tzlocal()),\n",
      " 'TransformEndTime': datetime.datetime(2020, 1, 6, 8, 22, 33, tzinfo=tzlocal()),\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/image-classification-model-2020-01-06-08-16-45',\n",
      " 'TransformJobName': 'image-classification-model-2020-01-06-08-16-45',\n",
      " 'TransformJobStatus': 'Completed'}\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "sm_cli = sess.sagemaker_client\n",
    "\n",
    "transform_jobs = sm_cli.list_transform_jobs()[\"TransformJobSummaries\"]\n",
    "for job in transform_jobs:\n",
    "    pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "42ffee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CreationTime': datetime.datetime(2022, 8, 10, 8, 54, 8, 975000, tzinfo=tzlocal()),\n",
      " 'DataProcessing': {'InputFilter': '$',\n",
      "                    'JoinSource': 'None',\n",
      "                    'OutputFilter': '$'},\n",
      " 'ModelName': 'pytorch-inference-2022-08-10-08-54-07-174',\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '895',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Wed, 10 Aug 2022 09:03:53 GMT',\n",
      "                                      'x-amzn-requestid': 'c11b8ac6-4177-452f-a12d-10a3e75bac68'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': 'c11b8ac6-4177-452f-a12d-10a3e75bac68',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TransformEndTime': datetime.datetime(2022, 8, 10, 8, 59, 9, 265000, tzinfo=tzlocal()),\n",
      " 'TransformInput': {'CompressionType': 'None',\n",
      "                    'ContentType': 'application/x-image',\n",
      "                    'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
      "                                                    'S3Uri': 's3://sagemaker-us-east-1-726335585155/batch_transform'}},\n",
      "                    'SplitType': 'None'},\n",
      " 'TransformJobArn': 'arn:aws:sagemaker:us-east-1:726335585155:transform-job/pytorch-inference-2022-08-10-08-54-08-963',\n",
      " 'TransformJobName': 'pytorch-inference-2022-08-10-08-54-08-963',\n",
      " 'TransformJobStatus': 'Completed',\n",
      " 'TransformOutput': {'AssembleWith': 'None',\n",
      "                     'KmsKeyId': '',\n",
      "                     'S3OutputPath': 's3://sagemaker-us-east-1-726335585155/pytorch-inference-2022-08-10-08-54-08-963'},\n",
      " 'TransformResources': {'InstanceCount': 1, 'InstanceType': 'ml.m5.xlarge'},\n",
      " 'TransformStartTime': datetime.datetime(2022, 8, 10, 8, 57, 37, 564000, tzinfo=tzlocal())}\n"
     ]
    }
   ],
   "source": [
    "job_info = sm_cli.describe_transform_job(\n",
    "    TransformJobName=transformer.latest_transform_job.name\n",
    ")\n",
    "\n",
    "pp.pprint(job_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdcaf93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-726335585155 pytorch-inference-2022-08-10-08-54-08-963\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def get_bucket_and_prefix(s3_output_path):\n",
    "    trim = re.sub(\"s3://\", \"\", s3_output_path)\n",
    "    bucket, prefix = trim.split(\"/\")\n",
    "    return bucket, prefix\n",
    "\n",
    "\n",
    "local_path = \"output\"  # Where to save the output locally\n",
    "\n",
    "bucket, output_prefix = get_bucket_and_prefix(job_info[\"TransformOutput\"][\"S3OutputPath\"])\n",
    "print(bucket, output_prefix)\n",
    "\n",
    "sess.download_data(path=local_path, bucket=bucket, key_prefix=output_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4578e66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': {'Warm Lined': 'other', 'Details': 'Zipper', 'Type': 'Pullovers', 'Composition': '100% Polyester', 'Quantity': '1 piece', 'Belt': 'other', 'Fit Type': 'Regular Fit', 'Length': 'Regular', 'Sleeve Length': 'Long Sleeve', 'Pattern Type': 'Plain', 'Color': 'Black', 'Lining': 'other', 'Sleeve Type': 'Drop Shoulder', 'Pockets': 'other', 'Sheer': 'No', 'Size Fit': 'other', 'Neckline': 'Hooded', 'Fabric': 'Slight Stretch', 'Material': 'Polyester', 'Hem Shaped': 'other', 'Care Instructions': 'Machine wash or professional dry clean', 'Body': 'other', 'Arabian Clothing': 'other', 'Style': 'Casual'}}\n",
      "{'result': {'Warm Lined': 'other', 'Details': 'Zipper', 'Type': 'Pullovers', 'Composition': '100% Polyester', 'Quantity': '1 piece', 'Belt': 'other', 'Fit Type': 'Regular Fit', 'Length': 'Regular', 'Sleeve Length': 'Long Sleeve', 'Pattern Type': 'Plain', 'Color': 'Black', 'Lining': 'other', 'Sleeve Type': 'Drop Shoulder', 'Pockets': 'other', 'Sheer': 'No', 'Size Fit': 'other', 'Neckline': 'Hooded', 'Fabric': 'Slight Stretch', 'Material': 'Polyester', 'Hem Shaped': 'other', 'Care Instructions': 'Machine wash or professional dry clean', 'Body': 'other', 'Arabian Clothing': 'other', 'Style': 'Casual'}}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import json\n",
    "\n",
    "for f in os.listdir(local_path):\n",
    "    path = os.path.join(local_path, f)\n",
    "    with open(path, \"r\") as f:\n",
    "        pred = json.load(f)\n",
    "        print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24705cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}