{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8564fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4c8f899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: openpyxl in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from openpyxl) (1.0.1)\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d483f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data\n",
    "#!mkdir data_0731\n",
    "#!aws s3 cp s3://jackie-test/bumingjueli/data0731/ ./data_0731/ --recursive\n",
    "#!unzip ./data_0731/Sports.zip -d ./data_0731"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121f2a2",
   "metadata": {},
   "source": [
    "# data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15d0bb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< predict for keys:  Pockets,Lining,Sheer,Pattern Type,Neckline,Chest pad,Sleeve Type,Length,Fabric,Support,Fit Type,Belt,Waterproof,Quantity,Details,Number of Pieces,Filling,Sleeve Length,Care Instructions,Warm Lined,Panty Type,Color,Features,Bra Type,Activity,Type,Body,Composition,Material,Waist Line\n",
      "train size (4975, 39), test size(1659, 39)\n"
     ]
    }
   ],
   "source": [
    "#filter not 13 list\n",
    "def get_feature_len(x):\n",
    "    t = json.loads(x)\n",
    "    return len(t)\n",
    "\n",
    "def get_key_list(x):\n",
    "    # get key dictionary\n",
    "    t = json.loads(x)\n",
    "    res = [i for i in list(t.values())]\n",
    "    res = [list(i.keys())[0] for i in res]\n",
    "    return res\n",
    "\n",
    "def get_keys(df):\n",
    "    lst = list(df['feature_dict'])\n",
    "    myList = [x for j in lst for x in j]\n",
    "    res = list(set(myList))\n",
    "    #res_str = ','.join(res)\n",
    "    return res\n",
    "    \n",
    "def map_feature(x,leng):\n",
    "    t = json.loads(x)\n",
    "    for i in range(leng):\n",
    "        if str(i) in t.keys():\n",
    "            continue\n",
    "        else:\n",
    "            t[str(i)] = ''\n",
    "    return t\n",
    "\n",
    "def get_res(x):\n",
    "    try:\n",
    "        a = ast.literal_eval(str(x))\n",
    "        return a\n",
    "    except:\n",
    "        return {'res':'others'}\n",
    "        \n",
    "#map back labels\n",
    "def get_label_txt():\n",
    "    with open('./data/label.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    keys =  [i.split('\\t')[0] for i in lines]\n",
    "    keys_update = [str(int(i)-1) for i in keys]\n",
    "    res = [i.split('\\t')[1][:-1] for i in lines ]\n",
    "    dict_res = dict(zip(keys_update, res))\n",
    "    return dict_res\n",
    "\n",
    "def get_key_value(x,i):\n",
    "#x = df['data'][59335]\n",
    "\n",
    "    t = json.loads(x)\n",
    "\n",
    "    res = [i for i in list(t.values())]\n",
    "    keys = [list(i.keys())[0] for i in res]\n",
    "    values = [list(i.values())[0] for i in res]\n",
    "    dict_res = dict(zip(keys, values))\n",
    "    if i in dict_res.keys():\n",
    "        return dict_res[i]\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "\n",
    "def test_path(x,category):\n",
    "    root_path = os.path.join('/home/ec2-user/SageMaker/bumingjueli/img-cls/data/data_0731',category)\n",
    "    img_name = os.path.join(root_path,str(x)+'.png')\n",
    "    #print ('img_name',img_name)\n",
    "    if os.path.exists(img_name):  \n",
    "        # for local training\n",
    "        #return img_name\n",
    "        # for sagemaker only\n",
    "        img = Image.open(img_name)\n",
    "        if len(img.getbands())==3:\n",
    "            return os.path.join('/opt/ml/input/data/training',str(x)+'.png')\n",
    "        else:\n",
    "            return 'none'\n",
    "    else:\n",
    "        return 'none'\n",
    "def self_mkdir(folder):\n",
    "    isExists = os.path.exists(folder)\n",
    "    if not isExists:\n",
    "        os.makedirs(folder)\n",
    "        print('path of %s is build' % (folder))\n",
    "\n",
    "def copy_files(df,category,output_dir):\n",
    "    for i in df['md5_url']:\n",
    "        copyfile(os.path.join('./data_0731',category,i+'.png'),os.path.join(output_dir,i+'.png'))\n",
    "        \n",
    "        \n",
    "def get_data(path,category,output_dir):\n",
    "    df = pd.read_excel(path,engine=\"openpyxl\")\n",
    "    df = df[df['creg']==category]\n",
    "    #df['feature_len'] = df['data'].map(lambda x: get_feature_len(x))\n",
    "    #leng = max(df['feature_len'])\n",
    "    df['feature_dict'] = df['data'].map(lambda x: get_key_list(x))\n",
    "    res_keys = get_keys(df)\n",
    "    print (\"<<< predict for keys: \", ','.join(res_keys))\n",
    "    \n",
    "    for i in res_keys:\n",
    "        df[i] = df['data'].map(lambda x: get_key_value(x,i))\n",
    "    \n",
    "    #repath\n",
    "    df['image_path'] = df['md5_url'].map(lambda x: test_path(x,category))\n",
    "    df = df[df['image_path']!='none']\n",
    "    \n",
    "    #make dir if not exist\n",
    "    self_mkdir(output_dir)\n",
    "    #save data\n",
    "    df[res_keys].to_csv(os.path.join(output_dir, 'total.csv'),index=False)\n",
    "    \n",
    "    #sample\n",
    "    #df = df.head(20)\n",
    "    #copy images\n",
    "    copy_files(df,category,output_dir)\n",
    "    \n",
    "    train, test = train_test_split(df,test_size=0.25,random_state=0)\n",
    "    train.to_csv(os.path.join(output_dir, 'train.csv'))\n",
    "    test.to_csv(os.path.join(output_dir, 'test.csv'))\n",
    "    print (\"train size {}, test size{}\".format(train.shape,test.shape))\n",
    "    \n",
    "    return df\n",
    "\n",
    "category = 'Women-Sweatshirts'\n",
    "output_dir = os.path.join(\"./train_data\",category)\n",
    "df = get_data('./data_0731/shein_info.xlsx',category=category,output_dir = output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae7c4c",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "sess = sage.Session()\n",
    "\n",
    "WORK_DIRECTORY = output_dir\n",
    "\n",
    "# S3 prefix\n",
    "prefix = \"bmjl-train-\"+category\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f424ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"epoch\":50,\n",
    "    \"batch_size\":4,\n",
    "    \"num_workers\":8,\n",
    "    'val_epoch':1,\n",
    "    'save_epoch':10,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d365a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'train_general_sagemaker.py'\n",
    "source_dir = './code'\n",
    "git_config = None\n",
    "role = get_execution_role()\n",
    "framework_version = '1.7.1'\n",
    "py_version='py36'\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#instance_type='local_gpu'\n",
    "instance_count=1\n",
    "volume_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    "    git_config = git_config,\n",
    "    role = role,\n",
    "    debugger_hook_config=False,\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    instance_type = instance_type,\n",
    "    instance_count = instance_count,\n",
    "    base_job_name = base_job_name,\n",
    "    volume_size=volume_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57fafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = estimator.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092ac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}