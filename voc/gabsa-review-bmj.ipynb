{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f292507b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "import pandas as pd\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8873454b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting mendelai-brat-parser\n",
      "  Downloading mendelai_brat_parser-0.0.11.tar.gz (4.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25hBuilding wheels for collected packages: mendelai-brat-parser\n",
      "  Building wheel for mendelai-brat-parser (setup.py) ... \u001B[?25ldone\n",
      "\u001B[?25h  Created wheel for mendelai-brat-parser: filename=mendelai_brat_parser-0.0.11-py3-none-any.whl size=4945 sha256=d061dc3c5fb289b982388241b9abadd4b2c7fe53234b2b74bc98597d39c0b48d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/90/a7/ff/138853d8196095fec56e0a97779a96d754b98f169c063beca3\n",
      "Successfully built mendelai-brat-parser\n",
      "Installing collected packages: mendelai-brat-parser\n",
      "Successfully installed mendelai-brat-parser-0.0.11\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install mendelai-brat-parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386c4d0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585ef1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process for (aspect, category)\n",
      "a_list: ['feelings', 'expectancy', 'color', 'scene', 'purchase_behavior', 'size', 'design', 'price', 'fabric', 'style', 'audiences', 'quality', 'type', 'collocation', 'delivery']\n",
      "finished process, result save to:  ./label_data/good/aspect_category.csv\n"
     ]
    }
   ],
   "source": [
    "! python data_prepare_bmjl.py\\\n",
    "--label_dir './label_data/good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e4d2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process for (aspect, category)\n",
      "a_list: ['size', 'scene', 'design', 'feelings', 'fabric', 'purchase_behavior', 'audiences', 'color', 'quality', 'type', 'price', 'style', 'collocation', 'expectancy', 'delivery']\n",
      "finished process, result save to:  ./label_data/bad/aspect_category.csv\n"
     ]
    }
   ],
   "source": [
    "! python data_prepare_bmjl.py\\\n",
    "--label_dir './label_data/bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b5600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data\n",
    "good = './label_data/good/aspect_category.csv'\n",
    "bad = './label_data/bad/aspect_category.csv'\n",
    "df1 = pd.read_csv(good)\n",
    "df2 = pd.read_csv(bad)\n",
    "df_res = pd.concat([df1,df2])\n",
    "df_res.to_csv('./aspect_category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d8d9c8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1  sent_num  \\\n",
      "0           0             0         0   \n",
      "1           1             0         0   \n",
      "2           2             0         0   \n",
      "3           3             0         0   \n",
      "4           4             0         0   \n",
      "\n",
      "                                                text  sent_start  sent_end  \\\n",
      "0  I like the shorts. They're comfortable. But I ...           0       313   \n",
      "1  Absolutely love these shorts! The green color ...           0       215   \n",
      "2  I ordered the purple tie dye color and was sen...           0       322   \n",
      "3  I am 5’1 and around 110-112 lbs. I love these ...           0       453   \n",
      "4  I am obsessed with these shorts. I’ve ordered ...           0       351   \n",
      "\n",
      "   sent_len                                              label  \\\n",
      "0       313  [('comfortable', 'feelings'), ('being able to ...   \n",
      "1       215  [('green color was perfect', 'color'), ('runni...   \n",
      "2       322  [('Just wish I was given the correct color', '...   \n",
      "3       453  [('I love these shorts', 'feelings'), ('perfec...   \n",
      "4       351  [('I’ve ordered multiple colors', 'purchase_be...   \n",
      "\n",
      "                                           label_tag  \n",
      "0                                feelings,expectancy  \n",
      "1  color,scene,purchase_behavior,purchase_behavio...  \n",
      "2                                         expectancy  \n",
      "3                   feelings,size,design,design,size  \n",
      "4   purchase_behavior,price,design,purchase_behavior  \n",
      "<< path valid!\n",
      "training size:  (826, 9)\n",
      "test size:  (104, 9)\n",
      "validate size:  (103, 9)\n",
      "<<<finish data preparing!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#preprocess data\n",
    "def write_txt(df,path):\n",
    "    '''\n",
    "    write back to txt\n",
    "    '''\n",
    "    #output txt file\n",
    "    df = df.reset_index()\n",
    "    with open(path,'a')as f:\n",
    "        for i in range(len(df)):\n",
    "            f.write(\"{} #### {}\".format(df.loc[i,'text'].strip(),df.loc[i,'label']))\n",
    "            f.write('\\n')\n",
    "            \n",
    "            \n",
    "def mkdir_rm(folder):\n",
    "    '''\n",
    "    make directory if not exists\n",
    "    '''\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder) \n",
    "    os.mkdir(folder)\n",
    "    print (\"<< path valid!\")\n",
    "    \n",
    "\n",
    "def preprocess_data(input_file,output_path,over_sample=True):\n",
    "    jsonObj = pd.read_csv(input_file)\n",
    "    jsonObj = jsonObj[jsonObj['label']!='[]']\n",
    "    print (jsonObj.head())\n",
    "    \n",
    "    #remove & remake the output folder \n",
    "    mkdir_rm(output_path)\n",
    "    \n",
    "    #generate tag.txt\n",
    "    #a_list = ['consumer','zone','target','consequence','product','product_spec']\n",
    "    #with open('tag.txt', 'w') as filehandle:\n",
    "     #   filehandle.writelines(\"%s\\n\" % tag for tag in a_list)\n",
    "    \n",
    "    #train/test/val split\n",
    "    train, validate, test = np.split(jsonObj.sample(frac=1), [int(.8*len(jsonObj)), int(.9*len(jsonObj))])\n",
    "   \n",
    "    print (\"training size: \",train.shape)\n",
    "    print (\"test size: \",test.shape)\n",
    "    print (\"validate size: \",validate.shape)\n",
    "    \n",
    "    # write train/test/dev\n",
    "    write_txt(train,os.path.join(output_path,'train.txt'))\n",
    "    write_txt(test,os.path.join(output_path,'test.txt'))\n",
    "    write_txt(validate,os.path.join(output_path,'dev.txt'))\n",
    "    print (\"<<<finish data preparing!\")\n",
    "    \n",
    "input_file = './aspect_category.csv'\n",
    "output_path = './data/tasd/bmjl'\n",
    "preprocess_data(input_file,output_path,over_sample=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ec1ce",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3a5fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sage.Session()\n",
    "\n",
    "WORK_DIRECTORY = \"./data\"\n",
    "\n",
    "# S3 prefix\n",
    "prefix = \"bmjl\"\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"task\" : \"tasd\", \n",
    "    \"dataset\" : \"bmjl\", \n",
    "    \"model_name_or_path\" : \"t5-base\", \n",
    "    \"paradigm\": \"extraction\",\n",
    "    \"eval_batch_size\" :\"16\",\n",
    "    \"train_batch_size\" :\"2\",\n",
    "    \"learning_rate\" :\"3e-4\",\n",
    "    \"num_train_epochs\":\"1\",\n",
    "    \"n_gpu\": \"1\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a1a00b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'finetune.py'\n",
    "source_dir = './'\n",
    "git_config = None\n",
    "role = get_execution_role()\n",
    "framework_version = '1.7.1'\n",
    "py_version='py36'\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#instance_type='local_gpu'\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0da441",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_point = 'finetune.py'\n",
    "source_dir = './'\n",
    "git_config = None\n",
    "role = get_execution_role()\n",
    "framework_version = '1.7.1'\n",
    "py_version='py36'\n",
    "instance_type='ml.p3.2xlarge'\n",
    "#instance_type='local_gpu'\n",
    "instance_count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63fea514",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point = entry_point,\n",
    "    source_dir = source_dir,\n",
    "    git_config = git_config,\n",
    "    role = role,\n",
    "    debugger_hook_config=False,\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    "    instance_type = instance_type,\n",
    "    instance_count = instance_count\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "992c348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'tasd': data_location+'/tasd/'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf34d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-17 02:58:35 Starting - Starting the training job...\n",
      "2022-08-17 02:59:01 Starting - Preparing the instances for trainingProfilerReport-1660705115: InProgress\n",
      ".........\n",
      "2022-08-17 03:00:30 Downloading - Downloading input data...\n",
      "2022-08-17 03:00:50 Training - Downloading the training image.......................\u001B[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001B[0m\n",
      "\u001B[34mbash: no job control in this shell\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:46,061 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:46,085 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:46,095 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:04:47,443 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.6 -m pip install -r requirements.txt\u001B[0m\n",
      "\u001B[34mCollecting transformers==4.6.0\n",
      "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\u001B[0m\n",
      "\u001B[34mCollecting datasets==1.11.0\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\u001B[0m\n",
      "\u001B[34mCollecting sentencepiece==0.1.91\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\u001B[0m\n",
      "\u001B[34mCollecting pytorch_lightning==0.8.1\n",
      "  Downloading pytorch_lightning-0.8.1-py3-none-any.whl (293 kB)\u001B[0m\n",
      "\u001B[34mCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\u001B[0m\n",
      "\u001B[34mCollecting editdistance\n",
      "  Downloading editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2.25.1)\u001B[0m\n",
      "\u001B[34mCollecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.0.1)\u001B[0m\n",
      "\u001B[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.51.0)\u001B[0m\n",
      "\u001B[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001B[0m\n",
      "\n",
      "2022-08-17 03:04:51 Training - Training image download completed. Training in progress.\u001B[34mCollecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (20.9)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.70.11.1)\u001B[0m\n",
      "\u001B[34mCollecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (1.1.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.3.3)\u001B[0m\n",
      "\u001B[34mCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (2021.5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard>=1.14\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2.10)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2020.12.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.17.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.35.1)\u001B[0m\n",
      "\u001B[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.0.1)\u001B[0m\n",
      "\u001B[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.10.0-py2.py3-none-any.whl (167 kB)\u001B[0m\n",
      "\u001B[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001B[0m\n",
      "\u001B[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001B[0m\n",
      "\u001B[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.16.0)\u001B[0m\n",
      "\u001B[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001B[0m\n",
      "\u001B[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001B[0m\n",
      "\u001B[34mCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.10.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r requirements.txt (line 1)) (2.4.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2021.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (7.1.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34mBuilding wheels for collected packages: jieba, sacremoses\n",
      "  Building wheel for jieba (setup.py): started\u001B[0m\n",
      "\u001B[34m  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314478 sha256=f01018e941d46d63eea042259f3db5a1bb75167f4bc9d69d8c97816c99c4d663\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/a7/8b/a7e03881534e78558920ac68aaeca05180c0e2c3d11c4fce3b\n",
      "  Building wheel for sacremoses (setup.py): started\u001B[0m\n",
      "\u001B[34m  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895252 sha256=9e801007b4f861a76a98e90eaf4af594c0069c6209ed1dca0043726c99b825b1\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001B[0m\n",
      "\u001B[34mSuccessfully built jieba sacremoses\u001B[0m\n",
      "\u001B[34mInstalling collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, regex, markdown, grpcio, google-auth-oauthlib, filelock, absl-py, xxhash, tokenizers, tensorboard, sacremoses, pyarrow, huggingface-hub, transformers, sentencepiece, pytorch-lightning, jieba, editdistance, datasets\u001B[0m\n",
      "\u001B[34m  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.0.1\n",
      "    Uninstalling importlib-metadata-4.0.1:\n",
      "      Successfully uninstalled importlib-metadata-4.0.1\u001B[0m\n",
      "\u001B[34m  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 4.0.0\n",
      "    Uninstalling pyarrow-4.0.0:\n",
      "      Successfully uninstalled pyarrow-4.0.0\u001B[0m\n",
      "\u001B[34mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 datasets-1.11.0 editdistance-0.6.0 filelock-3.4.1 google-auth-2.10.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.0.8 importlib-metadata-4.8.3 jieba-0.42.1 markdown-3.3.7 oauthlib-3.2.0 pyarrow-6.0.1 pyasn1-modules-0.2.8 pytorch-lightning-0.8.1 regex-2022.7.25 requests-oauthlib-1.3.1 sacremoses-0.0.53 sentencepiece-0.1.91 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.10.3 transformers-4.6.0 xxhash-3.0.0\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m2022-08-17 03:05:10,013 sagemaker-training-toolkit INFO     Invoking user script\u001B[0m\n",
      "\u001B[34mTraining Env:\u001B[0m\n",
      "\u001B[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"tasd\": \"/opt/ml/input/data/tasd\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dataset\": \"bmjl\",\n",
      "        \"eval_batch_size\": \"16\",\n",
      "        \"learning_rate\": \"3e-4\",\n",
      "        \"model_name_or_path\": \"t5-base\",\n",
      "        \"n_gpu\": \"1\",\n",
      "        \"num_train_epochs\": \"1\",\n",
      "        \"paradigm\": \"extraction\",\n",
      "        \"task\": \"tasd\",\n",
      "        \"train_batch_size\": \"2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"tasd\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2022-08-17-02-58-32-852\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-08-17-02-58-32-852/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"finetune\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"finetune.py\"\u001B[0m\n",
      "\u001B[34m}\u001B[0m\n",
      "\u001B[34mEnvironment variables:\u001B[0m\n",
      "\u001B[34mSM_HOSTS=[\"algo-1\"]\u001B[0m\n",
      "\u001B[34mSM_NETWORK_INTERFACE_NAME=eth0\u001B[0m\n",
      "\u001B[34mSM_HPS={\"dataset\":\"bmjl\",\"eval_batch_size\":\"16\",\"learning_rate\":\"3e-4\",\"model_name_or_path\":\"t5-base\",\"n_gpu\":\"1\",\"num_train_epochs\":\"1\",\"paradigm\":\"extraction\",\"task\":\"tasd\",\"train_batch_size\":\"2\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ENTRY_POINT=finetune.py\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_PARAMS={}\u001B[0m\n",
      "\u001B[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001B[0m\n",
      "\u001B[34mSM_INPUT_DATA_CONFIG={\"tasd\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001B[0m\n",
      "\u001B[34mSM_CHANNELS=[\"tasd\"]\u001B[0m\n",
      "\u001B[34mSM_CURRENT_HOST=algo-1\u001B[0m\n",
      "\u001B[34mSM_MODULE_NAME=finetune\u001B[0m\n",
      "\u001B[34mSM_LOG_LEVEL=20\u001B[0m\n",
      "\u001B[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001B[0m\n",
      "\u001B[34mSM_INPUT_DIR=/opt/ml/input\u001B[0m\n",
      "\u001B[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_DIR=/opt/ml/output\u001B[0m\n",
      "\u001B[34mSM_NUM_CPUS=8\u001B[0m\n",
      "\u001B[34mSM_NUM_GPUS=1\u001B[0m\n",
      "\u001B[34mSM_MODEL_DIR=/opt/ml/model\u001B[0m\n",
      "\u001B[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-08-17-02-58-32-852/source/sourcedir.tar.gz\u001B[0m\n",
      "\u001B[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"tasd\":\"/opt/ml/input/data/tasd\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dataset\":\"bmjl\",\"eval_batch_size\":\"16\",\"learning_rate\":\"3e-4\",\"model_name_or_path\":\"t5-base\",\"n_gpu\":\"1\",\"num_train_epochs\":\"1\",\"paradigm\":\"extraction\",\"task\":\"tasd\",\"train_batch_size\":\"2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"tasd\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2022-08-17-02-58-32-852\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-726335585155/pytorch-training-2022-08-17-02-58-32-852/source/sourcedir.tar.gz\",\"module_name\":\"finetune\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"finetune.py\"}\u001B[0m\n",
      "\u001B[34mSM_USER_ARGS=[\"--dataset\",\"bmjl\",\"--eval_batch_size\",\"16\",\"--learning_rate\",\"3e-4\",\"--model_name_or_path\",\"t5-base\",\"--n_gpu\",\"1\",\"--num_train_epochs\",\"1\",\"--paradigm\",\"extraction\",\"--task\",\"tasd\",\"--train_batch_size\",\"2\"]\u001B[0m\n",
      "\u001B[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001B[0m\n",
      "\u001B[34mSM_CHANNEL_TASD=/opt/ml/input/data/tasd\u001B[0m\n",
      "\u001B[34mSM_HP_DATASET=bmjl\u001B[0m\n",
      "\u001B[34mSM_HP_EVAL_BATCH_SIZE=16\u001B[0m\n",
      "\u001B[34mSM_HP_LEARNING_RATE=3e-4\u001B[0m\n",
      "\u001B[34mSM_HP_MODEL_NAME_OR_PATH=t5-base\u001B[0m\n",
      "\u001B[34mSM_HP_N_GPU=1\u001B[0m\n",
      "\u001B[34mSM_HP_NUM_TRAIN_EPOCHS=1\u001B[0m\n",
      "\u001B[34mSM_HP_PARADIGM=extraction\u001B[0m\n",
      "\u001B[34mSM_HP_TASK=tasd\u001B[0m\n",
      "\u001B[34mSM_HP_TRAIN_BATCH_SIZE=2\u001B[0m\n",
      "\u001B[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001B[0m\n",
      "\u001B[34mInvoking script with the following command:\u001B[0m\n",
      "\u001B[34m/opt/conda/bin/python3.6 finetune.py --dataset bmjl --eval_batch_size 16 --learning_rate 3e-4 --model_name_or_path t5-base --n_gpu 1 --num_train_epochs 1 --paradigm extraction --task tasd --train_batch_size 2\u001B[0m\n",
      "\u001B[34m/opt/ml/code\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: transformers==4.6.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1)) (4.6.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: datasets==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 2)) (1.11.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: sentencepiece==0.1.91 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 3)) (0.1.91)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytorch_lightning==0.8.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 4)) (0.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: jieba in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 5)) (0.42.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: editdistance in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 6)) (0.6.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (20.9)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2.25.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.0.53)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.51.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.8.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2022.7.25)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.10.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (2021.5.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.3.3)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (3.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (6.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (1.1.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.70.11.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tensorboard>=1.14 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2020.12.5)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2.10)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.35.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.6.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.17.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.2.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.47.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.3.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.4.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.2.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.2.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.16.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.3.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.10.0.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.2.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r requirements.txt (line 1)) (2.4.7)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2.8.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2021.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (7.1.2)\u001B[0m\n",
      "\u001B[34m<<<run train!!\u001B[0m\n",
      "\u001B[34margs task:  tasd\n",
      " ============================== NEW EXP: TASD on bmjl ============================== \u001B[0m\n",
      "\u001B[34mHere is an example (from dev set) under `extraction` paradigm:\u001B[0m\n",
      "\u001B[34mTotal examples = 103 for data/tasd/bmjl/dev.txt\u001B[0m\n",
      "\u001B[34mInput : I sized up and they were still super short. You could easily see the under shorts without moving. They also did not flatter my shape at all and made the material pull in the middle.\u001B[0m\n",
      "\u001B[34mOutput: (super short, size); (sized up, size); (material pull in the middle, design); (did not flatter my shape, type); (see the under shorts without moving, size); (see the under shorts without moving, design)\u001B[0m\n",
      "\u001B[34m****** Conduct Training ******\u001B[0m\n",
      "\u001B[34mNamespace(adam_epsilon=1e-08, ckpoint_path='/opt/ml/model/cktepoch=1.ckpt', customer_jj=False, dataset='bmjl', do_batch_predict=False, do_direct_eval=False, do_direct_predict=False, do_eval=False, do_train=True, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=0.0003, max_seq_length=128, model_name_or_path='t5-base', n_gpu=1, num_train_epochs=1, output_dir='/opt/ml/model', paradigm='extraction', seed=42, task='tasd', text='早餐一般般，勉勉强强填饱肚子，样式可选性不多，可能是疫情的影响吧。不过酒店的服务不错，五个小孩早餐都送了，点👍。由于酒店历史有点长，所以设施感觉一般般，整体还可以，三钻吧', train_batch_size=2, warmup_steps=0.0, weight_decay=0.0)\u001B[0m\n",
      "\u001B[34m{'default_root_dir': '/opt/ml/model', 'accumulate_grad_batches': 1, 'gpus': 1, 'gradient_clip_val': 1.0, 'max_epochs': 1, 'checkpoint_callback': <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x7f6052534748>, 'callbacks': [<__main__.LoggingCallback object at 0x7f60525347b8>]}\u001B[0m\n",
      "\u001B[34mTotal examples = 103 for data/tasd/bmjl/dev.txt\u001B[0m\n",
      "\u001B[34m#015Validation sanity check: 0it [00:00, ?it/s]#015Validation sanity check:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]#015                                                                      #015Total examples = 826 for data/tasd/bmjl/train.txt\u001B[0m\n",
      "\u001B[34mtrain Input : theses shorts were made of cheap material not advertised properly very upset Amazon would deal with this company on anything further from maker I relied on Amazon to carry good products not product from any China that is cheap\u001B[0m\n",
      "\u001B[34mtrain Output: (cheap material, fabric); (cheap, fabric)\u001B[0m\n",
      "\u001B[34mself.hparams.n_gpu:  1\u001B[0m\n",
      "\u001B[34mt_total:  826.0\u001B[0m\n",
      "\u001B[34mTotal examples = 103 for data/tasd/bmjl/dev.txt\u001B[0m\n",
      "\u001B[34m#015Training: 0it [00:00, ?it/s]#015Training:   0%|          | 0/420 [00:00<?, ?it/s]#015Epoch 1:   0%|          | 0/420 [00:00<?, ?it/s] #015Epoch 1:   0%|          | 1/420 [00:00<03:25,  2.04it/s]#015Epoch 1:   0%|          | 1/420 [00:00<03:25,  2.04it/s, loss=3.807, v_num=0]#015Epoch 1:   0%|          | 2/420 [00:00<02:39,  2.63it/s, loss=3.807, v_num=0]#015Epoch 1:   0%|          | 2/420 [00:00<02:39,  2.62it/s, loss=3.528, v_num=0]#015Epoch 1:   1%|          | 3/420 [00:01<02:22,  2.92it/s, loss=3.528, v_num=0]#015Epoch 1:   1%|          | 3/420 [00:01<02:22,  2.92it/s, loss=3.461, v_num=0]#015Epoch 1:   1%|          | 4/420 [00:01<02:14,  3.09it/s, loss=3.461, v_num=0]#015Epoch 1:   1%|          | 4/420 [00:01<02:14,  3.09it/s, loss=3.245, v_num=0]#015Epoch 1:   1%|          | 5/420 [00:01<02:11,  3.15it/s, loss=3.245, v_num=0]#015Epoch 1:   1%|          | 5/420 [00:01<02:11,  3.14it/s, loss=3.493, v_num=0]#015Epoch 1:   1%|▏         | 6/420 [00:01<02:09,  3.20it/s, loss=3.493, v_num=0]#015Epoch 1:   1%|▏         | 6/420 [00:01<02:09,  3.20it/s, loss=3.313, v_num=0]#015Epoch 1:   2%|▏         | 7/420 [00:02<02:05,  3.28it/s, loss=3.313, v_num=0]#015Epoch 1:   2%|▏         | 7/420 [00:02<02:05,  3.28it/s, loss=3.119, v_num=0]#015Epoch 1:   2%|▏         | 8/420 [00:02<02:03,  3.35it/s, loss=3.119, v_num=0]#015Epoch 1:   2%|▏         | 8/420 [00:02<02:03,  3.35it/s, loss=2.970, v_num=0]#015Epoch 1:   2%|▏         | 9/420 [00:02<02:00,  3.40it/s, loss=2.970, v_num=0]#015Epoch 1:   2%|▏         | 9/420 [00:02<02:00,  3.40it/s, loss=3.016, v_num=0]#015Epoch 1:   2%|▏         | 10/420 [00:02<01:59,  3.42it/s, loss=3.016, v_num=0]#015Epoch 1:   2%|▏         | 10/420 [00:02<01:59,  3.42it/s, loss=2.900, v_num=0]#015Epoch 1:   3%|▎         | 11/420 [00:03<01:57,  3.47it/s, loss=2.900, v_num=0]#015Epoch 1:   3%|▎         | 11/420 [00:03<01:57,  3.47it/s, loss=2.788, v_num=0]#015Epoch 1:   3%|▎         | 12/420 [00:03<01:56,  3.50it/s, loss=2.788, v_num=0]#015Epoch 1:   3%|▎         | 12/420 [00:03<01:56,  3.50it/s, loss=2.688, v_num=0]#015Epoch 1:   3%|▎         | 13/420 [00:03<01:55,  3.53it/s, loss=2.688, v_num=0]#015Epoch 1:   3%|▎         | 13/420 [00:03<01:55,  3.53it/s, loss=2.580, v_num=0]#015Epoch 1:   3%|▎         | 14/420 [00:03<01:53,  3.56it/s, loss=2.580, v_num=0]#015Epoch 1:   3%|▎         | 14/420 [00:03<01:53,  3.56it/s, loss=2.511, v_num=0]#015Epoch 1:   4%|▎         | 15/420 [00:04<01:53,  3.57it/s, loss=2.511, v_num=0]#015Epoch 1:   4%|▎         | 15/420 [00:04<01:53,  3.57it/s, loss=2.445, v_num=0]#015Epoch 1:   4%|▍         | 16/420 [00:04<01:52,  3.59it/s, loss=2.445, v_num=0]#015Epoch 1:   4%|▍         | 16/420 [00:04<01:52,  3.59it/s, loss=2.393, v_num=0]#015Epoch 1:   4%|▍         | 17/420 [00:04<01:51,  3.60it/s, loss=2.393, v_num=0]#015Epoch 1:   4%|▍         | 17/420 [00:04<01:51,  3.60it/s, loss=2.366, v_num=0]#015Epoch 1:   4%|▍         | 18/420 [00:04<01:51,  3.62it/s, loss=2.366, v_num=0]#015Epoch 1:   4%|▍         | 18/420 [00:04<01:51,  3.62it/s, loss=2.324, v_num=0]#015Epoch 1:   5%|▍         | 19/420 [00:05<01:50,  3.62it/s, loss=2.324, v_num=0]#015Epoch 1:   5%|▍         | 19/420 [00:05<01:50,  3.62it/s, loss=2.289, v_num=0]#015Epoch 1:   5%|▍         | 20/420 [00:05<01:50,  3.64it/s, loss=2.289, v_num=0]#015Epoch 1:   5%|▍         | 20/420 [00:05<01:50,  3.64it/s, loss=2.239, v_num=0]#015Epoch 1:   5%|▌         | 21/420 [00:05<01:49,  3.65it/s, loss=2.239, v_num=0]#015Epoch 1:   5%|▌         | 21/420 [00:05<01:49,  3.65it/s, loss=2.129, v_num=0]#015Epoch 1:   5%|▌         | 22/420 [00:06<01:48,  3.65it/s, loss=2.129, v_num=0]#015Epoch 1:   5%|▌         | 22/420 [00:06<01:49,  3.65it/s, loss=2.036, v_num=0]#015Epoch 1:   5%|▌         | 23/420 [00:06<01:48,  3.66it/s, loss=2.036, v_num=0]#015Epoch 1:   5%|▌         | 23/420 [00:06<01:48,  3.66it/s, loss=1.944, v_num=0]#015Epoch 1:   6%|▌         | 24/420 [00:06<01:48,  3.66it/s, loss=1.944, v_num=0]#015Epoch 1:   6%|▌         | 24/420 [00:06<01:48,  3.66it/s, loss=1.883, v_num=0]#015Epoch 1:   6%|▌         | 25/420 [00:06<01:47,  3.67it/s, loss=1.883, v_num=0]#015Epoch 1:   6%|▌         | 25/420 [00:06<01:47,  3.67it/s, loss=1.710, v_num=0]#015Epoch 1:   6%|▌         | 26/420 [00:07<01:47,  3.67it/s, loss=1.710, v_num=0]#015Epoch 1:   6%|▌         | 26/420 [00:07<01:47,  3.67it/s, loss=1.660, v_num=0]#015Epoch 1:   6%|▋         | 27/420 [00:07<01:46,  3.68it/s, loss=1.660, v_num=0]#015Epoch 1:   6%|▋         | 27/420 [00:07<01:46,  3.68it/s, loss=1.635, v_num=0]#015Epoch 1:   7%|▋         | 28/420 [00:07<01:46,  3.69it/s, loss=1.635, v_num=0]#015Epoch 1:   7%|▋         | 28/420 [00:07<01:46,  3.69it/s, loss=1.615, v_num=0]#015Epoch 1:   7%|▋         | 29/420 [00:07<01:45,  3.70it/s, loss=1.615, v_num=0]#015Epoch 1:   7%|▋         | 29/420 [00:07<01:45,  3.70it/s, loss=1.511, v_num=0]#015Epoch 1:   7%|▋         | 30/420 [00:08<01:45,  3.71it/s, loss=1.511, v_num=0]#015Epoch 1:   7%|▋         | 30/420 [00:08<01:45,  3.71it/s, loss=1.461, v_num=0]#015Epoch 1:   7%|▋         | 31/420 [00:08<01:44,  3.71it/s, loss=1.461, v_num=0]#015Epoch 1:   7%|▋         | 31/420 [00:08<01:44,  3.71it/s, loss=1.454, v_num=0]#015Epoch 1:   8%|▊         | 32/420 [00:08<01:44,  3.71it/s, loss=1.454, v_num=0]#015Epoch 1:   8%|▊         | 32/420 [00:08<01:44,  3.71it/s, loss=1.420, v_num=0]#015Epoch 1:   8%|▊         | 33/420 [00:08<01:44,  3.71it/s, loss=1.420, v_num=0]#015Epoch 1:   8%|▊         | 33/420 [00:08<01:44,  3.71it/s, loss=1.419, v_num=0]#015Epoch 1:   8%|▊         | 34/420 [00:09<01:43,  3.71it/s, loss=1.419, v_num=0]#015Epoch 1:   8%|▊         | 34/420 [00:09<01:43,  3.71it/s, loss=1.381, v_num=0]#015Epoch 1:   8%|▊         | 35/420 [00:09<01:43,  3.71it/s, loss=1.381, v_num=0]#015Epoch 1:   8%|▊         | 35/420 [00:09<01:43,  3.71it/s, loss=1.368, v_num=0]#015Epoch 1:   9%|▊         | 36/420 [00:09<01:43,  3.72it/s, loss=1.368, v_num=0]#015Epoch 1:   9%|▊         | 36/420 [00:09<01:43,  3.72it/s, loss=1.328, v_num=0]#015Epoch 1:   9%|▉         | 37/420 [00:09<01:43,  3.72it/s, loss=1.328, v_num=0]#015Epoch 1:   9%|▉         | 37/420 [00:09<01:43,  3.72it/s, loss=1.290, v_num=0]#015Epoch 1:   9%|▉         | 38/420 [00:10<01:42,  3.72it/s, loss=1.290, v_num=0]#015Epoch 1:   9%|▉         | 38/420 [00:10<01:42,  3.72it/s, loss=1.272, v_num=0]#015Epoch 1:   9%|▉         | 39/420 [00:10<01:42,  3.72it/s, loss=1.272, v_num=0]#015Epoch 1:   9%|▉         | 39/420 [00:10<01:42,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|▉         | 40/420 [00:10<01:42,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|▉         | 40/420 [00:10<01:42,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|▉         | 41/420 [00:11<01:41,  3.72it/s, loss=1.229, v_num=0]#015Epoch 1:  10%|▉         | 41/420 [00:11<01:41,  3.72it/s, loss=1.203, v_num=0]#015Epoch 1:  10%|█         | 42/420 [00:11<01:41,  3.72it/s, loss=1.203, v_num=0]#015Epoch 1:  10%|█         | 42/420 [00:11<01:41,  3.72it/s, loss=1.186, v_num=0]#015Epoch 1:  10%|█         | 43/420 [00:11<01:41,  3.73it/s, loss=1.186, v_num=0]#015Epoch 1:  10%|█         | 43/420 [00:11<01:41,  3.72it/s, loss=1.167, v_num=0]#015Epoch 1:  10%|█         | 44/420 [00:11<01:40,  3.73it/s, loss=1.167, v_num=0]#015Epoch 1:  10%|█         | 44/420 [00:11<01:40,  3.73it/s, loss=1.160, v_num=0]#015Epoch 1:  11%|█         | 45/420 [00:12<01:40,  3.73it/s, loss=1.160, v_num=0]#015Epoch 1:  11%|█         | 45/420 [00:12<01:40,  3.73it/s, loss=1.175, v_num=0]#015Epoch 1:  11%|█         | 46/420 [00:12<01:40,  3.74it/s, loss=1.175, v_num=0]#015Epoch 1:  11%|█         | 46/420 [00:12<01:40,  3.74it/s, loss=1.159, v_num=0]#015Epoch 1:  11%|█         | 47/420 [00:12<01:39,  3.74it/s, loss=1.159, v_num=0]#015Epoch 1:  11%|█         | 47/420 [00:12<01:39,  3.74it/s, loss=1.144, v_num=0]#015Epoch 1:  11%|█▏        | 48/420 [00:12<01:39,  3.74it/s, loss=1.144, v_num=0]#015Epoch 1:  11%|█▏        | 48/420 [00:12<01:39,  3.74it/s, loss=1.133, v_num=0]#015Epoch 1:  12%|█▏        | 49/420 [00:13<01:38,  3.75it/s, loss=1.133, v_num=0]#015Epoch 1:  12%|█▏        | 49/420 [00:13<01:38,  3.75it/s, loss=1.152, v_num=0]#015Epoch 1:  12%|█▏        | 50/420 [00:13<01:38,  3.74it/s, loss=1.152, v_num=0]#015Epoch 1:  12%|█▏        | 50/420 [00:13<01:38,  3.74it/s, loss=1.171, v_num=0]#015Epoch 1:  12%|█▏        | 51/420 [00:13<01:39,  3.72it/s, loss=1.171, v_num=0]#015Epoch 1:  12%|█▏        | 51/420 [00:13<01:39,  3.72it/s, loss=1.143, v_num=0]#015Epoch 1:  12%|█▏        | 52/420 [00:13<01:38,  3.72it/s, loss=1.143, v_num=0]#015Epoch 1:  12%|█▏        | 52/420 [00:13<01:38,  3.72it/s, loss=1.200, v_num=0]#015Epoch 1:  13%|█▎        | 53/420 [00:14<01:38,  3.71it/s, loss=1.200, v_num=0]#015Epoch 1:  13%|█▎        | 53/420 [00:14<01:38,  3.71it/s, loss=1.202, v_num=0]#015Epoch 1:  13%|█▎        | 54/420 [00:14<01:38,  3.71it/s, loss=1.202, v_num=0]#015Epoch 1:  13%|█▎        | 54/420 [00:14<01:38,  3.71it/s, loss=1.258, v_num=0]#015Epoch 1:  13%|█▎        | 55/420 [00:14<01:38,  3.71it/s, loss=1.258, v_num=0]#015Epoch 1:  13%|█▎        | 55/420 [00:14<01:38,  3.71it/s, loss=1.260, v_num=0]#015Epoch 1:  13%|█▎        | 56/420 [00:15<01:38,  3.71it/s, loss=1.260, v_num=0]#015Epoch 1:  13%|█▎        | 56/420 [00:15<01:38,  3.71it/s, loss=1.281, v_num=0]#015Epoch 1:  14%|█▎        | 57/420 [00:15<01:37,  3.71it/s, loss=1.281, v_num=0]#015Epoch 1:  14%|█▎        | 57/420 [00:15<01:37,  3.70it/s, loss=1.269, v_num=0]#015Epoch 1:  14%|█▍        | 58/420 [00:15<01:37,  3.70it/s, loss=1.269, v_num=0]#015Epoch 1:  14%|█▍        | 58/420 [00:15<01:37,  3.70it/s, loss=1.288, v_num=0]#015Epoch 1:  14%|█▍        | 59/420 [00:15<01:37,  3.69it/s, loss=1.288, v_num=0]#015Epoch 1:  14%|█▍        | 59/420 [00:15<01:37,  3.69it/s, loss=1.292, v_num=0]#015Epoch 1:  14%|█▍        | 60/420 [00:16<01:37,  3.68it/s, loss=1.292, v_num=0]#015Epoch 1:  14%|█▍        | 60/420 [00:16<01:37,  3.68it/s, loss=1.282, v_num=0]#015Epoch 1:  15%|█▍        | 61/420 [00:16<01:37,  3.68it/s, loss=1.282, v_num=0]#015Epoch 1:  15%|█▍        | 61/420 [00:16<01:37,  3.68it/s, loss=1.265, v_num=0]#015Epoch 1:  15%|█▍        | 62/420 [00:16<01:37,  3.68it/s, loss=1.265, v_num=0]#015Epoch 1:  15%|█▍        | 62/420 [00:16<01:37,  3.68it/s, loss=1.244, v_num=0]#015Epoch 1:  15%|█▌        | 63/420 [00:17<01:36,  3.68it/s, loss=1.244, v_num=0]#015Epoch 1:  15%|█▌        | 63/420 [00:17<01:36,  3.68it/s, loss=1.227, v_num=0]#015Epoch 1:  15%|█▌        | 64/420 [00:17<01:36,  3.68it/s, loss=1.227, v_num=0]#015Epoch 1:  15%|█▌        | 64/420 [00:17<01:36,  3.68it/s, loss=1.213, v_num=0]#015Epoch 1:  15%|█▌        | 65/420 [00:17<01:36,  3.69it/s, loss=1.213, v_num=0]#015Epoch 1:  15%|█▌        | 65/420 [00:17<01:36,  3.69it/s, loss=1.230, v_num=0]#015Epoch 1:  16%|█▌        | 66/420 [00:17<01:35,  3.69it/s, loss=1.230, v_num=0]#015Epoch 1:  16%|█▌        | 66/420 [00:17<01:35,  3.69it/s, loss=1.222, v_num=0]#015Epoch 1:  16%|█▌        | 67/420 [00:18<01:35,  3.69it/s, loss=1.222, v_num=0]#015Epoch 1:  16%|█▌        | 67/420 [00:18<01:35,  3.69it/s, loss=1.231, v_num=0]#015Epoch 1:  16%|█▌        | 68/420 [00:18<01:35,  3.70it/s, loss=1.231, v_num=0]#015Epoch 1:  16%|█▌        | 68/420 [00:18<01:35,  3.70it/s, loss=1.212, v_num=0]#015Epoch 1:  16%|█▋        | 69/420 [00:18<01:34,  3.70it/s, loss=1.212, v_num=0]#015Epoch 1:  16%|█▋        | 69/420 [00:18<01:34,  3.70it/s, loss=1.180, v_num=0]#015Epoch 1:  17%|█▋        | 70/420 [00:18<01:34,  3.71it/s, loss=1.180, v_num=0]#015Epoch 1:  17%|█▋        | 70/420 [00:18<01:34,  3.71it/s, loss=1.178, v_num=0]#015Epoch 1:  17%|█▋        | 71/420 [00:19<01:34,  3.71it/s, loss=1.178, v_num=0]#015Epoch 1:  17%|█▋        | 71/420 [00:19<01:34,  3.71it/s, loss=1.186, v_num=0]#015Epoch 1:  17%|█▋        | 72/420 [00:19<01:33,  3.72it/s, loss=1.186, v_num=0]#015Epoch 1:  17%|█▋        | 72/420 [00:19<01:33,  3.72it/s, loss=1.140, v_num=0]#015Epoch 1:  17%|█▋        | 73/420 [00:19<01:33,  3.72it/s, loss=1.140, v_num=0]#015Epoch 1:  17%|█▋        | 73/420 [00:19<01:33,  3.72it/s, loss=1.118, v_num=0]#015Epoch 1:  18%|█▊        | 74/420 [00:19<01:32,  3.72it/s, loss=1.118, v_num=0]#015Epoch 1:  18%|█▊        | 74/420 [00:19<01:32,  3.72it/s, loss=1.065, v_num=0]#015Epoch 1:  18%|█▊        | 75/420 [00:20<01:32,  3.73it/s, loss=1.065, v_num=0]#015Epoch 1:  18%|█▊        | 75/420 [00:20<01:32,  3.73it/s, loss=1.046, v_num=0]#015Epoch 1:  18%|█▊        | 76/420 [00:20<01:32,  3.73it/s, loss=1.046, v_num=0]#015Epoch 1:  18%|█▊        | 76/420 [00:20<01:32,  3.73it/s, loss=1.029, v_num=0]#015Epoch 1:  18%|█▊        | 77/420 [00:20<01:32,  3.73it/s, loss=1.029, v_num=0]#015Epoch 1:  18%|█▊        | 77/420 [00:20<01:32,  3.73it/s, loss=1.015, v_num=0]#015Epoch 1:  19%|█▊        | 78/420 [00:20<01:31,  3.73it/s, loss=1.015, v_num=0]#015Epoch 1:  19%|█▊        | 78/420 [00:20<01:31,  3.73it/s, loss=0.977, v_num=0]#015Epoch 1:  19%|█▉        | 79/420 [00:21<01:31,  3.73it/s, loss=0.977, v_num=0]#015Epoch 1:  19%|█▉        | 79/420 [00:21<01:31,  3.73it/s, loss=0.975, v_num=0]#015Epoch 1:  19%|█▉        | 80/420 [00:21<01:31,  3.73it/s, loss=0.975, v_num=0]#015Epoch 1:  19%|█▉        | 80/420 [00:21<01:31,  3.73it/s, loss=0.964, v_num=0]#015Epoch 1:  19%|█▉        | 81/420 [00:21<01:30,  3.73it/s, loss=0.964, v_num=0]#015Epoch 1:  19%|█▉        | 81/420 [00:21<01:30,  3.73it/s, loss=0.985, v_num=0]#015Epoch 1:  20%|█▉        | 82/420 [00:21<01:30,  3.74it/s, loss=0.985, v_num=0]#015Epoch 1:  20%|█▉        | 82/420 [00:21<01:30,  3.74it/s, loss=0.996, v_num=0]#015Epoch 1:  20%|█▉        | 83/420 [00:22<01:30,  3.74it/s, loss=0.996, v_num=0]#015Epoch 1:  20%|█▉        | 83/420 [00:22<01:30,  3.74it/s, loss=0.994, v_num=0]#015Epoch 1:  20%|██        | 84/420 [00:22<01:29,  3.74it/s, loss=0.994, v_num=0]#015Epoch 1:  20%|██        | 84/420 [00:22<01:29,  3.74it/s, loss=0.983, v_num=0]#015Epoch 1:  20%|██        | 85/420 [00:22<01:29,  3.74it/s, loss=0.983, v_num=0]#015Epoch 1:  20%|██        | 85/420 [00:22<01:29,  3.74it/s, loss=0.950, v_num=0]#015Epoch 1:  20%|██        | 86/420 [00:22<01:29,  3.74it/s, loss=0.950, v_num=0]#015Epoch 1:  20%|██        | 86/420 [00:22<01:29,  3.74it/s, loss=0.963, v_num=0]#015Epoch 1:  21%|██        | 87/420 [00:23<01:28,  3.74it/s, loss=0.963, v_num=0]#015Epoch 1:  21%|██        | 87/420 [00:23<01:28,  3.74it/s, loss=0.949, v_num=0]#015Epoch 1:  21%|██        | 88/420 [00:23<01:28,  3.74it/s, loss=0.949, v_num=0]#015Epoch 1:  21%|██        | 88/420 [00:23<01:28,  3.74it/s, loss=0.976, v_num=0]#015Epoch 1:  21%|██        | 89/420 [00:23<01:28,  3.74it/s, loss=0.976, v_num=0]#015Epoch 1:  21%|██        | 89/420 [00:23<01:28,  3.74it/s, loss=0.977, v_num=0]#015Epoch 1:  21%|██▏       | 90/420 [00:24<01:28,  3.75it/s, loss=0.977, v_num=0]#015Epoch 1:  21%|██▏       | 90/420 [00:24<01:28,  3.75it/s, loss=0.956, v_num=0]#015Epoch 1:  22%|██▏       | 91/420 [00:24<01:27,  3.75it/s, loss=0.956, v_num=0]#015Epoch 1:  22%|██▏       | 91/420 [00:24<01:27,  3.75it/s, loss=0.939, v_num=0]#015Epoch 1:  22%|██▏       | 92/420 [00:24<01:27,  3.75it/s, loss=0.939, v_num=0]#015Epoch 1:  22%|██▏       | 92/420 [00:24<01:27,  3.75it/s, loss=0.926, v_num=0]#015Epoch 1:  22%|██▏       | 93/420 [00:24<01:27,  3.75it/s, loss=0.926, v_num=0]#015Epoch 1:  22%|██▏       | 93/420 [00:24<01:27,  3.75it/s, loss=0.931, v_num=0]#015Epoch 1:  22%|██▏       | 94/420 [00:25<01:26,  3.75it/s, loss=0.931, v_num=0]#015Epoch 1:  22%|██▏       | 94/420 [00:25<01:26,  3.75it/s, loss=0.929, v_num=0]#015Epoch 1:  23%|██▎       | 95/420 [00:25<01:26,  3.75it/s, loss=0.929, v_num=0]#015Epoch 1:  23%|██▎       | 95/420 [00:25<01:26,  3.75it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|██▎       | 96/420 [00:25<01:26,  3.75it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|██▎       | 96/420 [00:25<01:26,  3.75it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|██▎       | 97/420 [00:25<01:25,  3.76it/s, loss=0.930, v_num=0]#015Epoch 1:  23%|██▎       | 97/420 [00:25<01:25,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  23%|██▎       | 98/420 [00:26<01:25,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  23%|██▎       | 98/420 [00:26<01:25,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  24%|██▎       | 99/420 [00:26<01:25,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  24%|██▎       | 99/420 [00:26<01:25,  3.76it/s, loss=0.945, v_num=0]#015Epoch 1:  24%|██▍    \u001B[0m\n",
      "\u001B[34m   | 100/420 [00:26<01:25,  3.76it/s, loss=0.945, v_num=0]#015Epoch 1:  24%|██▍       | 100/420 [00:26<01:25,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  24%|██▍       | 101/420 [00:26<01:24,  3.76it/s, loss=0.947, v_num=0]#015Epoch 1:  24%|██▍       | 101/420 [00:26<01:24,  3.76it/s, loss=0.951, v_num=0]#015Epoch 1:  24%|██▍       | 102/420 [00:27<01:24,  3.76it/s, loss=0.951, v_num=0]#015Epoch 1:  24%|██▍       | 102/420 [00:27<01:24,  3.76it/s, loss=0.962, v_num=0]#015Epoch 1:  25%|██▍       | 103/420 [00:27<01:24,  3.76it/s, loss=0.962, v_num=0]#015Epoch 1:  25%|██▍       | 103/420 [00:27<01:24,  3.76it/s, loss=0.981, v_num=0]#015Epoch 1:  25%|██▍       | 104/420 [00:27<01:24,  3.76it/s, loss=0.981, v_num=0]#015Epoch 1:  25%|██▍       | 104/420 [00:27<01:24,  3.76it/s, loss=1.006, v_num=0]#015Epoch 1:  25%|██▌       | 105/420 [00:27<01:23,  3.76it/s, loss=1.006, v_num=0]#015Epoch 1:  25%|██▌       | 105/420 [00:27<01:23,  3.76it/s, loss=1.011, v_num=0]#015Epoch 1:  25%|██▌       | 106/420 [00:28<01:23,  3.76it/s, loss=1.011, v_num=0]#015Epoch 1:  25%|██▌       | 106/420 [00:28<01:23,  3.76it/s, loss=1.004, v_num=0]#015Epoch 1:  25%|██▌       | 107/420 [00:28<01:23,  3.76it/s, loss=1.004, v_num=0]#015Epoch 1:  25%|██▌       | 107/420 [00:28<01:23,  3.76it/s, loss=0.978, v_num=0]#015Epoch 1:  26%|██▌       | 108/420 [00:28<01:22,  3.76it/s, loss=0.978, v_num=0]#015Epoch 1:  26%|██▌       | 108/420 [00:28<01:22,  3.76it/s, loss=0.950, v_num=0]#015Epoch 1:  26%|██▌       | 109/420 [00:28<01:22,  3.77it/s, loss=0.950, v_num=0]#015Epoch 1:  26%|██▌       | 109/420 [00:28<01:22,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|██▌       | 110/420 [00:29<01:22,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|██▌       | 110/420 [00:29<01:22,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|██▋       | 111/420 [00:29<01:21,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  26%|██▋       | 111/420 [00:29<01:21,  3.77it/s, loss=0.955, v_num=0]#015Epoch 1:  27%|██▋       | 112/420 [00:29<01:21,  3.77it/s, loss=0.955, v_num=0]#015Epoch 1:  27%|██▋       | 112/420 [00:29<01:21,  3.77it/s, loss=0.957, v_num=0]#015Epoch 1:  27%|██▋       | 113/420 [00:29<01:21,  3.77it/s, loss=0.957, v_num=0]#015Epoch 1:  27%|██▋       | 113/420 [00:29<01:21,  3.77it/s, loss=0.951, v_num=0]#015Epoch 1:  27%|██▋       | 114/420 [00:30<01:21,  3.78it/s, loss=0.951, v_num=0]#015Epoch 1:  27%|██▋       | 114/420 [00:30<01:21,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  27%|██▋       | 115/420 [00:30<01:20,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  27%|██▋       | 115/420 [00:30<01:20,  3.78it/s, loss=0.946, v_num=0]#015Epoch 1:  28%|██▊       | 116/420 [00:30<01:20,  3.78it/s, loss=0.946, v_num=0]#015Epoch 1:  28%|██▊       | 116/420 [00:30<01:20,  3.78it/s, loss=0.947, v_num=0]#015Epoch 1:  28%|██▊       | 117/420 [00:30<01:20,  3.78it/s, loss=0.947, v_num=0]#015Epoch 1:  28%|██▊       | 117/420 [00:30<01:20,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  28%|██▊       | 118/420 [00:31<01:19,  3.78it/s, loss=0.949, v_num=0]#015Epoch 1:  28%|██▊       | 118/420 [00:31<01:19,  3.78it/s, loss=0.945, v_num=0]#015Epoch 1:  28%|██▊       | 119/420 [00:31<01:19,  3.78it/s, loss=0.945, v_num=0]#015Epoch 1:  28%|██▊       | 119/420 [00:31<01:19,  3.78it/s, loss=0.951, v_num=0]#015Epoch 1:  29%|██▊       | 120/420 [00:31<01:19,  3.78it/s, loss=0.951, v_num=0]#015Epoch 1:  29%|██▊       | 120/420 [00:31<01:19,  3.78it/s, loss=0.941, v_num=0]#015Epoch 1:  29%|██▉       | 121/420 [00:32<01:19,  3.78it/s, loss=0.941, v_num=0]#015Epoch 1:  29%|██▉       | 121/420 [00:32<01:19,  3.78it/s, loss=0.927, v_num=0]#015Epoch 1:  29%|██▉       | 122/420 [00:32<01:18,  3.78it/s, loss=0.927, v_num=0]#015Epoch 1:  29%|██▉       | 122/420 [00:32<01:18,  3.78it/s, loss=0.913, v_num=0]#015Epoch 1:  29%|██▉       | 123/420 [00:32<01:18,  3.78it/s, loss=0.913, v_num=0]#015Epoch 1:  29%|██▉       | 123/420 [00:32<01:18,  3.78it/s, loss=0.893, v_num=0]#015Epoch 1:  30%|██▉       | 124/420 [00:32<01:18,  3.77it/s, loss=0.893, v_num=0]#015Epoch 1:  30%|██▉       | 124/420 [00:32<01:18,  3.77it/s, loss=0.892, v_num=0]#015Epoch 1:  30%|██▉       | 125/420 [00:33<01:18,  3.77it/s, loss=0.892, v_num=0]#015Epoch 1:  30%|██▉       | 125/420 [00:33<01:18,  3.77it/s, loss=0.864, v_num=0]#015Epoch 1:  30%|███       | 126/420 [00:33<01:17,  3.77it/s, loss=0.864, v_num=0]#015Epoch 1:  30%|███       | 126/420 [00:33<01:17,  3.77it/s, loss=0.842, v_num=0]#015Epoch 1:  30%|███       | 127/420 [00:33<01:17,  3.77it/s, loss=0.842, v_num=0]#015Epoch 1:  30%|███       | 127/420 [00:33<01:17,  3.77it/s, loss=0.840, v_num=0]#015Epoch 1:  30%|███       | 128/420 [00:33<01:17,  3.77it/s, loss=0.840, v_num=0]#015Epoch 1:  30%|███       | 128/420 [00:33<01:17,  3.77it/s, loss=0.854, v_num=0]#015Epoch 1:  31%|███       | 129/420 [00:34<01:17,  3.77it/s, loss=0.854, v_num=0]#015Epoch 1:  31%|███       | 129/420 [00:34<01:17,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  31%|███       | 130/420 [00:34<01:16,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  31%|███       | 130/420 [00:34<01:16,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  31%|███       | 131/420 [00:34<01:16,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  31%|███       | 131/420 [00:34<01:16,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  31%|███▏      | 132/420 [00:34<01:16,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  31%|███▏      | 132/420 [00:34<01:16,  3.77it/s, loss=0.837, v_num=0]#015Epoch 1:  32%|███▏      | 133/420 [00:35<01:16,  3.77it/s, loss=0.837, v_num=0]#015Epoch 1:  32%|███▏      | 133/420 [00:35<01:16,  3.77it/s, loss=0.836, v_num=0]#015Epoch 1:  32%|███▏      | 134/420 [00:35<01:15,  3.77it/s, loss=0.836, v_num=0]#015Epoch 1:  32%|███▏      | 134/420 [00:35<01:15,  3.77it/s, loss=0.852, v_num=0]#015Epoch 1:  32%|███▏      | 135/420 [00:35<01:15,  3.77it/s, loss=0.852, v_num=0]#015Epoch 1:  32%|███▏      | 135/420 [00:35<01:15,  3.77it/s, loss=0.835, v_num=0]#015Epoch 1:  32%|███▏      | 136/420 [00:36<01:15,  3.77it/s, loss=0.835, v_num=0]#015Epoch 1:  32%|███▏      | 136/420 [00:36<01:15,  3.77it/s, loss=0.827, v_num=0]#015Epoch 1:  33%|███▎      | 137/420 [00:36<01:15,  3.77it/s, loss=0.827, v_num=0]#015Epoch 1:  33%|███▎      | 137/420 [00:36<01:15,  3.77it/s, loss=0.822, v_num=0]#015Epoch 1:  33%|███▎      | 138/420 [00:36<01:14,  3.77it/s, loss=0.822, v_num=0]#015Epoch 1:  33%|███▎      | 138/420 [00:36<01:14,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  33%|███▎      | 139/420 [00:36<01:14,  3.77it/s, loss=0.832, v_num=0]#015Epoch 1:  33%|███▎      | 139/420 [00:36<01:14,  3.77it/s, loss=0.816, v_num=0]#015Epoch 1:  33%|███▎      | 140/420 [00:37<01:14,  3.77it/s, loss=0.816, v_num=0]#015Epoch 1:  33%|███▎      | 140/420 [00:37<01:14,  3.77it/s, loss=0.814, v_num=0]#015Epoch 1:  34%|███▎      | 141/420 [00:37<01:14,  3.77it/s, loss=0.814, v_num=0]#015Epoch 1:  34%|███▎      | 141/420 [00:37<01:14,  3.77it/s, loss=0.803, v_num=0]#015Epoch 1:  34%|███▍      | 142/420 [00:37<01:13,  3.77it/s, loss=0.803, v_num=0]#015Epoch 1:  34%|███▍      | 142/420 [00:37<01:13,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  34%|███▍      | 143/420 [00:37<01:13,  3.77it/s, loss=0.825, v_num=0]#015Epoch 1:  34%|███▍      | 143/420 [00:37<01:13,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  34%|███▍      | 144/420 [00:38<01:13,  3.77it/s, loss=0.839, v_num=0]#015Epoch 1:  34%|███▍      | 144/420 [00:38<01:13,  3.77it/s, loss=0.801, v_num=0]#015Epoch 1:  35%|███▍      | 145/420 [00:38<01:13,  3.77it/s, loss=0.801, v_num=0]#015Epoch 1:  35%|███▍      | 145/420 [00:38<01:13,  3.77it/s, loss=0.830, v_num=0]#015Epoch 1:  35%|███▍      | 146/420 [00:38<01:12,  3.77it/s, loss=0.830, v_num=0]#015Epoch 1:  35%|███▍      | 146/420 [00:38<01:12,  3.77it/s, loss=0.863, v_num=0]#015Epoch 1:  35%|███▌      | 147/420 [00:39<01:12,  3.77it/s, loss=0.863, v_num=0]#015Epoch 1:  35%|███▌      | 147/420 [00:39<01:12,  3.77it/s, loss=0.903, v_num=0]#015Epoch 1:  35%|███▌      | 148/420 [00:39<01:12,  3.76it/s, loss=0.903, v_num=0]#015Epoch 1:  35%|███▌      | 148/420 [00:39<01:12,  3.76it/s, loss=0.889, v_num=0]#015Epoch 1:  35%|███▌      | 149/420 [00:39<01:11,  3.76it/s, loss=0.889, v_num=0]#015Epoch 1:  35%|███▌      | 149/420 [00:39<01:11,  3.76it/s, loss=0.902, v_num=0]#015Epoch 1:  36%|███▌      | 150/420 [00:39<01:11,  3.76it/s, loss=0.902, v_num=0]#015Epoch 1:  36%|███▌      | 150/420 [00:39<01:11,  3.76it/s, loss=0.918, v_num=0]#015Epoch 1:  36%|███▌      | 151/420 [00:40<01:11,  3.76it/s, loss=0.918, v_num=0]#015Epoch 1:  36%|███▌      | 151/420 [00:40<01:11,  3.76it/s, loss=0.914, v_num=0]#015Epoch 1:  36%|███▌      | 152/420 [00:40<01:11,  3.76it/s, loss=0.914, v_num=0]#015Epoch 1:  36%|███▌      | 152/420 [00:40<01:11,  3.76it/s, loss=0.896, v_num=0]#015Epoch 1:  36%|███▋      | 153/420 [00:40<01:10,  3.76it/s, loss=0.896, v_num=0]#015Epoch 1:  36%|███▋      | 153/420 [00:40<01:10,  3.76it/s, loss=0.903, v_num=0]#015Epoch 1:  37%|███▋      | 154/420 [00:40<01:10,  3.76it/s, loss=0.903, v_num=0]#015Epoch 1:  37%|███▋      | 154/420 [00:40<01:10,  3.76it/s, loss=0.930, v_num=0]#015Epoch 1:  37%|███▋      | 155/420 [00:41<01:10,  3.76it/s, loss=0.930, v_num=0]#015Epoch 1:  37%|███▋      | 155/420 [00:41<01:10,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  37%|███▋      | 156/420 [00:41<01:10,  3.76it/s, loss=0.952, v_num=0]#015Epoch 1:  37%|███▋      | 156/420 [00:41<01:10,  3.76it/s, loss=0.954, v_num=0]#015Epoch 1:  37%|███▋      | 157/420 [00:41<01:09,  3.76it/s, loss=0.954, v_num=0]#015Epoch 1:  37%|███▋      | 157/420 [00:41<01:09,  3.76it/s, loss=0.950, v_num=0]#015Epoch 1:  38%|███▊      | 158/420 [00:41<01:09,  3.77it/s, loss=0.950, v_num=0]#015Epoch 1:  38%|███▊      | 158/420 [00:41<01:09,  3.77it/s, loss=0.933, v_num=0]#015Epoch 1:  38%|███▊      | 159/420 [00:42<01:09,  3.77it/s, loss=0.933, v_num=0]#015Epoch 1:  38%|███▊      | 159/420 [00:42<01:09,  3.77it/s, loss=0.946, v_num=0]#015Epoch 1:  38%|███▊      | 160/420 [00:42<01:08,  3.77it/s, loss=0.946, v_num=0]#015Epoch 1:  38%|███▊      | 160/420 [00:42<01:08,  3.77it/s, loss=0.958, v_num=0]#015Epoch 1:  38%|███▊      | 161/420 [00:42<01:08,  3.77it/s, loss=0.958, v_num=0]#015Epoch 1:  38%|███▊      | 161/420 [00:42<01:08,  3.77it/s, loss=0.960, v_num=0]#015Epoch 1:  39%|███▊      | 162/420 [00:42<01:08,  3.77it/s, loss=0.960, v_num=0]#015Epoch 1:  39%|███▊      | 162/420 [00:42<01:08,  3.77it/s, loss=0.943, v_num=0]#015Epoch 1:  39%|███▉      | 163/420 [00:43<01:08,  3.77it/s, loss=0.943, v_num=0]#015Epoch 1:  39%|███▉      | 163/420 [00:43<01:08,  3.77it/s, loss=0.926, v_num=0]#015Epoch 1:  39%|███▉      | 164/420 [00:43<01:07,  3.77it/s, loss=0.926, v_num=0]#015Epoch 1:  39%|███▉      | 164/420 [00:43<01:07,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  39%|███▉      | 165/420 [00:43<01:07,  3.77it/s, loss=0.953, v_num=0]#015Epoch 1:  39%|███▉      | 165/420 [00:43<01:07,  3.77it/s, loss=0.938, v_num=0]#015Epoch 1:  40%|███▉      | 166/420 [00:43<01:07,  3.77it/s, loss=0.938, v_num=0]#015Epoch 1:  40%|███▉      | 166/420 [00:43<01:07,  3.77it/s, loss=0.916, v_num=0]#015Epoch 1:  40%|███▉      | 167/420 [00:44<01:06,  3.78it/s, loss=0.916, v_num=0]#015Epoch 1:  40%|███▉      | 167/420 [00:44<01:06,  3.78it/s, loss=0.890, v_num=0]#015Epoch 1:  40%|████      | 168/420 [00:44<01:06,  3.78it/s, loss=0.890, v_num=0]#015Epoch 1:  40%|████      | 168/420 [00:44<01:06,  3.78it/s, loss=0.891, v_num=0]#015Epoch 1:  40%|████      | 169/420 [00:44<01:06,  3.78it/s, loss=0.891, v_num=0]#015Epoch 1:  40%|████      | 169/420 [00:44<01:06,  3.78it/s, loss=0.882, v_num=0]#015Epoch 1:  40%|████      | 170/420 [00:44<01:06,  3.78it/s, loss=0.882, v_num=0]#015Epoch 1:  40%|████      | 170/420 [00:44<01:06,  3.78it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|████      | 171/420 [00:45<01:05,  3.78it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|████      | 171/420 [00:45<01:05,  3.78it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|████      | 172/420 [00:45<01:05,  3.79it/s, loss=0.872, v_num=0]#015Epoch 1:  41%|████      | 172/420 [00:45<01:05,  3.79it/s, loss=0.884, v_num=0]#015Epoch 1:  41%|████      | 173/420 [00:45<01:05,  3.79it/s, loss=0.884, v_num=0]#015Epoch 1:  41%|████      | 173/420 [00:45<01:05,  3.79it/s, loss=0.928, v_num=0]#015Epoch 1:  41%|████▏     | 174/420 [00:45<01:04,  3.79it/s, loss=0.928, v_num=0]#015Epoch 1:  41%|████▏     | 174/420 [00:45<01:04,  3.79it/s, loss=0.894, v_num=0]#015Epoch 1:  42%|████▏     | 175/420 [00:46<01:04,  3.79it/s, loss=0.894, v_num=0]#015Epoch 1:  42%|████▏     | 175/420 [00:46<01:04,  3.79it/s, loss=0.922, v_num=0]#015Epoch 1:  42%|████▏     | 176/420 [00:46<01:04,  3.79it/s, loss=0.922, v_num=0]#015Epoch 1:  42%|████▏     | 176/420 [00:46<01:04,  3.79it/s, loss=0.933, v_num=0]#015Epoch 1:  42%|████▏     | 177/420 [00:46<01:04,  3.79it/s, loss=0.933, v_num=0]#015Epoch 1:  42%|████▏     | 177/420 [00:46<01:04,  3.79it/s, loss=0.929, v_num=0]#015Epoch 1:  42%|████▏     | 178/420 [00:46<01:03,  3.79it/s, loss=0.929, v_num=0]#015Epoch 1:  42%|████▏     | 178/420 [00:46<01:03,  3.79it/s, loss=0.947, v_num=0]#015Epoch 1:  43%|████▎     | 179/420 [00:47<01:03,  3.80it/s, loss=0.947, v_num=0]#015Epoch 1:  43%|████▎     | 179/420 [00:47<01:03,  3.80it/s, loss=0.939, v_num=0]#015Epoch 1:  43%|████▎     | 180/420 [00:47<01:03,  3.80it/s, loss=0.939, v_num=0]#015Epoch 1:  43%|████▎     | 180/420 [00:47<01:03,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  43%|████▎     | 181/420 [00:47<01:02,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  43%|████▎     | 181/420 [00:47<01:02,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  43%|████▎     | 182/420 [00:47<01:02,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  43%|████▎     | 182/420 [00:47<01:02,  3.80it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|████▎     | 183/420 [00:48<01:02,  3.80it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|████▎     | 183/420 [00:48<01:02,  3.80it/s, loss=0.927, v_num=0]#015Epoch 1:  44%|████▍     | 184/420 [00:48<01:02,  3.80it/s, loss=0.927, v_num=0]#015Epoch 1:  44%|████▍     | 184/420 [00:48<01:02,  3.80it/s, loss=0.917, v_num=0]#015Epoch 1:  44%|████▍     | 185/420 [00:48<01:01,  3.81it/s, loss=0.917, v_num=0]#015Epoch 1:  44%|████▍     | 185/420 [00:48<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|████▍     | 186/420 [00:48<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  44%|████▍     | 186/420 [00:48<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  45%|████▍     | 187/420 [00:49<01:01,  3.81it/s, loss=0.923, v_num=0]#015Epoch 1:  45%|████▍     | 187/420 [00:49<01:01,  3.81it/s, loss=0.918, v_num=0]#015Epoch 1:  45%|████▍     | 188/420 [00:49<01:00,  3.81it/s, loss=0.918, v_num=0]#015Epoch 1:  45%|████▍     | 188/420 [00:49<01:00,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  45%|████▌     | 189/420 [00:49<01:00,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  45%|████▌     | 189/420 [00:49<01:00,  3.81it/s, loss=0.903, v_num=0]#015Epoch 1:  45%|████▌     | 190/420 [00:49<01:00,  3.81it/s, loss=0.903, v_num=0]#015Epoch 1:  45%|████▌     | 190/420 [00:49<01:00,  3.81it/s, loss=0.900, v_num=0]#015Epoch 1:  45%|████▌     | 191/420 [00:50<01:00,  3.81it/s, loss=0.900, v_num=0]#015Epoch 1:  45%|████▌     | 191/420 [00:50<01:00,  3.81it/s, loss=0.911, v_num=0]#015Epoch 1:  46%|████▌     | 192/420 [00:50<00:59,  3.81it/s, loss=0.911, v_num=0]#015Epoch 1:  46%|████▌     | 192/420 [00:50<00:59,  3.81it/s, loss=0.914, v_num=0]#015Epoch 1:  46%|████▌     | 193/420 [00:50<00:59,  3.81it/s, loss=0.914, v_num=0]#015Epoch\u001B[0m\n",
      "\u001B[34m 1:  46%|████▌     | 193/420 [00:50<00:59,  3.81it/s, loss=0.838, v_num=0]#015Epoch 1:  46%|████▌     | 194/420 [00:50<00:59,  3.81it/s, loss=0.838, v_num=0]#015Epoch 1:  46%|████▌     | 194/420 [00:50<00:59,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  46%|████▋     | 195/420 [00:51<00:59,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  46%|████▋     | 195/420 [00:51<00:59,  3.81it/s, loss=0.785, v_num=0]#015Epoch 1:  47%|████▋     | 196/420 [00:51<00:58,  3.80it/s, loss=0.785, v_num=0]#015Epoch 1:  47%|████▋     | 196/420 [00:51<00:58,  3.80it/s, loss=0.765, v_num=0]#015Epoch 1:  47%|████▋     | 197/420 [00:51<00:58,  3.80it/s, loss=0.765, v_num=0]#015Epoch 1:  47%|████▋     | 197/420 [00:51<00:58,  3.80it/s, loss=0.766, v_num=0]#015Epoch 1:  47%|████▋     | 198/420 [00:52<00:58,  3.81it/s, loss=0.766, v_num=0]#015Epoch 1:  47%|████▋     | 198/420 [00:52<00:58,  3.81it/s, loss=0.753, v_num=0]#015Epoch 1:  47%|████▋     | 199/420 [00:52<00:58,  3.81it/s, loss=0.753, v_num=0]#015Epoch 1:  47%|████▋     | 199/420 [00:52<00:58,  3.81it/s, loss=0.754, v_num=0]#015Epoch 1:  48%|████▊     | 200/420 [00:52<00:57,  3.81it/s, loss=0.754, v_num=0]#015Epoch 1:  48%|████▊     | 200/420 [00:52<00:57,  3.81it/s, loss=0.744, v_num=0]#015Epoch 1:  48%|████▊     | 201/420 [00:52<00:57,  3.81it/s, loss=0.744, v_num=0]#015Epoch 1:  48%|████▊     | 201/420 [00:52<00:57,  3.81it/s, loss=0.747, v_num=0]#015Epoch 1:  48%|████▊     | 202/420 [00:53<00:57,  3.81it/s, loss=0.747, v_num=0]#015Epoch 1:  48%|████▊     | 202/420 [00:53<00:57,  3.81it/s, loss=0.757, v_num=0]#015Epoch 1:  48%|████▊     | 203/420 [00:53<00:57,  3.81it/s, loss=0.757, v_num=0]#015Epoch 1:  48%|████▊     | 203/420 [00:53<00:57,  3.81it/s, loss=0.756, v_num=0]#015Epoch 1:  49%|████▊     | 204/420 [00:53<00:56,  3.81it/s, loss=0.756, v_num=0]#015Epoch 1:  49%|████▊     | 204/420 [00:53<00:56,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|████▉     | 205/420 [00:53<00:56,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|████▉     | 205/420 [00:53<00:56,  3.81it/s, loss=0.790, v_num=0]#015Epoch 1:  49%|████▉     | 206/420 [00:54<00:56,  3.81it/s, loss=0.790, v_num=0]#015Epoch 1:  49%|████▉     | 206/420 [00:54<00:56,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|████▉     | 207/420 [00:54<00:55,  3.81it/s, loss=0.792, v_num=0]#015Epoch 1:  49%|████▉     | 207/420 [00:54<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|████▉     | 208/420 [00:54<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|████▉     | 208/420 [00:54<00:55,  3.81it/s, loss=0.812, v_num=0]#015Epoch 1:  50%|████▉     | 209/420 [00:54<00:55,  3.81it/s, loss=0.812, v_num=0]#015Epoch 1:  50%|████▉     | 209/420 [00:54<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|█████     | 210/420 [00:55<00:55,  3.81it/s, loss=0.795, v_num=0]#015Epoch 1:  50%|█████     | 210/420 [00:55<00:55,  3.81it/s, loss=0.807, v_num=0]#015Epoch 1:  50%|█████     | 211/420 [00:55<00:54,  3.81it/s, loss=0.807, v_num=0]#015Epoch 1:  50%|█████     | 211/420 [00:55<00:54,  3.81it/s, loss=0.809, v_num=0]#015Epoch 1:  50%|█████     | 212/420 [00:55<00:54,  3.81it/s, loss=0.809, v_num=0]#015Epoch 1:  50%|█████     | 212/420 [00:55<00:54,  3.81it/s, loss=0.798, v_num=0]#015Epoch 1:  51%|█████     | 213/420 [00:55<00:54,  3.81it/s, loss=0.798, v_num=0]#015Epoch 1:  51%|█████     | 213/420 [00:55<00:54,  3.81it/s, loss=0.848, v_num=0]#015Epoch 1:  51%|█████     | 214/420 [00:56<00:54,  3.81it/s, loss=0.848, v_num=0]#015Epoch 1:  51%|█████     | 214/420 [00:56<00:54,  3.81it/s, loss=0.858, v_num=0]#015Epoch 1:  51%|█████     | 215/420 [00:56<00:53,  3.81it/s, loss=0.858, v_num=0]#015Epoch 1:  51%|█████     | 215/420 [00:56<00:53,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  51%|█████▏    | 216/420 [00:56<00:53,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  51%|█████▏    | 216/420 [00:56<00:53,  3.81it/s, loss=0.861, v_num=0]#015Epoch 1:  52%|█████▏    | 217/420 [00:56<00:53,  3.81it/s, loss=0.861, v_num=0]#015Epoch 1:  52%|█████▏    | 217/420 [00:56<00:53,  3.81it/s, loss=0.873, v_num=0]#015Epoch 1:  52%|█████▏    | 218/420 [00:57<00:53,  3.81it/s, loss=0.873, v_num=0]#015Epoch 1:  52%|█████▏    | 218/420 [00:57<00:53,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  52%|█████▏    | 219/420 [00:57<00:52,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  52%|█████▏    | 219/420 [00:57<00:52,  3.81it/s, loss=0.885, v_num=0]#015Epoch 1:  52%|█████▏    | 220/420 [00:57<00:52,  3.81it/s, loss=0.885, v_num=0]#015Epoch 1:  52%|█████▏    | 220/420 [00:57<00:52,  3.81it/s, loss=0.883, v_num=0]#015Epoch 1:  53%|█████▎    | 221/420 [00:58<00:52,  3.81it/s, loss=0.883, v_num=0]#015Epoch 1:  53%|█████▎    | 221/420 [00:58<00:52,  3.81it/s, loss=0.876, v_num=0]#015Epoch 1:  53%|█████▎    | 222/420 [00:58<00:52,  3.80it/s, loss=0.876, v_num=0]#015Epoch 1:  53%|█████▎    | 222/420 [00:58<00:52,  3.80it/s, loss=0.881, v_num=0]#015Epoch 1:  53%|█████▎    | 223/420 [00:58<00:51,  3.80it/s, loss=0.881, v_num=0]#015Epoch 1:  53%|█████▎    | 223/420 [00:58<00:51,  3.80it/s, loss=0.885, v_num=0]#015Epoch 1:  53%|█████▎    | 224/420 [00:58<00:51,  3.80it/s, loss=0.885, v_num=0]#015Epoch 1:  53%|█████▎    | 224/420 [00:58<00:51,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  54%|█████▎    | 225/420 [00:59<00:51,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  54%|█████▎    | 225/420 [00:59<00:51,  3.80it/s, loss=0.871, v_num=0]#015Epoch 1:  54%|█████▍    | 226/420 [00:59<00:51,  3.80it/s, loss=0.871, v_num=0]#015Epoch 1:  54%|█████▍    | 226/420 [00:59<00:51,  3.80it/s, loss=0.873, v_num=0]#015Epoch 1:  54%|█████▍    | 227/420 [00:59<00:50,  3.80it/s, loss=0.873, v_num=0]#015Epoch 1:  54%|█████▍    | 227/420 [00:59<00:50,  3.80it/s, loss=0.880, v_num=0]#015Epoch 1:  54%|█████▍    | 228/420 [00:59<00:50,  3.80it/s, loss=0.880, v_num=0]#015Epoch 1:  54%|█████▍    | 228/420 [00:59<00:50,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  55%|█████▍    | 229/420 [01:00<00:50,  3.80it/s, loss=0.887, v_num=0]#015Epoch 1:  55%|█████▍    | 229/420 [01:00<00:50,  3.80it/s, loss=0.928, v_num=0]#015Epoch 1:  55%|█████▍    | 230/420 [01:00<00:49,  3.80it/s, loss=0.928, v_num=0]#015Epoch 1:  55%|█████▍    | 230/420 [01:00<00:49,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  55%|█████▌    | 231/420 [01:00<00:49,  3.80it/s, loss=0.940, v_num=0]#015Epoch 1:  55%|█████▌    | 231/420 [01:00<00:49,  3.80it/s, loss=0.920, v_num=0]#015Epoch 1:  55%|█████▌    | 232/420 [01:00<00:49,  3.80it/s, loss=0.920, v_num=0]#015Epoch 1:  55%|█████▌    | 232/420 [01:00<00:49,  3.80it/s, loss=0.926, v_num=0]#015Epoch 1:  55%|█████▌    | 233/420 [01:01<00:49,  3.80it/s, loss=0.926, v_num=0]#015Epoch 1:  55%|█████▌    | 233/420 [01:01<00:49,  3.80it/s, loss=0.900, v_num=0]#015Epoch 1:  56%|█████▌    | 234/420 [01:01<00:48,  3.80it/s, loss=0.900, v_num=0]#015Epoch 1:  56%|█████▌    | 234/420 [01:01<00:48,  3.80it/s, loss=0.942, v_num=0]#015Epoch 1:  56%|█████▌    | 235/420 [01:01<00:48,  3.80it/s, loss=0.942, v_num=0]#015Epoch 1:  56%|█████▌    | 235/420 [01:01<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|█████▌    | 236/420 [01:02<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|█████▌    | 236/420 [01:02<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|█████▋    | 237/420 [01:02<00:48,  3.80it/s, loss=0.959, v_num=0]#015Epoch 1:  56%|█████▋    | 237/420 [01:02<00:48,  3.80it/s, loss=0.950, v_num=0]#015Epoch 1:  57%|█████▋    | 238/420 [01:02<00:47,  3.80it/s, loss=0.950, v_num=0]#015Epoch 1:  57%|█████▋    | 238/420 [01:02<00:47,  3.80it/s, loss=0.962, v_num=0]#015Epoch 1:  57%|█████▋    | 239/420 [01:02<00:47,  3.80it/s, loss=0.962, v_num=0]#015Epoch 1:  57%|█████▋    | 239/420 [01:02<00:47,  3.80it/s, loss=0.935, v_num=0]#015Epoch 1:  57%|█████▋    | 240/420 [01:03<00:47,  3.80it/s, loss=0.935, v_num=0]#015Epoch 1:  57%|█████▋    | 240/420 [01:03<00:47,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  57%|█████▋    | 241/420 [01:03<00:47,  3.80it/s, loss=0.946, v_num=0]#015Epoch 1:  57%|█████▋    | 241/420 [01:03<00:47,  3.80it/s, loss=0.955, v_num=0]#015Epoch 1:  58%|█████▊    | 242/420 [01:03<00:46,  3.80it/s, loss=0.955, v_num=0]#015Epoch 1:  58%|█████▊    | 242/420 [01:03<00:46,  3.80it/s, loss=1.005, v_num=0]#015Epoch 1:  58%|█████▊    | 243/420 [01:03<00:46,  3.80it/s, loss=1.005, v_num=0]#015Epoch 1:  58%|█████▊    | 243/420 [01:03<00:46,  3.80it/s, loss=1.014, v_num=0]#015Epoch 1:  58%|█████▊    | 244/420 [01:04<00:46,  3.80it/s, loss=1.014, v_num=0]#015Epoch 1:  58%|█████▊    | 244/420 [01:04<00:46,  3.80it/s, loss=0.975, v_num=0]#015Epoch 1:  58%|█████▊    | 245/420 [01:04<00:45,  3.80it/s, loss=0.975, v_num=0]#015Epoch 1:  58%|█████▊    | 245/420 [01:04<00:45,  3.80it/s, loss=0.982, v_num=0]#015Epoch 1:  59%|█████▊    | 246/420 [01:04<00:45,  3.81it/s, loss=0.982, v_num=0]#015Epoch 1:  59%|█████▊    | 246/420 [01:04<00:45,  3.81it/s, loss=0.965, v_num=0]#015Epoch 1:  59%|█████▉    | 247/420 [01:04<00:45,  3.81it/s, loss=0.965, v_num=0]#015Epoch 1:  59%|█████▉    | 247/420 [01:04<00:45,  3.81it/s, loss=0.970, v_num=0]#015Epoch 1:  59%|█████▉    | 248/420 [01:05<00:45,  3.81it/s, loss=0.970, v_num=0]#015Epoch 1:  59%|█████▉    | 248/420 [01:05<00:45,  3.81it/s, loss=0.960, v_num=0]#015Epoch 1:  59%|█████▉    | 249/420 [01:05<00:44,  3.81it/s, loss=0.960, v_num=0]#015Epoch 1:  59%|█████▉    | 249/420 [01:05<00:44,  3.81it/s, loss=0.943, v_num=0]#015Epoch 1:  60%|█████▉    | 250/420 [01:05<00:44,  3.81it/s, loss=0.943, v_num=0]#015Epoch 1:  60%|█████▉    | 250/420 [01:05<00:44,  3.81it/s, loss=0.934, v_num=0]#015Epoch 1:  60%|█████▉    | 251/420 [01:05<00:44,  3.81it/s, loss=0.934, v_num=0]#015Epoch 1:  60%|█████▉    | 251/420 [01:05<00:44,  3.81it/s, loss=0.951, v_num=0]#015Epoch 1:  60%|██████    | 252/420 [01:06<00:44,  3.81it/s, loss=0.951, v_num=0]#015Epoch 1:  60%|██████    | 252/420 [01:06<00:44,  3.81it/s, loss=0.944, v_num=0]#015Epoch 1:  60%|██████    | 253/420 [01:06<00:43,  3.81it/s, loss=0.944, v_num=0]#015Epoch 1:  60%|██████    | 253/420 [01:06<00:43,  3.81it/s, loss=0.929, v_num=0]#015Epoch 1:  60%|██████    | 254/420 [01:06<00:43,  3.81it/s, loss=0.929, v_num=0]#015Epoch 1:  60%|██████    | 254/420 [01:06<00:43,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  61%|██████    | 255/420 [01:07<00:43,  3.81it/s, loss=0.897, v_num=0]#015Epoch 1:  61%|██████    | 255/420 [01:07<00:43,  3.81it/s, loss=0.879, v_num=0]#015Epoch 1:  61%|██████    | 256/420 [01:07<00:43,  3.81it/s, loss=0.879, v_num=0]#015Epoch 1:  61%|██████    | 256/420 [01:07<00:43,  3.81it/s, loss=0.865, v_num=0]#015Epoch 1:  61%|██████    | 257/420 [01:07<00:42,  3.81it/s, loss=0.865, v_num=0]#015Epoch 1:  61%|██████    | 257/420 [01:07<00:42,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  61%|██████▏   | 258/420 [01:07<00:42,  3.81it/s, loss=0.850, v_num=0]#015Epoch 1:  61%|██████▏   | 258/420 [01:07<00:42,  3.81it/s, loss=0.851, v_num=0]#015Epoch 1:  62%|██████▏   | 259/420 [01:08<00:42,  3.81it/s, loss=0.851, v_num=0]#015Epoch 1:  62%|██████▏   | 259/420 [01:08<00:42,  3.81it/s, loss=0.872, v_num=0]#015Epoch 1:  62%|██████▏   | 260/420 [01:08<00:42,  3.81it/s, loss=0.872, v_num=0]#015Epoch 1:  62%|██████▏   | 260/420 [01:08<00:42,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  62%|██████▏   | 261/420 [01:08<00:41,  3.81it/s, loss=0.863, v_num=0]#015Epoch 1:  62%|██████▏   | 261/420 [01:08<00:41,  3.81it/s, loss=0.856, v_num=0]#015Epoch 1:  62%|██████▏   | 262/420 [01:08<00:41,  3.81it/s, loss=0.856, v_num=0]#015Epoch 1:  62%|██████▏   | 262/420 [01:08<00:41,  3.81it/s, loss=0.787, v_num=0]#015Epoch 1:  63%|██████▎   | 263/420 [01:09<00:41,  3.80it/s, loss=0.787, v_num=0]#015Epoch 1:  63%|██████▎   | 263/420 [01:09<00:41,  3.80it/s, loss=0.790, v_num=0]#015Epoch 1:  63%|██████▎   | 264/420 [01:09<00:40,  3.81it/s, loss=0.790, v_num=0]#015Epoch 1:  63%|██████▎   | 264/420 [01:09<00:40,  3.81it/s, loss=0.778, v_num=0]#015Epoch 1:  63%|██████▎   | 265/420 [01:09<00:40,  3.81it/s, loss=0.778, v_num=0]#015Epoch 1:  63%|██████▎   | 265/420 [01:09<00:40,  3.81it/s, loss=0.783, v_num=0]#015Epoch 1:  63%|██████▎   | 266/420 [01:09<00:40,  3.81it/s, loss=0.783, v_num=0]#015Epoch 1:  63%|██████▎   | 266/420 [01:09<00:40,  3.81it/s, loss=0.799, v_num=0]#015Epoch 1:  64%|██████▎   | 267/420 [01:10<00:40,  3.81it/s, loss=0.799, v_num=0]#015Epoch 1:  64%|██████▎   | 267/420 [01:10<00:40,  3.81it/s, loss=0.780, v_num=0]#015Epoch 1:  64%|██████▍   | 268/420 [01:10<00:39,  3.81it/s, loss=0.780, v_num=0]#015Epoch 1:  64%|██████▍   | 268/420 [01:10<00:39,  3.81it/s, loss=0.845, v_num=0]#015Epoch 1:  64%|██████▍   | 269/420 [01:10<00:39,  3.81it/s, loss=0.845, v_num=0]#015Epoch 1:  64%|██████▍   | 269/420 [01:10<00:39,  3.81it/s, loss=0.815, v_num=0]#015Epoch 1:  64%|██████▍   | 270/420 [01:10<00:39,  3.81it/s, loss=0.815, v_num=0]#015Epoch 1:  64%|██████▍   | 270/420 [01:10<00:39,  3.81it/s, loss=0.824, v_num=0]#015Epoch 1:  65%|██████▍   | 271/420 [01:11<00:39,  3.81it/s, loss=0.824, v_num=0]#015Epoch 1:  65%|██████▍   | 271/420 [01:11<00:39,  3.81it/s, loss=0.816, v_num=0]#015Epoch 1:  65%|██████▍   | 272/420 [01:11<00:38,  3.81it/s, loss=0.816, v_num=0]#015Epoch 1:  65%|██████▍   | 272/420 [01:11<00:38,  3.81it/s, loss=0.832, v_num=0]#015Epoch 1:  65%|██████▌   | 273/420 [01:11<00:38,  3.81it/s, loss=0.832, v_num=0]#015Epoch 1:  65%|██████▌   | 273/420 [01:11<00:38,  3.81it/s, loss=0.844, v_num=0]#015Epoch 1:  65%|██████▌   | 274/420 [01:11<00:38,  3.81it/s, loss=0.844, v_num=0]#015Epoch 1:  65%|██████▌   | 274/420 [01:11<00:38,  3.81it/s, loss=0.825, v_num=0]#015Epoch 1:  65%|██████▌   | 275/420 [01:12<00:38,  3.81it/s, loss=0.825, v_num=0]#015Epoch 1:  65%|██████▌   | 275/420 [01:12<00:38,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  66%|██████▌   | 276/420 [01:12<00:37,  3.81it/s, loss=0.818, v_num=0]#015Epoch 1:  66%|██████▌   | 276/420 [01:12<00:37,  3.81it/s, loss=0.838, v_num=0]#015Epoch 1:  66%|██████▌   | 277/420 [01:12<00:37,  3.80it/s, loss=0.838, v_num=0]#015Epoch 1:  66%|██████▌   | 277/420 [01:12<00:37,  3.80it/s, loss=0.866, v_num=0]#015Epoch 1:  66%|██████▌   | 278/420 [01:13<00:37,  3.81it/s, loss=0.866, v_num=0]#015Epoch 1:  66%|██████▌   | 278/420 [01:13<00:37,  3.80it/s, loss=0.853, v_num=0]#015Epoch 1:  66%|██████▋   | 279/420 [01:13<00:37,  3.80it/s, loss=0.853, v_num=0]#015Epoch 1:  66%|██████▋   | 279/420 [01:13<00:37,  3.80it/s, loss=0.833, v_num=0]#015Epoch 1:  67%|██████▋   | 280/420 [01:13<00:36,  3.80it/s, loss=0.833, v_num=0]#015Epoch 1:  67%|██████▋   | 280/420 [01:13<00:36,  3.80it/s, loss=0.830, v_num=0]#015Epoch 1:  67%|██████▋   | 281/420 [01:13<00:36,  3.80it/s, loss=0.830, v_num=0]#015Epoch 1:  67%|██████▋   | 281/420 [01:13<00:36,  3.80it/s, loss=0.844, v_num=0]#015Epoch 1:  67%|██████▋   | 282/420 [01:14<00:36,  3.80it/s, loss=0.844, v_num=0]#015Epoch\u001B[0m\n",
      "\u001B[34m 1:  67%|██████▋   | 282/420 [01:14<00:36,  3.80it/s, loss=0.859, v_num=0]#015Epoch 1:  67%|██████▋   | 283/420 [01:14<00:36,  3.80it/s, loss=0.859, v_num=0]#015Epoch 1:  67%|██████▋   | 283/420 [01:14<00:36,  3.80it/s, loss=0.835, v_num=0]#015Epoch 1:  68%|██████▊   | 284/420 [01:14<00:35,  3.80it/s, loss=0.835, v_num=0]#015Epoch 1:  68%|██████▊   | 284/420 [01:14<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|██████▊   | 285/420 [01:14<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|██████▊   | 285/420 [01:14<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|██████▊   | 286/420 [01:15<00:35,  3.80it/s, loss=0.843, v_num=0]#015Epoch 1:  68%|██████▊   | 286/420 [01:15<00:35,  3.80it/s, loss=0.825, v_num=0]#015Epoch 1:  68%|██████▊   | 287/420 [01:15<00:35,  3.80it/s, loss=0.825, v_num=0]#015Epoch 1:  68%|██████▊   | 287/420 [01:15<00:35,  3.80it/s, loss=0.839, v_num=0]#015Epoch 1:  69%|██████▊   | 288/420 [01:15<00:34,  3.80it/s, loss=0.839, v_num=0]#015Epoch 1:  69%|██████▊   | 288/420 [01:15<00:34,  3.80it/s, loss=0.767, v_num=0]#015Epoch 1:  69%|██████▉   | 289/420 [01:16<00:34,  3.80it/s, loss=0.767, v_num=0]#015Epoch 1:  69%|██████▉   | 289/420 [01:16<00:34,  3.80it/s, loss=0.775, v_num=0]#015Epoch 1:  69%|██████▉   | 290/420 [01:16<00:34,  3.80it/s, loss=0.775, v_num=0]#015Epoch 1:  69%|██████▉   | 290/420 [01:16<00:34,  3.80it/s, loss=0.751, v_num=0]#015Epoch 1:  69%|██████▉   | 291/420 [01:16<00:33,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  69%|██████▉   | 291/420 [01:16<00:33,  3.79it/s, loss=0.739, v_num=0]#015Epoch 1:  70%|██████▉   | 292/420 [01:16<00:33,  3.80it/s, loss=0.739, v_num=0]#015Epoch 1:  70%|██████▉   | 292/420 [01:16<00:33,  3.80it/s, loss=0.720, v_num=0]#015Epoch 1:  70%|██████▉   | 293/420 [01:17<00:33,  3.79it/s, loss=0.720, v_num=0]#015Epoch 1:  70%|██████▉   | 293/420 [01:17<00:33,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  70%|███████   | 294/420 [01:17<00:33,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  70%|███████   | 294/420 [01:17<00:33,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  70%|███████   | 295/420 [01:17<00:32,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  70%|███████   | 295/420 [01:17<00:32,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  70%|███████   | 296/420 [01:18<00:32,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  70%|███████   | 296/420 [01:18<00:32,  3.79it/s, loss=0.721, v_num=0]#015Epoch 1:  71%|███████   | 297/420 [01:18<00:32,  3.79it/s, loss=0.721, v_num=0]#015Epoch 1:  71%|███████   | 297/420 [01:18<00:32,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  71%|███████   | 298/420 [01:18<00:32,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  71%|███████   | 298/420 [01:18<00:32,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  71%|███████   | 299/420 [01:18<00:31,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  71%|███████   | 299/420 [01:18<00:31,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  71%|███████▏  | 300/420 [01:19<00:31,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  71%|███████▏  | 300/420 [01:19<00:31,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  72%|███████▏  | 301/420 [01:19<00:31,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  72%|███████▏  | 301/420 [01:19<00:31,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  72%|███████▏  | 302/420 [01:19<00:31,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  72%|███████▏  | 302/420 [01:19<00:31,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  72%|███████▏  | 303/420 [01:19<00:30,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  72%|███████▏  | 303/420 [01:19<00:30,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  72%|███████▏  | 304/420 [01:20<00:30,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  72%|███████▏  | 304/420 [01:20<00:30,  3.79it/s, loss=0.796, v_num=0]#015Epoch 1:  73%|███████▎  | 305/420 [01:20<00:30,  3.79it/s, loss=0.796, v_num=0]#015Epoch 1:  73%|███████▎  | 305/420 [01:20<00:30,  3.79it/s, loss=0.797, v_num=0]#015Epoch 1:  73%|███████▎  | 306/420 [01:20<00:30,  3.79it/s, loss=0.797, v_num=0]#015Epoch 1:  73%|███████▎  | 306/420 [01:20<00:30,  3.79it/s, loss=0.810, v_num=0]#015Epoch 1:  73%|███████▎  | 307/420 [01:20<00:29,  3.79it/s, loss=0.810, v_num=0]#015Epoch 1:  73%|███████▎  | 307/420 [01:20<00:29,  3.79it/s, loss=0.817, v_num=0]#015Epoch 1:  73%|███████▎  | 308/420 [01:21<00:29,  3.79it/s, loss=0.817, v_num=0]#015Epoch 1:  73%|███████▎  | 308/420 [01:21<00:29,  3.79it/s, loss=0.821, v_num=0]#015Epoch 1:  74%|███████▎  | 309/420 [01:21<00:29,  3.79it/s, loss=0.821, v_num=0]#015Epoch 1:  74%|███████▎  | 309/420 [01:21<00:29,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  74%|███████▍  | 310/420 [01:21<00:29,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  74%|███████▍  | 310/420 [01:21<00:29,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  74%|███████▍  | 311/420 [01:22<00:28,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  74%|███████▍  | 311/420 [01:22<00:28,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  74%|███████▍  | 312/420 [01:22<00:28,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  74%|███████▍  | 312/420 [01:22<00:28,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  75%|███████▍  | 313/420 [01:22<00:28,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  75%|███████▍  | 313/420 [01:22<00:28,  3.79it/s, loss=0.851, v_num=0]#015Epoch 1:  75%|███████▍  | 314/420 [01:22<00:27,  3.79it/s, loss=0.851, v_num=0]#015Epoch 1:  75%|███████▍  | 314/420 [01:22<00:27,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  75%|███████▌  | 315/420 [01:23<00:27,  3.79it/s, loss=0.838, v_num=0]#015Epoch 1:  75%|███████▌  | 315/420 [01:23<00:27,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  75%|███████▌  | 316/420 [01:23<00:27,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  75%|███████▌  | 316/420 [01:23<00:27,  3.79it/s, loss=0.877, v_num=0]#015Epoch 1:  75%|███████▌  | 317/420 [01:23<00:27,  3.79it/s, loss=0.877, v_num=0]#015Epoch 1:  75%|███████▌  | 317/420 [01:23<00:27,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|███████▌  | 318/420 [01:23<00:26,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|███████▌  | 318/420 [01:23<00:26,  3.79it/s, loss=0.856, v_num=0]#015Epoch 1:  76%|███████▌  | 319/420 [01:24<00:26,  3.79it/s, loss=0.856, v_num=0]#015Epoch 1:  76%|███████▌  | 319/420 [01:24<00:26,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|███████▌  | 320/420 [01:24<00:26,  3.79it/s, loss=0.870, v_num=0]#015Epoch 1:  76%|███████▌  | 320/420 [01:24<00:26,  3.79it/s, loss=0.893, v_num=0]#015Epoch 1:  76%|███████▋  | 321/420 [01:24<00:26,  3.79it/s, loss=0.893, v_num=0]#015Epoch 1:  76%|███████▋  | 321/420 [01:24<00:26,  3.79it/s, loss=0.890, v_num=0]#015Epoch 1:  77%|███████▋  | 322/420 [01:25<00:25,  3.79it/s, loss=0.890, v_num=0]#015Epoch 1:  77%|███████▋  | 322/420 [01:25<00:25,  3.79it/s, loss=0.905, v_num=0]#015Epoch 1:  77%|███████▋  | 323/420 [01:25<00:25,  3.79it/s, loss=0.905, v_num=0]#015Epoch 1:  77%|███████▋  | 323/420 [01:25<00:25,  3.79it/s, loss=0.881, v_num=0]#015Epoch 1:  77%|███████▋  | 324/420 [01:25<00:25,  3.79it/s, loss=0.881, v_num=0]#015Epoch 1:  77%|███████▋  | 324/420 [01:25<00:25,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  77%|███████▋  | 325/420 [01:25<00:25,  3.79it/s, loss=0.855, v_num=0]#015Epoch 1:  77%|███████▋  | 325/420 [01:25<00:25,  3.79it/s, loss=0.852, v_num=0]#015Epoch 1:  78%|███████▊  | 326/420 [01:26<00:24,  3.79it/s, loss=0.852, v_num=0]#015Epoch 1:  78%|███████▊  | 326/420 [01:26<00:24,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  78%|███████▊  | 327/420 [01:26<00:24,  3.79it/s, loss=0.843, v_num=0]#015Epoch 1:  78%|███████▊  | 327/420 [01:26<00:24,  3.79it/s, loss=0.834, v_num=0]#015Epoch 1:  78%|███████▊  | 328/420 [01:26<00:24,  3.79it/s, loss=0.834, v_num=0]#015Epoch 1:  78%|███████▊  | 328/420 [01:26<00:24,  3.79it/s, loss=0.827, v_num=0]#015Epoch 1:  78%|███████▊  | 329/420 [01:26<00:24,  3.79it/s, loss=0.827, v_num=0]#015Epoch 1:  78%|███████▊  | 329/420 [01:26<00:24,  3.79it/s, loss=0.835, v_num=0]#015Epoch 1:  79%|███████▊  | 330/420 [01:27<00:23,  3.79it/s, loss=0.835, v_num=0]#015Epoch 1:  79%|███████▊  | 330/420 [01:27<00:23,  3.79it/s, loss=0.837, v_num=0]#015Epoch 1:  79%|███████▉  | 331/420 [01:27<00:23,  3.79it/s, loss=0.837, v_num=0]#015Epoch 1:  79%|███████▉  | 331/420 [01:27<00:23,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  79%|███████▉  | 332/420 [01:27<00:23,  3.79it/s, loss=0.840, v_num=0]#015Epoch 1:  79%|███████▉  | 332/420 [01:27<00:23,  3.79it/s, loss=0.831, v_num=0]#015Epoch 1:  79%|███████▉  | 333/420 [01:27<00:22,  3.79it/s, loss=0.831, v_num=0]#015Epoch 1:  79%|███████▉  | 333/420 [01:27<00:22,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  80%|███████▉  | 334/420 [01:28<00:22,  3.79it/s, loss=0.819, v_num=0]#015Epoch 1:  80%|███████▉  | 334/420 [01:28<00:22,  3.79it/s, loss=0.839, v_num=0]#015Epoch 1:  80%|███████▉  | 335/420 [01:28<00:22,  3.79it/s, loss=0.839, v_num=0]#015Epoch 1:  80%|███████▉  | 335/420 [01:28<00:22,  3.79it/s, loss=0.824, v_num=0]#015Epoch 1:  80%|████████  | 336/420 [01:28<00:22,  3.79it/s, loss=0.824, v_num=0]#015Epoch 1:  80%|████████  | 336/420 [01:28<00:22,  3.79it/s, loss=0.787, v_num=0]#015Epoch 1:  80%|████████  | 337/420 [01:28<00:21,  3.79it/s, loss=0.787, v_num=0]#015Epoch 1:  80%|████████  | 337/420 [01:28<00:21,  3.79it/s, loss=0.781, v_num=0]#015Epoch 1:  80%|████████  | 338/420 [01:29<00:21,  3.79it/s, loss=0.781, v_num=0]#015Epoch 1:  80%|████████  | 338/420 [01:29<00:21,  3.79it/s, loss=0.776, v_num=0]#015Epoch 1:  81%|████████  | 339/420 [01:29<00:21,  3.79it/s, loss=0.776, v_num=0]#015Epoch 1:  81%|████████  | 339/420 [01:29<00:21,  3.79it/s, loss=0.786, v_num=0]#015Epoch 1:  81%|████████  | 340/420 [01:29<00:21,  3.79it/s, loss=0.786, v_num=0]#015Epoch 1:  81%|████████  | 340/420 [01:29<00:21,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  81%|████████  | 341/420 [01:30<00:20,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  81%|████████  | 341/420 [01:30<00:20,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  81%|████████▏ | 342/420 [01:30<00:20,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  81%|████████▏ | 342/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|████████▏ | 343/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|████████▏ | 343/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|████████▏ | 344/420 [01:30<00:20,  3.79it/s, loss=0.751, v_num=0]#015Epoch 1:  82%|████████▏ | 344/420 [01:30<00:20,  3.79it/s, loss=0.744, v_num=0]#015Epoch 1:  82%|████████▏ | 345/420 [01:31<00:19,  3.79it/s, loss=0.744, v_num=0]#015Epoch 1:  82%|████████▏ | 345/420 [01:31<00:19,  3.79it/s, loss=0.743, v_num=0]#015Epoch 1:  82%|████████▏ | 346/420 [01:31<00:19,  3.79it/s, loss=0.743, v_num=0]#015Epoch 1:  82%|████████▏ | 346/420 [01:31<00:19,  3.79it/s, loss=0.748, v_num=0]#015Epoch 1:  83%|████████▎ | 347/420 [01:31<00:19,  3.79it/s, loss=0.748, v_num=0]#015Epoch 1:  83%|████████▎ | 347/420 [01:31<00:19,  3.79it/s, loss=0.741, v_num=0]#015Epoch 1:  83%|████████▎ | 348/420 [01:31<00:19,  3.79it/s, loss=0.741, v_num=0]#015Epoch 1:  83%|████████▎ | 348/420 [01:31<00:19,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  83%|████████▎ | 349/420 [01:32<00:18,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  83%|████████▎ | 349/420 [01:32<00:18,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  83%|████████▎ | 350/420 [01:32<00:18,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  83%|████████▎ | 350/420 [01:32<00:18,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|████████▎ | 351/420 [01:32<00:18,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|████████▎ | 351/420 [01:32<00:18,  3.79it/s, loss=0.700, v_num=0]#015Epoch 1:  84%|████████▍ | 352/420 [01:32<00:17,  3.79it/s, loss=0.700, v_num=0]#015Epoch 1:  84%|████████▍ | 352/420 [01:32<00:17,  3.79it/s, loss=0.702, v_num=0]#015Epoch 1:  84%|████████▍ | 353/420 [01:33<00:17,  3.79it/s, loss=0.702, v_num=0]#015Epoch 1:  84%|████████▍ | 353/420 [01:33<00:17,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|████████▍ | 354/420 [01:33<00:17,  3.79it/s, loss=0.707, v_num=0]#015Epoch 1:  84%|████████▍ | 354/420 [01:33<00:17,  3.79it/s, loss=0.699, v_num=0]#015Epoch 1:  85%|████████▍ | 355/420 [01:33<00:17,  3.79it/s, loss=0.699, v_num=0]#015Epoch 1:  85%|████████▍ | 355/420 [01:33<00:17,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  85%|████████▍ | 356/420 [01:34<00:16,  3.79it/s, loss=0.727, v_num=0]#015Epoch 1:  85%|████████▍ | 356/420 [01:34<00:16,  3.79it/s, loss=0.739, v_num=0]#015Epoch 1:  85%|████████▌ | 357/420 [01:34<00:16,  3.79it/s, loss=0.739, v_num=0]#015Epoch 1:  85%|████████▌ | 357/420 [01:34<00:16,  3.79it/s, loss=0.733, v_num=0]#015Epoch 1:  85%|████████▌ | 358/420 [01:34<00:16,  3.79it/s, loss=0.733, v_num=0]#015Epoch 1:  85%|████████▌ | 358/420 [01:34<00:16,  3.79it/s, loss=0.754, v_num=0]#015Epoch 1:  85%|████████▌ | 359/420 [01:34<00:16,  3.79it/s, loss=0.754, v_num=0]#015Epoch 1:  85%|████████▌ | 359/420 [01:34<00:16,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  86%|████████▌ | 360/420 [01:35<00:15,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  86%|████████▌ | 360/420 [01:35<00:15,  3.79it/s, loss=0.755, v_num=0]#015Epoch 1:  86%|████████▌ | 361/420 [01:35<00:15,  3.79it/s, loss=0.755, v_num=0]#015Epoch 1:  86%|████████▌ | 361/420 [01:35<00:15,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  86%|████████▌ | 362/420 [01:35<00:15,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  86%|████████▌ | 362/420 [01:35<00:15,  3.79it/s, loss=0.723, v_num=0]#015Epoch 1:  86%|████████▋ | 363/420 [01:35<00:15,  3.79it/s, loss=0.723, v_num=0]#015Epoch 1:  86%|████████▋ | 363/420 [01:35<00:15,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  87%|████████▋ | 364/420 [01:36<00:14,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  87%|████████▋ | 364/420 [01:36<00:14,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  87%|████████▋ | 365/420 [01:36<00:14,  3.79it/s, loss=0.746, v_num=0]#015Epoch 1:  87%|████████▋ | 365/420 [01:36<00:14,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  87%|████████▋ | 366/420 [01:36<00:14,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  87%|████████▋ | 366/420 [01:36<00:14,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  87%|████████▋ | 367/420 [01:36<00:13,  3.79it/s, loss=0.728, v_num=0]#015Epoch 1:  87%|███████�\u001B[0m\n",
      "\u001B[34m�▋ | 367/420 [01:36<00:13,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  88%|████████▊ | 368/420 [01:37<00:13,  3.79it/s, loss=0.734, v_num=0]#015Epoch 1:  88%|████████▊ | 368/420 [01:37<00:13,  3.79it/s, loss=0.740, v_num=0]#015Epoch 1:  88%|████████▊ | 369/420 [01:37<00:13,  3.79it/s, loss=0.740, v_num=0]#015Epoch 1:  88%|████████▊ | 369/420 [01:37<00:13,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|████████▊ | 370/420 [01:37<00:13,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|████████▊ | 370/420 [01:37<00:13,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|████████▊ | 371/420 [01:37<00:12,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  88%|████████▊ | 371/420 [01:37<00:12,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  89%|████████▊ | 372/420 [01:38<00:12,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  89%|████████▊ | 372/420 [01:38<00:12,  3.79it/s, loss=0.766, v_num=0]#015Epoch 1:  89%|████████▉ | 373/420 [01:38<00:12,  3.79it/s, loss=0.766, v_num=0]#015Epoch 1:  89%|████████▉ | 373/420 [01:38<00:12,  3.79it/s, loss=0.772, v_num=0]#015Epoch 1:  89%|████████▉ | 374/420 [01:38<00:12,  3.79it/s, loss=0.772, v_num=0]#015Epoch 1:  89%|████████▉ | 374/420 [01:38<00:12,  3.79it/s, loss=0.762, v_num=0]#015Epoch 1:  89%|████████▉ | 375/420 [01:38<00:11,  3.79it/s, loss=0.762, v_num=0]#015Epoch 1:  89%|████████▉ | 375/420 [01:38<00:11,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  90%|████████▉ | 376/420 [01:39<00:11,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  90%|████████▉ | 376/420 [01:39<00:11,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  90%|████████▉ | 377/420 [01:39<00:11,  3.79it/s, loss=0.716, v_num=0]#015Epoch 1:  90%|████████▉ | 377/420 [01:39<00:11,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  90%|█████████ | 378/420 [01:39<00:11,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  90%|█████████ | 378/420 [01:39<00:11,  3.79it/s, loss=0.720, v_num=0]#015Epoch 1:  90%|█████████ | 379/420 [01:39<00:10,  3.79it/s, loss=0.720, v_num=0]#015Epoch 1:  90%|█████████ | 379/420 [01:39<00:10,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  90%|█████████ | 380/420 [01:40<00:10,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  90%|█████████ | 380/420 [01:40<00:10,  3.79it/s, loss=0.698, v_num=0]#015Epoch 1:  91%|█████████ | 381/420 [01:40<00:10,  3.79it/s, loss=0.698, v_num=0]#015Epoch 1:  91%|█████████ | 381/420 [01:40<00:10,  3.79it/s, loss=0.719, v_num=0]#015Epoch 1:  91%|█████████ | 382/420 [01:40<00:10,  3.79it/s, loss=0.719, v_num=0]#015Epoch 1:  91%|█████████ | 382/420 [01:40<00:10,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  91%|█████████ | 383/420 [01:40<00:09,  3.79it/s, loss=0.730, v_num=0]#015Epoch 1:  91%|█████████ | 383/420 [01:40<00:09,  3.79it/s, loss=0.745, v_num=0]#015Epoch 1:  91%|█████████▏| 384/420 [01:41<00:09,  3.79it/s, loss=0.745, v_num=0]#015Epoch 1:  91%|█████████▏| 384/420 [01:41<00:09,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  92%|█████████▏| 385/420 [01:41<00:09,  3.79it/s, loss=0.726, v_num=0]#015Epoch 1:  92%|█████████▏| 385/420 [01:41<00:09,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|█████████▏| 386/420 [01:41<00:08,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|█████████▏| 386/420 [01:41<00:08,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  92%|█████████▏| 387/420 [01:42<00:08,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  92%|█████████▏| 387/420 [01:42<00:08,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|█████████▏| 388/420 [01:42<00:08,  3.79it/s, loss=0.736, v_num=0]#015Epoch 1:  92%|█████████▏| 388/420 [01:42<00:08,  3.79it/s, loss=0.769, v_num=0]#015Epoch 1:  93%|█████████▎| 389/420 [01:42<00:08,  3.79it/s, loss=0.769, v_num=0]#015Epoch 1:  93%|█████████▎| 389/420 [01:42<00:08,  3.79it/s, loss=0.756, v_num=0]#015Epoch 1:  93%|█████████▎| 390/420 [01:42<00:07,  3.79it/s, loss=0.756, v_num=0]#015Epoch 1:  93%|█████████▎| 390/420 [01:42<00:07,  3.79it/s, loss=0.758, v_num=0]#015Epoch 1:  93%|█████████▎| 391/420 [01:43<00:07,  3.79it/s, loss=0.758, v_num=0]#015Epoch 1:  93%|█████████▎| 391/420 [01:43<00:07,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  93%|█████████▎| 392/420 [01:43<00:07,  3.79it/s, loss=0.778, v_num=0]#015Epoch 1:  93%|█████████▎| 392/420 [01:43<00:07,  3.79it/s, loss=0.775, v_num=0]#015Epoch 1:  94%|█████████▎| 393/420 [01:43<00:07,  3.79it/s, loss=0.775, v_num=0]#015Epoch 1:  94%|█████████▎| 393/420 [01:43<00:07,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  94%|█████████▍| 394/420 [01:43<00:06,  3.79it/s, loss=0.760, v_num=0]#015Epoch 1:  94%|█████████▍| 394/420 [01:43<00:06,  3.79it/s, loss=0.764, v_num=0]#015Epoch 1:  94%|█████████▍| 395/420 [01:44<00:06,  3.79it/s, loss=0.764, v_num=0]#015Epoch 1:  94%|█████████▍| 395/420 [01:44<00:06,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  94%|█████████▍| 396/420 [01:44<00:06,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  94%|█████████▍| 396/420 [01:44<00:06,  3.79it/s, loss=0.773, v_num=0]#015Epoch 1:  95%|█████████▍| 397/420 [01:44<00:06,  3.79it/s, loss=0.773, v_num=0]#015Epoch 1:  95%|█████████▍| 397/420 [01:44<00:06,  3.79it/s, loss=0.761, v_num=0]#015Epoch 1:  95%|█████████▍| 398/420 [01:44<00:05,  3.79it/s, loss=0.761, v_num=0]#015Epoch 1:  95%|█████████▍| 398/420 [01:44<00:05,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  95%|█████████▌| 399/420 [01:45<00:05,  3.79it/s, loss=0.765, v_num=0]#015Epoch 1:  95%|█████████▌| 399/420 [01:45<00:05,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  95%|█████████▌| 400/420 [01:45<00:05,  3.79it/s, loss=0.763, v_num=0]#015Epoch 1:  95%|█████████▌| 400/420 [01:45<00:05,  3.79it/s, loss=0.770, v_num=0]#015Epoch 1:  95%|█████████▌| 401/420 [01:45<00:05,  3.79it/s, loss=0.770, v_num=0]#015Epoch 1:  95%|█████████▌| 401/420 [01:45<00:05,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  96%|█████████▌| 402/420 [01:46<00:04,  3.79it/s, loss=0.752, v_num=0]#015Epoch 1:  96%|█████████▌| 402/420 [01:46<00:04,  3.79it/s, loss=0.738, v_num=0]#015Epoch 1:  96%|█████████▌| 403/420 [01:46<00:04,  3.79it/s, loss=0.738, v_num=0]#015Epoch 1:  96%|█████████▌| 403/420 [01:46<00:04,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  96%|█████████▌| 404/420 [01:46<00:04,  3.79it/s, loss=0.724, v_num=0]#015Epoch 1:  96%|█████████▌| 404/420 [01:46<00:04,  3.79it/s, loss=0.710, v_num=0]#015Epoch 1:  96%|█████████▋| 405/420 [01:46<00:03,  3.79it/s, loss=0.710, v_num=0]#015Epoch 1:  96%|█████████▋| 405/420 [01:46<00:03,  3.79it/s, loss=0.729, v_num=0]#015Epoch 1:  97%|█████████▋| 406/420 [01:47<00:03,  3.79it/s, loss=0.729, v_num=0]#015Epoch 1:  97%|█████████▋| 406/420 [01:47<00:03,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  97%|█████████▋| 407/420 [01:47<00:03,  3.79it/s, loss=0.725, v_num=0]#015Epoch 1:  97%|█████████▋| 407/420 [01:47<00:03,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  97%|█████████▋| 408/420 [01:47<00:03,  3.79it/s, loss=0.722, v_num=0]#015Epoch 1:  97%|█████████▋| 408/420 [01:47<00:03,  3.79it/s, loss=0.685, v_num=0]#015Epoch 1:  97%|█████████▋| 409/420 [01:47<00:02,  3.79it/s, loss=0.685, v_num=0]#015Epoch 1:  97%|█████████▋| 409/420 [01:47<00:02,  3.79it/s, loss=0.682, v_num=0]#015Epoch 1:  98%|█████████▊| 410/420 [01:48<00:02,  3.79it/s, loss=0.682, v_num=0]#015Epoch 1:  98%|█████████▊| 410/420 [01:48<00:02,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  98%|█████████▊| 411/420 [01:48<00:02,  3.79it/s, loss=0.678, v_num=0]#015Epoch 1:  98%|█████████▊| 411/420 [01:48<00:02,  3.79it/s, loss=0.662, v_num=0]#015Epoch 1:  98%|█████████▊| 412/420 [01:48<00:02,  3.79it/s, loss=0.662, v_num=0]#015Epoch 1:  98%|█████████▊| 412/420 [01:48<00:02,  3.79it/s, loss=0.697, v_num=0]#015Epoch 1:  98%|█████████▊| 413/420 [01:48<00:01,  3.79it/s, loss=0.697, v_num=0]#015Epoch 1:  98%|█████████▊| 413/420 [01:48<00:01,  3.79it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating: 0it [00:00, ?it/s]#033[A\u001B[0m\n",
      "\u001B[34m#015Validating:  14%|█▍        | 1/7 [00:00<00:01,  5.44it/s]#033[A#015Epoch 1:  99%|█████████▊| 414/420 [01:49<00:01,  3.80it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating:  43%|████▎     | 3/7 [00:00<00:00,  6.43it/s]#033[A#015Epoch 1:  99%|█████████▉| 416/420 [01:49<00:01,  3.81it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating:  71%|███████▏  | 5/7 [00:00<00:00,  7.33it/s]#033[A#015Epoch 1: 100%|█████████▉| 418/420 [01:49<00:00,  3.82it/s, loss=0.713, v_num=0]\u001B[0m\n",
      "\u001B[34m#015Validating: 100%|██████████| 7/7 [00:00<00:00,  8.26it/s]#033[A#015Epoch 1: 100%|██████████| 420/420 [01:49<00:00,  3.83it/s, loss=0.713, v_num=0]#015Epoch 1: 100%|██████████| 420/420 [01:49<00:00,  3.83it/s, loss=0.713, v_num=0, val_loss=0.702]\u001B[0m\n",
      "\u001B[34m#015                                                         #033[A#015Epoch 1: 100%|██████████| 420/420 [01:54<00:00,  3.66it/s, loss=0.713, v_num=0, val_loss=0.702]\u001B[0m\n",
      "\u001B[34msave output model path:  /opt/ml/model\u001B[0m\n",
      "\u001B[34m/opt/ml/model/cktepoch=1.ckpt\u001B[0m\n",
      "\u001B[34m/opt/ml/model/lightning_logs\u001B[0m\n",
      "\u001B[34mall checkpoints:  ['/opt/ml/model/cktepoch=1.ckpt']\u001B[0m\n",
      "\u001B[34mFinish training and saving the model!\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 792k/792k [00:00<00:00, 36.1MB/s]\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]#015Downloading: 100%|██████████| 1.39M/1.39M [00:00<00:00, 39.3MB/s]\u001B[0m\n",
      "\u001B[34m/opt/conda/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 1.20k/1.20k [00:00<00:00, 1.65MB/s]\u001B[0m\n",
      "\u001B[34m#015Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]#015Downloading:   0%|          | 3.49M/892M [00:00<00:25, 34.9MB/s]#015Downloading:   1%|          | 8.11M/892M [00:00<00:23, 37.7MB/s]#015Downloading:   1%|▏         | 12.6M/892M [00:00<00:22, 39.5MB/s]#015Downloading:   2%|▏         | 17.3M/892M [00:00<00:20, 41.7MB/s]#015Downloading:   2%|▏         | 22.1M/892M [00:00<00:20, 43.2MB/s]#015Downloading:   3%|▎         | 26.8M/892M [00:00<00:19, 44.4MB/s]#015Downloading:   4%|▎         | 31.6M/892M [00:00<00:18, 45.5MB/s]#015Downloading:   4%|▍         | 36.6M/892M [00:00<00:18, 46.5MB/s]#015Downloading:   5%|▍         | 41.5M/892M [00:00<00:17, 47.3MB/s]#015Downloading:   5%|▌         | 46.4M/892M [00:01<00:17, 47.8MB/s]#015Downloading:   6%|▌         | 51.1M/892M [00:01<00:17, 47.3MB/s]#015Downloading:   6%|▋         | 55.8M/892M [00:01<00:18, 44.5MB/s]#015Downloading:   7%|▋         | 60.2M/892M [00:01<00:19, 42.7MB/s]#015Downloading:   7%|▋         | 64.9M/892M [00:01<00:18, 43.9MB/s]#015Downloading:   8%|▊         | 69.8M/892M [00:01<00:18, 45.4MB/s]#015Downloading:   8%|▊         | 74.8M/892M [00:01<00:17, 46.6MB/s]#015Downloading:   9%|▉         | 79.8M/892M [00:01<00:17, 47.4MB/s]#015Downloading:  10%|▉         | 84.7M/892M [00:01<00:16, 48.1MB/s]#015Downloading:  10%|█         | 89.7M/892M [00:01<00:16, 48.6MB/s]#015Downloading:  11%|█         | 94.6M/892M [00:02<00:16, 47.8MB/s]#015Downloading:  11%|█         | 99.4M/892M [00:02<00:16, 48.0MB/s]#015Downloading:  12%|█▏        | 104M/892M [00:02<00:16, 48.1MB/s] #015Downloading:  12%|█▏        | 109M/892M [00:02<00:16, 48.1MB/s]#015Downloading:  13%|█▎        | 114M/892M [00:02<00:16, 48.4MB/s]#015Downloading:  13%|█▎        | 119M/892M [00:02<00:15, 48.6MB/s]#015Downloading:  14%|█▍        | 124M/892M [00:02<00:16, 47.8MB/s]#015Downloading:  14%|█▍        | 129M/892M [00:02<00:15, 47.9MB/s]#015Downloading:  15%|█▍        | 133M/892M [00:02<00:15, 47.9MB/s]#015Downloading:  16%|█▌        | 138M/892M [00:02<00:15, 48.3MB/s]#015Downloading:  16%|█▌        | 143M/892M [00:03<00:16, 45.9MB/s]#015Downloading:  17%|█▋        | 148M/892M [00:03<00:16, 46.1MB/s]#015Downloading:  17%|█▋        | 153M/892M [00:03<00:15, 47.0MB/s]#015Downloading:  18%|█▊        | 158M/892M [00:03<00:15, 47.7MB/s]#015Downloading:  18%|█▊        | 163M/892M [00:03<00:15, 48.2MB/s]#015Downloading:  19%|█▉        | 168M/892M [00:03<00:14, 48.5MB/s]#015Downloading:  19%|█▉        | 172M/892M [00:03<00:14, 48.8MB/s]#015Downloading:  20%|█▉        | 177M/892M [00:03<00:14, 49.0MB/s]#015Downloading:  20%|██        | 182M/892M [00:03<00:14, 49.2MB/s]#015Downloading:  21%|██        | 187M/892M [00:03<00:14, 49.2MB/s]#015Downloading:  22%|██▏       | 192M/892M [00:04<00:15, 45.2MB/s]#015Downloading:  22%|██▏       | 197M/892M [00:04<00:16, 43.1MB/s]#015Downloading:  23%|██▎       | 201M/892M [00:04<00:16, 41.7MB/s]#015Downloading:  23%|██▎       | 205M/892M [00:04<00:16, 40.8MB/s]#015Downloading:  24%|██▎       | 210M/892M [00:04<00:16, 42.2MB/s]#015Downloading:  24%|██▍       | 215M/892M [00:04<00:15, 44.0MB/s]#015Downloading:  25%|██▍       | 220M/892M [00:04<00:14, 45.5MB/s]#015Downloading:  25%|██▌       | 225M/892M [00:04<00:14, 47.0MB/s]#015Downloading:  26%|██▌       | 231M/892M [00:04<00:13, 49.9MB/s]#015Downloading:  26%|██▋       | 236M/892M [00:05<00:13, 49.1MB/s]#015Downloading:  27%|██▋       | 241M/892M [00:05<00:13, 49.3MB/s]#015Downloading:  28%|██▊       | 246M/892M [00:05<00:13, 49.4MB/s]#015Downloading:  28%|██▊       | 251M/892M [00:05<00:12, 49.5MB/s]#015Downloading:  29%|██▊       | 256M/892M [00:05<00:12, 49.4MB/s]#015Downloading:  29%|██▉       | 261M/892M [00:05<00:13, 48.2MB/s]#015Downloading:  30%|██▉       | 266M/892M [00:05<00:12, 48.7MB/s]#015Downloading:  30%|███       | 271M/892M [00:05<00:12, 48.1MB/s]#015Downloading:  31%|███       | 276M/892M [00:05<00:12, 48.6MB/s]#015Downloading:  31%|███▏      | 280M/892M [00:05<00:12, 48.9MB/s]#015Downloading:  32%|███▏      | 285M/892M [00:06<00:12, 48.9MB/s]#015Downloading:  33%|███▎      | 290M/892M [00:06<00:12, 48.8MB/s]#015Downloading:  33%|███▎      | 295M/892M [00:06<00:12, 49.0MB/s]#015Downloading:  34%|███▎      | 300M/892M [00:06<00:12, 49.1MB/s]#015Downloading:  34%|███▍      | 305M/892M [00:06<00:11, 49.4MB/s]#015Downloading:  35%|███▍      | 310M/892M [00:06<00:12, 47.2MB/s]#015Downloading:  35%|███▌      | 315M/892M [00:06<00:12, 47.5MB/s]#015Downloading:  36%|███▌      | 320M/892M [00:06<00:11, 48.2MB/s]#015Downloading:  36%|███▋      | 325M/892M [00:06<00:12, 46.2MB/s]#015Downloading:  37%|███▋      | 330M/892M [00:06<00:12, 46.7MB/s]#015Downloading:  38%|███▊      | 334M/892M [00:07<00:11, 47.5MB/s]#015Downloading:  38%|███▊      | 339M/892M [00:07<00:11, 48.2MB/s]#015Downloading:  39%|███▊      | 345M/892M [00:07<00:11, 48.8MB/s]#015Downloading:  39%|███▉      | 350M/892M [00:07<00:10, 49.3MB/s]#015Downloading:  40%|███▉      | 355M/892M [00:07<00:10, 49.8MB/s]#015Downloading:  40%|████      | 360M/892M [00:07<00:10, 49.9MB/s]#015Downloading:  41%|████      | 365M/892M [00:07<00:10, 49.0MB/s]#015Downloading:  41%|████▏     | 370M/892M [00:07<00:10, 49.4MB/s]#015Downloading:  42%|████▏     | 375M/892M [00:07<00:10, 49.6MB/s]#015Downloading:  43%|████▎     | 380M/892M [00:07<00:10, 49.6MB/s]#015Downloading:  43%|████▎     | 385M/892M [00:08<00:10, 49.7MB/s]#015Downloading:  44%|████▎     | 390M/892M [00:08<00:10, 50.0MB/s]#015Downloading:  44%|████▍     | 395M/892M [00:08<00:09, 50.2MB/s]#015Downloading:  45%|████▍     | 400M/892M [00:08<00:09, 50.7MB/s]#015Downloading:  45%|████▌     | 405M/892M [00:08<00:09, 50.8MB/s]#015Downloading:  46%|████▌     | 410M/892M [00:08<00:09, 51.0MB/s]#015Downloading:  47%|████▋     | 415M/892M [00:08<00:09, 51.3MB/s]#015Downloading:  47%|████▋     | 421M/892M [00:08<00:09, 51.3MB/s]#015Downloading:  48%|████▊     | 426M/892M [00:08<00:09, 51.3MB/s]#015Downloading:  48%|████▊     | 431M/892M [00:08<00:08, 51.3MB/s]#015Downloading:  49%|████▉     | 436M/892M [00:09<00:09, 49.9MB/s]#015Downloading:  49%|████▉     | 441M/892M [00:09<00:08, 50.4MB/s]#015Downloading:  50%|█████     | 446M/892M [00:09<00:08, 50.7MB/s]#015Downloading:  51%|█████     | 451M/892M [00:09<00:08, 51.0MB/s]#015Downloading:  51%|█████     | 457M/892M [00:09<00:08, 51.0MB/s]#015Downloading:  52%|█████▏    | 462M/892M [00:09<00:08, 51.3MB/s]#015Downloading:  52%|█████▏    | 467M/892M [00:09<00:08, 51.4MB/s]#015Downloading:  53%|█████▎    | 472M/892M [00:09<00:08, 51.6MB/s]#015Downloading:  54%|█████▎    | 477M/892M [00:09<00:08, 51.7MB/s]#015Downloading:  54%|█████▍    | 483M/892M [00:10<00:07, 51.8MB/s]#015Downloading:  55%|█████▍    | 488M/892M [00:10<00:07, 51.7MB/s]#015Downloading:  55%|█████▌    | 493M/892M [00:10<00:07, 51.8MB/s]#015Downloading:  56%|█████▌    | 498M/892M [00:10<00:07, 52.0MB/s]#015Downloading:  56%|█████▋    | 503M/892M [00:10<00:07, 52.0MB/s]#015Downloading:  57%|█████▋    | 509M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  58%|█████▊    | 514M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  58%|█████▊    | 519M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  59%|█████▉    | 524M/892M [00:10<00:07, 51.9MB/s]#015Downloading:  59%|█████▉    | 529M/892M [00:10<00:07, 51.8MB/s]#015Downloading:  60%|█████▉    | 535M/892M [00:11<00:06, 51.6MB/s]#015Downloading:  61%|██████    | 540M/892M [00:11<00:06, 50.4MB/s]#015Downloading:  61%|██████    | 545M/892M [00:11<00:07, 49.1MB/s]#015Downloading:  62%|██████▏   | 550M/892M [00:11<00:06, 49.9MB/s]#015Downloading:  62%|██████▏   | 555M/892M [00:11<00:06, 50.4MB/s]#015Downloading:  63%|██████▎   | 560M/892M [00:11<00:06, 50.7MB/s]#015Downloading:  63%|██████▎   | 565M/892M [00:11<00:06, 51.0MB/s]#015Downloading:  64%|██████▍   | 571M/892M [00:11<00:06, 51.1MB/s]#015Downloading:  65%|██████▍   | 576M/892M [00:11<00:06, 51.3MB/s]#015Downloading:  65%|██████▌   | 581M/892M [00:11<00:06, 51.4MB/s]#015Downloading:  66%|██████▌   | 586M/892M [00:12<00:05, 51.5MB/s]#015Downloading:  66%|██████▋   | 591M/892M [00:12<00:05, 51.6MB/s]#015Downloading:  67%|██████▋   | 596M/892M [00:12<00:05, 51.3MB/s]#015Downloading:  67%|██████▋   | 602M/892M [00:12<00:05, 51.2MB/s]#015Downloading:  68%|██████▊   | 607M/892M [00:12<00:05, 51.2MB/s]#015Downloading:  69%|██████▊   | 612M/892M [00:12<00:05, 51.2MB/s]#015Downloading:  69%|██████▉   | 617M/892M [00:12<00:05, 51.5MB/s]#015Downloading:  70%|██████▉   | 622M/892M [00:12<00:05, 50.1MB/s]#015Downloading:  70%|███████   | 627M/892M [00:12<00:05, 50.3MB/s]#015Downloading:  71%|███████   | 632M/892M [00:12<00:05, 50.8MB/s]#015Downloading:  72%|███████▏  | 638M/892M [00:13<00:04, 51.0MB/s]#015Downloading:  72%|███████▏  | 643M/892M [00:13<00:04, 50.8MB/s]#015Downloading:  73%|███████▎  | 648M/892M [00:13<00:04, 51.1MB/s]#015Downloading:  73%|███████▎  | 653M/892M [00:13<00:04, 51.2MB/s]#015Downloading:  74%|███████▍  | 658M/892M [00:13<00:04, 51.4MB/s]#015Downloading:  74%|███████▍  | 663M/892M [00:13<00:04, 51.4MB/s]#015Downloading:  75%|███████▍  | 669M/892M [00:13<00:04, 51.5MB/s]#015Downloading:  76%|███████▌  | 674M/892M [00:13<00:04, 51.4MB/s]#015Downloading:  76%|███████▌  | 679M/892M [00:13<00:04, 51.2MB/s]#015Downloading:  77%|███████▋  | 684M/892M [00:13<00:04, 51.2MB/s]#015Downloading:  77%|███████▋  | 689M/892M [00:14<00:03, 51.3MB/s]#015Downloading:  78%|███████▊  | 694M/892M [00:14<00:03, 51.2MB/s]#015Downloading:  78%|███████▊  | 699M/892M [00:14<00:03, 51.3MB/s]#015Downloading:  79%|███████▉  | 705M/892M [00:14<00:03, 51.3MB/s]#015Downloading:  80%|███████▉  | 710M/892M [00:14<00:03, 51.5MB/s]#015Downloading:  80%|████████  | 715M/892M [00:14<00:03, 51.6MB/s]#015Downloading:  81%|████████  | 720M/892M [00:14<00:03, 51.7MB/s]#015Downloading:  81%|████████▏ | 725M/892M [00:14<00:03, 51.8MB/s]#015Downloading:  82%|████████▏ | 730M/892M [00:14<00:03, 51.8MB/s]#015Downloading:  83%|████████▎ | 736M/892M [00:14<00:03, 51.8MB/s]#015Downloading:  83%|████████▎ | 741M/892M [00:15<00:02, 51.8MB/s]#015Downloading:  84%|████████▎ | 746M/892M [00:15<00:02, 51.7MB/s]#015Downloading:  84%|████████▍ | 751M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  85%|████████▍ | 756M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  85%|████████▌ | 762M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  86%|████████▌ | 767M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  87%|████████▋ | 772M/892M [00:15<00:02, 51.5MB/s]#015Downloading:  87%|████████▋ | 777M/892M [00:15<00:02, 51.5MB/s]#015Downloading:  88%|████████▊ | 782M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  88%|████████▊ | 787M/892M [00:15<00:02, 51.6MB/s]#015Downloading:  89%|████████▉ | 793M/892M [00:16<00:01, 51.6MB/s]#015Downloading:  89%|████████▉ | 798M/892M [00:16<00:01, 51.5MB/s]#015Downloading:  90%|█████████ | 803M/892M [00:16<00:01, 51.4MB/s]#015Downloading:  91%|█████████ | 808M/892M [00:16<00:01, 51.3MB/s]#015Downloading:  91%|█████████ | 813M/892M [00:16<00:01, 50.8MB/s]#015Downloading:  92%|█████████▏| 818M/892M [00:16<00:01, 50.9MB/s]#015Downloading:  92%|█████████▏| 823M/892M [00:16<00:01, 51.1MB/s]#015Downloading:  93%|█████████▎| 829M/892M [00:16<00:01, 51.1MB/s]#015Downloading:  93%|█████████▎| 834M/892M [00:16<00:01, 51.3MB/s]#015Downloading:  94%|█████████▍| 839M/892M [00:16<00:01, 51.4MB/s]#015Downloading:  95%|█████████▍| 844M/892M [00:17<00:00, 50.9MB/s]#015Downloading:  95%|█████████▌| 849M/892M [00:17<00:00, 50.9MB/s]#015Downloading:  96%|█████████▌| 854M/892M [00:17<00:00, 51.0MB/s]#015Downloading:  96%|█████████▋| 859M/892M [00:17<00:00, 51.1MB/s]#015Downloading:  97%|█████████▋| 865M/892M [00:17<00:00, 51.2MB/s]#015Downloading:  98%|█████████▊| 870M/892M [00:17<00:00, 51.3MB/s]#015Downloading:  98%|█████████▊| 875M/892M [00:17<00:00, 51.3MB/s]#015Downloading:  99%|█████████▊| 880M/892M [00:17<00:00, 51.3MB/s]#015Downloading:  99%|█████████▉| 885M/892M [00:17<00:00, 51.3MB/s]#015Downloading: 100%|█████████▉| 890M/892M [00:17<00:00, 51.4MB/s]#015Downloading: 100%|██████████| 892M/892M [00:17<00:00, 49.6MB/s]\u001B[0m\n",
      "\u001B[34mGPU available: True, used: True\u001B[0m\n",
      "\u001B[34mTPU available: False, using: 0 TPU cores\u001B[0m\n",
      "\u001B[34mCUDA_VISIBLE_DEVICES: [0]\n",
      "  | Name  | Type                       | Params\u001B[0m\n",
      "\u001B[34m-----------------------------------------------------\u001B[0m\n",
      "\u001B[34m0 | model | T5ForConditionalGeneration | 222 M \u001B[0m\n",
      "\u001B[34mINFO:__main__:***** Validation results *****\u001B[0m\n",
      "\u001B[34mINFO:__main__:avg_val_loss = tensor(0.7019, device='cuda:0')\u001B[0m\n",
      "\u001B[34mINFO:__main__:loss = tensor(0.8472, device='cuda:0')\u001B[0m\n",
      "\u001B[34mINFO:__main__:train_loss = tensor(0.8472, device='cuda:0')\u001B[0m\n",
      "\u001B[34mINFO:__main__:val_loss = tensor(0.7019, device='cuda:0')\u001B[0m\n",
      "\u001B[34m2022-08-17 03:07:45,837 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001B[0m\n",
      "\n",
      "2022-08-17 03:08:12 Uploading - Uploading generated training model\n",
      "2022-08-17 03:16:54 Completed - Training job completed\n",
      "ProfilerReport-1660705115: NoIssuesFound\n",
      "Training seconds: 974\n",
      "Billable seconds: 974\n"
     ]
    }
   ],
   "source": [
    "response = estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e951b",
   "metadata": {},
   "source": [
    "# deploy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e16f435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "instance_type = 'ml.m5.4xlarge'\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75d0fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_model = estimator.model_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f357cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "pytorch_model = PyTorchModel(model_data=s3_model, \n",
    "                             role=role,\n",
    "                             entry_point='inference.py', \n",
    "                             source_dir='./', \n",
    "                             framework_version='1.7.1', \n",
    "                             py_version='py36'\n",
    "                ) # TODO set model_server_workers=1 to avoid torchhub bug\n",
    "\n",
    "predictor = pytorch_model.deploy(instance_type=instance_type, initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da3506eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': '(pretty new to pickleball, scene); (finally decided to try out some different paddles, purchase_behavior)'}\n"
     ]
    }
   ],
   "source": [
    "from boto3.session import Session\n",
    "import json\n",
    "\n",
    "body = {\"inputs\": \"I am pretty new to pickleball and finally decided to try out some different paddles.\"}\n",
    "\n",
    "session = Session()\n",
    "runtime = session.client(\"runtime.sagemaker\")\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=json.dumps(body),\n",
    ")\n",
    "result = json.loads(response[\"Body\"].read())\n",
    "print (result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f02d1c49",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.98 ms, sys: 11.8 ms, total: 13.8 ms\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': '(pretty new to pickleball, scene); (finally decided to try out some different paddles, purchase_behavior)'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "predictor.serializer = sagemaker.serializers.JSONSerializer()\n",
    "predictor.deserializer = sagemaker.deserializers.JSONDeserializer()\n",
    "\n",
    "body = {\"inputs\": \"I am pretty new to pickleball and finally decided to try out some different paddles.\"}\n",
    "\n",
    "predictor.predict(body,initial_args={\"ContentType\":\"application/json\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b90a291",
   "metadata": {},
   "source": [
    "# batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b36dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict.jsonl uploaded to s3://sagemaker-us-east-1-726335585155/batch_transform/input/predict.jsonl\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sagemaker.s3 import S3Uploader,s3_path_join\n",
    "\n",
    "# get the s3 bucket\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "#prepare data\n",
    "dataset_csv_file = 'predict_0811.csv'\n",
    "dataset_jsonl_file = \"predict.jsonl\"\n",
    "\n",
    "\n",
    "i = 0\n",
    "with open(dataset_csv_file, \"r+\") as infile, open(dataset_jsonl_file, \"w+\") as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    for row in reader:\n",
    "        if i <5:\n",
    "            json.dump({\"inputs\":row[\"0\"]}, outfile)\n",
    "            outfile.write('\\n')\n",
    "        i = i+1\n",
    "                \n",
    "# uploads a given file to S3.\n",
    "input_s3_path = s3_path_join(\"s3://\",sagemaker_session_bucket,\"batch_transform/input\")\n",
    "output_s3_path = s3_path_join(\"s3://\",sagemaker_session_bucket,\"batch_transform/output\")\n",
    "s3_file_uri = S3Uploader.upload(dataset_jsonl_file,input_s3_path)\n",
    "\n",
    "print(f\"{dataset_jsonl_file} uploaded to {s3_file_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a4702e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create transformer to run a batch job\n",
    "batch_job = pytorch_model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    output_path=output_s3_path,\n",
    "    strategy='SingleRecord'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92580b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................\u001B[34mCollecting transformers==4.6.0\n",
      "  Downloading transformers-4.6.0-py3-none-any.whl (2.3 MB)\u001B[0m\n",
      "\u001B[34mCollecting datasets==1.11.0\n",
      "  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\u001B[0m\n",
      "\u001B[34mCollecting sentencepiece==0.1.91\n",
      "  Downloading sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\u001B[0m\n",
      "\u001B[34mCollecting pytorch_lightning==0.8.1\n",
      "  Downloading pytorch_lightning-0.8.1-py3-none-any.whl (293 kB)\u001B[0m\n",
      "\u001B[34mCollecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mCollecting editdistance\n",
      "  Downloading editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\u001B[0m\n",
      "\u001B[34mCollecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001B[0m\n",
      "\u001B[34mCollecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34mCollecting regex!=2019.12.17\n",
      "  Downloading regex-2022.7.25-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\u001B[0m\n",
      "\u001B[34mCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (20.4)\u001B[0m\n",
      "\u001B[34mCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (4.62.3)\u001B[0m\n",
      "\u001B[34mCollecting huggingface-hub==0.0.8\n",
      "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.22.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34mCollecting fsspec>=2021.05.0\n",
      "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\u001B[0m\n",
      "\u001B[34mCollecting pyarrow!=4.0.0,>=1.0.0\n",
      "  Downloading pyarrow-6.0.1-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.25.0)\u001B[0m\n",
      "\u001B[34mCollecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py36-none-any.whl (106 kB)\u001B[0m\n",
      "\u001B[34mCollecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\u001B[0m\n",
      "\u001B[34mCollecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard>=1.14\n",
      "  Downloading tensorboard-2.10.0-py3-none-any.whl (5.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2021.5.30)\u001B[0m\n",
      "\u001B[34mCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.10.0-py2.py3-none-any.whl (167 kB)\u001B[0m\n",
      "\u001B[34mCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001B[0m\n",
      "\u001B[34mCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001B[0m\n",
      "\u001B[34mCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001B[0m\n",
      "\u001B[34mCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001B[0m\n",
      "\u001B[34mCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.37.0)\u001B[0m\n",
      "\u001B[34mCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch>=1.3->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.0.0)\u001B[0m\n",
      "\u001B[34mCollecting zipp>=0.5\n",
      "  Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2.8.2)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2021.3)\u001B[0m\n",
      "\u001B[34mCollecting click\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34mCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001B[0m\n",
      "\u001B[34mCollecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001B[0m\n",
      "\u001B[34mCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001B[0m\n",
      "\u001B[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34mCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\u001B[0m\n",
      "\u001B[34mBuilding wheels for collected packages: jieba, sacremoses\n",
      "  Building wheel for jieba (setup.py): started\u001B[0m\n",
      "\u001B[34m  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314476 sha256=a3a14471b331b7be42001fa26669b175c5ec2175fd50255c09610ca8487f69a6\n",
      "  Stored in directory: /root/.cache/pip/wheels/17/a7/8b/a7e03881534e78558920ac68aaeca05180c0e2c3d11c4fce3b\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895253 sha256=608c93633d2b3489c9711e524e9e25f58444430327c6b0b301192ee989532e50\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001B[0m\n",
      "\u001B[34mSuccessfully built jieba sacremoses\u001B[0m\n",
      "\u001B[34mInstalling collected packages: zipp, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, regex, protobuf, markdown, grpcio, google-auth-oauthlib, filelock, dill, click, absl-py, xxhash, tokenizers, tensorboard, sacremoses, pyarrow, multiprocess, huggingface-hub, fsspec, transformers, sentencepiece, pytorch-lightning, jieba, editdistance, datasets\u001B[0m\n",
      "\u001B[34mSuccessfully installed absl-py-1.2.0 cachetools-4.2.4 click-8.0.4 datasets-1.11.0 dill-0.3.4 editdistance-0.6.0 filelock-3.4.1 fsspec-2022.1.0 google-auth-2.10.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 huggingface-hub-0.0.8 importlib-metadata-4.8.3 jieba-0.42.1 markdown-3.3.7 multiprocess-0.70.12.2 oauthlib-3.2.0 protobuf-3.19.4 pyarrow-6.0.1 pyasn1-modules-0.2.8 pytorch-lightning-0.8.1 regex-2022.7.25 requests-oauthlib-1.3.1 sacremoses-0.0.53 sentencepiece-0.1.91 tensorboard-2.10.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.10.3 transformers-4.6.0 werkzeug-2.0.3 xxhash-3.0.0 zipp-3.6.0\u001B[0m\n",
      "\u001B[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[34m2022-08-17 03:44:28,984 [INFO ] main org.pytorch.serve.ModelServer - \u001B[0m\n",
      "\u001B[34mTorchserve version: 0.3.1\u001B[0m\n",
      "\u001B[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001B[0m\n",
      "\u001B[34mCurrent directory: /\u001B[0m\n",
      "\u001B[34mTemp directory: /home/model-server/tmp\u001B[0m\n",
      "\u001B[34mNumber of GPUs: 1\u001B[0m\n",
      "\u001B[34mNumber of CPUs: 4\u001B[0m\n",
      "\u001B[34mMax heap size: 2996 M\u001B[0m\n",
      "\u001B[34mPython executable: /opt/conda/bin/python3.6\u001B[0m\n",
      "\u001B[34mConfig file: /etc/sagemaker-ts.properties\u001B[0m\n",
      "\u001B[34mInference address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34mManagement address: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34mMetrics address: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[34mModel Store: /.sagemaker/ts/models\u001B[0m\n",
      "\u001B[34mInitial Models: model.mar\u001B[0m\n",
      "\u001B[34mLog dir: /logs\u001B[0m\n",
      "\u001B[34mMetrics dir: /logs\u001B[0m\n",
      "\u001B[34mNetty threads: 0\u001B[0m\n",
      "\u001B[34mNetty client threads: 0\u001B[0m\n",
      "\u001B[34mDefault workers per model: 1\u001B[0m\n",
      "\u001B[34mBlacklist Regex: N/A\u001B[0m\n",
      "\u001B[34mMaximum Response Size: 6553500\u001B[0m\n",
      "\u001B[34mMaximum Request Size: 6553500\u001B[0m\n",
      "\u001B[34mPrefer direct buffer: false\u001B[0m\n",
      "\u001B[34mAllowed Urls: [file://.*|http(s)?://.*]\u001B[0m\n",
      "\u001B[34mCustom python dependency for model allowed: false\u001B[0m\n",
      "\u001B[34mMetrics report format: prometheus\u001B[0m\n",
      "\u001B[34mEnable metrics API: true\u001B[0m\n",
      "\u001B[34m2022-08-17 03:44:29,018 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,631 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag eef13c56710a4bdbb5f6f62c208f9728\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,642 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,658 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,771 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,772 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,773 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,792 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]94\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,793 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,800 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,828 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,941 [INFO ] pool-1-thread-2 ACCESS_LOG - /169.254.255.130:60784 \"GET /ping HTTP/1.1\" 200 36\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:24,967 [INFO ] pool-1-thread-2 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,006 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:60798 \"GET /execution-parameters HTTP/1.1\" 404 2\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,007 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34mModel server started.\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,282 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,282 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:79.51536178588867|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,282 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:29.051639556884766|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:26.8|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14285.8984375|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1127.70703125|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:25,283 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:9.3|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707925\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,035 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: transformers==4.6.0 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 1)) (4.6.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,035 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: datasets==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 2)) (1.11.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,036 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: sentencepiece==0.1.91 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 3)) (0.1.91)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,037 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pytorch_lightning==0.8.1 in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 4)) (0.8.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,037 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: jieba in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 5)) (0.42.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,038 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: editdistance in /opt/conda/lib/python3.6/site-packages (from -r /opt/ml/model/code/requirements.txt (line 6)) (0.6.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,199 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,200 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: huggingface-hub==0.0.8 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.0.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,200 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.0.53)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,201 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (4.8.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,202 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (0.10.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,202 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.19.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,202 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.22.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,203 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.4.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (4.62.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (20.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2022.7.25)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,311 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.25.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,311 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: xxhash in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (3.0.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,312 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dill in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.3.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,312 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: multiprocess in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (0.70.12.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,313 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2022.1.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,314 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (6.0.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,321 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: PyYAML>=5.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (5.4.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,321 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tensorboard>=1.14 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,322 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.7.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,323 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: future>=0.17.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.18.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,380 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,381 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.25.11)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,382 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,383 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (2021.5.30)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,395 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.37.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,396 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (2.10.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,397 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.2.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,398 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (3.19.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,399 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.6.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,400 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (3.3.7)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,401 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.4.6)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,401 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.8.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,402 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.47.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,403 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (49.6.0.post20210108)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,404 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (2.0.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,430 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from torch>=1.3->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.0.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,472 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.6.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,479 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (3.0.6)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,480 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.16.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,488 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2021.3)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,488 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r /opt/ml/model/code/requirements.txt (line 2)) (2.8.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,492 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (1.0.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,492 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r /opt/ml/model/code/requirements.txt (line 1)) (8.0.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,517 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.2.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,518 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.2.4)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,519 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (4.7.2)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,525 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (1.3.1)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,611 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (0.4.8)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,618 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch_lightning==0.8.1->-r /opt/ml/model/code/requirements.txt (line 4)) (3.2.0)\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:26,825 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001B[0m\n",
      "\u001B[32m2022-08-17T03:45:25.054:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /home/model-server/tmp/models/eef13c56710a4bdbb5f6f62c208f9728\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<<run train!!\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/cktepoch=1.ckpt']\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - /home/model-server/tmp/models/eef13c56710a4bdbb5f6f62c208f9728\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - <<<run train!!\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - all checkpoints:  ['/opt/ml/model/cktepoch=1.ckpt']\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,551 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,553 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|██████████| 1.20k/1.20k [00:00<00:00, 1.04MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,701 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,806 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 4.87M/892M [00:00<00:18, 48.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:34,950 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 10.3M/892M [00:00<00:17, 50.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,061 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|▏         | 15.3M/892M [00:00<00:20, 42.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,173 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|▏         | 19.7M/892M [00:00<00:21, 41.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,273 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|▎         | 23.8M/892M [00:00<00:21, 39.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,551 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,553 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|██████████| 1.20k/1.20k [00:00<00:00, 1.04MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,601 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,701 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,806 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 4.87M/892M [00:00<00:18, 48.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:34,950 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 10.3M/892M [00:00<00:17, 50.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,061 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|▏         | 15.3M/892M [00:00<00:20, 42.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,173 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|▏         | 19.7M/892M [00:00<00:21, 41.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,273 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|▎         | 23.8M/892M [00:00<00:21, 39.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,373 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|▎         | 29.0M/892M [00:00<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,485 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|▍         | 34.3M/892M [00:00<00:18, 46.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,585 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|▍         | 39.0M/892M [00:00<00:18, 44.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,713 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|▍         | 43.6M/892M [00:00<00:18, 45.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|▌         | 48.1M/892M [00:01<00:20, 41.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:35,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|▌         | 52.4M/892M [00:01<00:23, 36.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|▋         | 57.5M/892M [00:01<00:20, 40.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,168 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|▋         | 62.7M/892M [00:01<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,373 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|▎         | 29.0M/892M [00:00<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,485 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|▍         | 34.3M/892M [00:00<00:18, 46.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,585 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|▍         | 39.0M/892M [00:00<00:18, 44.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,713 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|▍         | 43.6M/892M [00:00<00:18, 45.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|▌         | 48.1M/892M [00:01<00:20, 41.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:35,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|▌         | 52.4M/892M [00:01<00:23, 36.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|▋         | 57.5M/892M [00:01<00:20, 40.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,168 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|▋         | 62.7M/892M [00:01<00:19, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,435 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|▊         | 68.3M/892M [00:01<00:17, 46.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,535 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|▊         | 73.1M/892M [00:01<00:25, 31.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,635 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|▊         | 77.2M/892M [00:01<00:24, 33.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,735 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|▉         | 82.4M/892M [00:02<00:21, 38.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,836 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|▉         | 87.4M/892M [00:02<00:19, 41.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:36,938 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|█         | 92.1M/892M [00:02<00:18, 42.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,088 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|█         | 96.7M/892M [00:02<00:18, 43.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,191 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|█▏        | 101M/892M [00:02<00:20, 38.6MB/s] \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,292 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|█▏        | 106M/892M [00:02<00:19, 39.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,435 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|▊         | 68.3M/892M [00:01<00:17, 46.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,535 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|▊         | 73.1M/892M [00:01<00:25, 31.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,635 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|▊         | 77.2M/892M [00:01<00:24, 33.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,735 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|▉         | 82.4M/892M [00:02<00:21, 38.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,836 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|▉         | 87.4M/892M [00:02<00:19, 41.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:36,938 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|█         | 92.1M/892M [00:02<00:18, 42.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,088 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|█         | 96.7M/892M [00:02<00:18, 43.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,191 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|█▏        | 101M/892M [00:02<00:20, 38.6MB/s] \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,292 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|█▏        | 106M/892M [00:02<00:19, 39.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|█▏        | 110M/892M [00:02<00:19, 39.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,502 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|█▎        | 115M/892M [00:02<00:17, 43.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,603 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|█▎        | 119M/892M [00:02<00:18, 42.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,704 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|█▍        | 124M/892M [00:03<00:17, 42.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,804 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|█▍        | 128M/892M [00:03<00:17, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:37,964 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|█▍        | 133M/892M [00:03<00:16, 45.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,085 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|█▌        | 138M/892M [00:03<00:19, 38.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,210 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|█▌        | 142M/892M [00:03<00:20, 37.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|█▏        | 110M/892M [00:02<00:19, 39.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,502 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|█▎        | 115M/892M [00:02<00:17, 43.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,603 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|█▎        | 119M/892M [00:02<00:18, 42.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,704 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|█▍        | 124M/892M [00:03<00:17, 42.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,804 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|█▍        | 128M/892M [00:03<00:17, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:37,964 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|█▍        | 133M/892M [00:03<00:16, 45.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,085 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|█▌        | 138M/892M [00:03<00:19, 38.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,210 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|█▌        | 142M/892M [00:03<00:20, 37.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,311 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|█▋        | 146M/892M [00:03<00:21, 35.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|█▋        | 150M/892M [00:03<00:19, 37.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,607 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|█▋        | 154M/892M [00:03<00:24, 30.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,707 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|█▊        | 158M/892M [00:04<00:23, 31.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,807 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|█▊        | 162M/892M [00:04<00:21, 33.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:38,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|█▊        | 166M/892M [00:04<00:20, 35.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:39,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|█▉        | 169M/892M [00:04<00:23, 30.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:39,177 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|█▉        | 173M/892M [00:04<00:22, 31.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:39,277 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|█▉        | 177M/892M [00:04<00:22, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,311 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|█▋        | 146M/892M [00:03<00:21, 35.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|█▋        | 150M/892M [00:03<00:19, 37.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,607 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|█▋        | 154M/892M [00:03<00:24, 30.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,707 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|█▊        | 158M/892M [00:04<00:23, 31.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,807 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|█▊        | 162M/892M [00:04<00:21, 33.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:38,967 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|█▊        | 166M/892M [00:04<00:20, 35.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:39,067 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|█▉        | 169M/892M [00:04<00:23, 30.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:39,177 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|█▉        | 173M/892M [00:04<00:22, 31.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:39,277 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|█▉        | 177M/892M [00:04<00:22, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,409 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|██▍       | 214M/892M [00:05<00:19, 34.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,509 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|██▍       | 218M/892M [00:05<00:21, 31.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|██▍       | 222M/892M [00:05<00:19, 33.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,727 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|██▌       | 225M/892M [00:06<00:20, 33.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,831 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|██▌       | 228M/892M [00:06<00:20, 32.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:40,981 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|██▌       | 232M/892M [00:06<00:19, 34.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,082 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|██▋       | 236M/892M [00:06<00:21, 30.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,182 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|██▋       | 239M/892M [00:06<00:21, 30.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,409 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|██▍       | 214M/892M [00:05<00:19, 34.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,509 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|██▍       | 218M/892M [00:05<00:21, 31.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|██▍       | 222M/892M [00:05<00:19, 33.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,727 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|██▌       | 225M/892M [00:06<00:20, 33.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,831 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|██▌       | 228M/892M [00:06<00:20, 32.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:40,981 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|██▌       | 232M/892M [00:06<00:19, 34.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,082 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|██▋       | 236M/892M [00:06<00:21, 30.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,182 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|██▋       | 239M/892M [00:06<00:21, 30.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|██▋       | 243M/892M [00:06<00:20, 31.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,514 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|██▊       | 247M/892M [00:06<00:22, 28.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,615 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|██▊       | 250M/892M [00:06<00:25, 24.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|██▊       | 253M/892M [00:07<00:23, 27.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,827 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|██▊       | 256M/892M [00:07<00:23, 27.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:41,927 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|██▉       | 259M/892M [00:07<00:23, 27.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,027 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|██▉       | 263M/892M [00:07<00:20, 30.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,149 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|███       | 268M/892M [00:07<00:17, 36.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|███       | 272M/892M [00:07<00:17, 34.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|██▋       | 243M/892M [00:06<00:20, 31.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,514 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|██▊       | 247M/892M [00:06<00:22, 28.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,615 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|██▊       | 250M/892M [00:06<00:25, 24.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|██▊       | 253M/892M [00:07<00:23, 27.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,827 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|██▊       | 256M/892M [00:07<00:23, 27.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:41,927 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|██▉       | 259M/892M [00:07<00:23, 27.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,027 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|██▉       | 263M/892M [00:07<00:20, 30.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,149 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|███       | 268M/892M [00:07<00:17, 36.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|███       | 272M/892M [00:07<00:17, 34.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|███       | 275M/892M [00:07<00:18, 34.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,457 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|███▏      | 281M/892M [00:07<00:15, 39.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,573 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|███▏      | 287M/892M [00:07<00:12, 48.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,673 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|███▎      | 292M/892M [00:07<00:12, 46.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,773 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|███▎      | 298M/892M [00:08<00:12, 48.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,889 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|███▍      | 303M/892M [00:08<00:11, 49.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:42,994 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|███▍      | 308M/892M [00:08<00:12, 47.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|███▌      | 313M/892M [00:08<00:12, 46.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,223 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|███▌      | 317M/892M [00:08<00:12, 44.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,357 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|███       | 275M/892M [00:07<00:18, 34.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,457 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|███▏      | 281M/892M [00:07<00:15, 39.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,573 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|███▏      | 287M/892M [00:07<00:12, 48.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,673 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|███▎      | 292M/892M [00:07<00:12, 46.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,773 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|███▎      | 298M/892M [00:08<00:12, 48.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,889 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|███▍      | 303M/892M [00:08<00:11, 49.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:42,994 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|███▍      | 308M/892M [00:08<00:12, 47.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|███▌      | 313M/892M [00:08<00:12, 46.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,223 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|███▌      | 317M/892M [00:08<00:12, 44.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,323 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|███▌      | 322M/892M [00:08<00:13, 43.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,423 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|███▋      | 326M/892M [00:08<00:12, 44.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|███▋      | 331M/892M [00:08<00:12, 44.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,651 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|███▊      | 337M/892M [00:08<00:11, 48.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,751 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|███▊      | 342M/892M [00:09<00:12, 45.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  39%|███▉      | 348M/892M [00:09<00:10, 49.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:43,995 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|███▉      | 353M/892M [00:09<00:11, 47.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,116 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|████      | 358M/892M [00:09<00:11, 44.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,269 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|████      | 362M/892M [00:09<00:12, 42.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,323 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|███▌      | 322M/892M [00:08<00:13, 43.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,423 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|███▋      | 326M/892M [00:08<00:12, 44.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|███▋      | 331M/892M [00:08<00:12, 44.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,651 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|███▊      | 337M/892M [00:08<00:11, 48.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,751 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|███▊      | 342M/892M [00:09<00:12, 45.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,867 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  39%|███▉      | 348M/892M [00:09<00:10, 49.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:43,995 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|███▉      | 353M/892M [00:09<00:11, 47.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,116 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|████      | 358M/892M [00:09<00:11, 44.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,269 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|████      | 362M/892M [00:09<00:12, 42.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|████      | 367M/892M [00:09<00:14, 37.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,572 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|████▏     | 373M/892M [00:09<00:11, 43.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,672 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|████▏     | 378M/892M [00:09<00:14, 35.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,782 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|████▎     | 382M/892M [00:10<00:14, 35.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:44,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|████▎     | 385M/892M [00:10<00:14, 35.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|████▎     | 389M/892M [00:10<00:14, 34.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|████▍     | 393M/892M [00:10<00:14, 35.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,201 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|████▍     | 397M/892M [00:10<00:13, 37.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|████      | 367M/892M [00:09<00:14, 37.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,572 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|████▏     | 373M/892M [00:09<00:11, 43.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,672 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|████▏     | 378M/892M [00:09<00:14, 35.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,782 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|████▎     | 382M/892M [00:10<00:14, 35.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:44,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|████▎     | 385M/892M [00:10<00:14, 35.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|████▎     | 389M/892M [00:10<00:14, 34.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|████▍     | 393M/892M [00:10<00:14, 35.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,201 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|████▍     | 397M/892M [00:10<00:13, 37.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|████▌     | 401M/892M [00:10<00:12, 38.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,471 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|████▌     | 405M/892M [00:10<00:15, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,571 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|████▌     | 410M/892M [00:10<00:13, 35.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,731 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|████▋     | 415M/892M [00:10<00:12, 39.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,851 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|████▋     | 419M/892M [00:11<00:13, 34.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:45,951 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|████▋     | 423M/892M [00:11<00:14, 33.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,076 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|████▊     | 427M/892M [00:11<00:12, 35.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,176 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|████▊     | 431M/892M [00:11<00:12, 36.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,287 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  49%|████▉     | 438M/892M [00:11<00:10, 43.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,370 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|████▌     | 401M/892M [00:10<00:12, 38.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,471 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|████▌     | 405M/892M [00:10<00:15, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,571 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|████▌     | 410M/892M [00:10<00:13, 35.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,731 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|████▋     | 415M/892M [00:10<00:12, 39.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,851 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|████▋     | 419M/892M [00:11<00:13, 34.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:45,951 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|████▋     | 423M/892M [00:11<00:14, 33.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,076 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|████▊     | 427M/892M [00:11<00:12, 35.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,176 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|████▊     | 431M/892M [00:11<00:12, 36.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,287 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  49%|████▉     | 438M/892M [00:11<00:10, 43.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|████▉     | 443M/892M [00:11<00:10, 42.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,681 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|█████     | 447M/892M [00:11<00:13, 32.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|█████     | 451M/892M [00:12<00:15, 28.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,886 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|█████     | 455M/892M [00:12<00:14, 31.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:46,987 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|█████▏    | 458M/892M [00:12<00:13, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,087 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|█████▏    | 462M/892M [00:12<00:12, 33.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,188 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|█████▏    | 467M/892M [00:12<00:11, 37.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,288 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|█████▎    | 472M/892M [00:12<00:10, 40.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,506 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|████▉     | 443M/892M [00:11<00:10, 42.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,681 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|█████     | 447M/892M [00:11<00:13, 32.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|█████     | 451M/892M [00:12<00:15, 28.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,886 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|█████     | 455M/892M [00:12<00:14, 31.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:46,987 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|█████▏    | 458M/892M [00:12<00:13, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,087 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|█████▏    | 462M/892M [00:12<00:12, 33.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,188 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|█████▏    | 467M/892M [00:12<00:11, 37.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,288 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|█████▎    | 472M/892M [00:12<00:10, 40.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,388 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|█████▎    | 477M/892M [00:12<00:09, 42.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,488 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|█████▍    | 481M/892M [00:12<00:09, 44.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,588 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|█████▍    | 486M/892M [00:12<00:08, 45.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,694 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|█████▌    | 493M/892M [00:12<00:07, 50.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|█████▌    | 498M/892M [00:13<00:07, 49.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:47,933 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|█████▋    | 503M/892M [00:13<00:07, 49.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,033 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|█████▋    | 508M/892M [00:13<00:08, 44.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,144 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|█████▊    | 513M/892M [00:13<00:08, 47.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,388 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|█████▎    | 477M/892M [00:12<00:09, 42.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,488 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|█████▍    | 481M/892M [00:12<00:09, 44.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,588 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|█████▍    | 486M/892M [00:12<00:08, 45.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,694 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|█████▌    | 493M/892M [00:12<00:07, 50.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|█████▌    | 498M/892M [00:13<00:07, 49.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:47,933 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|█████▋    | 503M/892M [00:13<00:07, 49.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,033 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|█████▋    | 508M/892M [00:13<00:08, 44.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,144 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|█████▊    | 513M/892M [00:13<00:08, 47.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,271 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|█████▊    | 518M/892M [00:13<00:08, 45.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,271 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|█████▊    | 518M/892M [00:13<00:08, 45.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|█████▊    | 523M/892M [00:13<00:08, 43.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,492 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|█████▉    | 527M/892M [00:13<00:08, 40.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,592 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|█████▉    | 532M/892M [00:13<00:08, 42.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,764 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|██████    | 537M/892M [00:13<00:07, 44.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:48,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|██████    | 541M/892M [00:14<00:09, 37.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|██████    | 545M/892M [00:14<00:10, 34.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|██████▏   | 549M/892M [00:14<00:09, 34.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|██████▏   | 554M/892M [00:14<00:08, 38.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,392 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|█████▊    | 523M/892M [00:13<00:08, 43.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,492 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|█████▉    | 527M/892M [00:13<00:08, 40.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,592 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|█████▉    | 532M/892M [00:13<00:08, 42.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,764 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|██████    | 537M/892M [00:13<00:07, 44.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:48,900 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|██████    | 541M/892M [00:14<00:09, 37.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|██████    | 545M/892M [00:14<00:10, 34.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|██████▏   | 549M/892M [00:14<00:09, 34.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|██████▏   | 554M/892M [00:14<00:08, 38.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|██████▎   | 558M/892M [00:14<00:08, 38.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,414 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|██████▎   | 563M/892M [00:14<00:07, 41.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|██████▎   | 567M/892M [00:14<00:07, 42.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,714 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|██████▍   | 573M/892M [00:14<00:07, 45.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|██████▎   | 558M/892M [00:14<00:08, 38.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,414 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|██████▎   | 563M/892M [00:14<00:07, 41.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|██████▎   | 567M/892M [00:14<00:07, 42.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,714 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|██████▍   | 573M/892M [00:14<00:07, 45.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,884 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|██████▍   | 577M/892M [00:15<00:08, 35.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:49,983 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|██████▌   | 581M/892M [00:15<00:10, 30.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,083 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|██████▌   | 585M/892M [00:15<00:09, 32.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,183 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|██████▌   | 589M/892M [00:15<00:08, 34.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,286 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|██████▋   | 594M/892M [00:15<00:07, 39.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,884 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|██████▍   | 577M/892M [00:15<00:08, 35.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:49,983 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|██████▌   | 581M/892M [00:15<00:10, 30.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,083 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|██████▌   | 585M/892M [00:15<00:09, 32.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,183 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|██████▌   | 589M/892M [00:15<00:08, 34.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,286 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|██████▋   | 594M/892M [00:15<00:07, 39.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,387 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|██████▋   | 601M/892M [00:15<00:06, 46.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|██████▊   | 606M/892M [00:15<00:06, 47.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,624 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|██████▊   | 611M/892M [00:15<00:06, 43.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|██████▉   | 616M/892M [00:16<00:06, 44.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,824 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|██████▉   | 620M/892M [00:16<00:05, 45.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:50,931 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|███████   | 625M/892M [00:16<00:05, 46.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,032 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|███████   | 630M/892M [00:16<00:05, 45.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,160 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|███████   | 635M/892M [00:16<00:05, 47.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,387 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|██████▋   | 601M/892M [00:15<00:06, 46.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,524 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|██████▊   | 606M/892M [00:15<00:06, 47.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,624 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|██████▊   | 611M/892M [00:15<00:06, 43.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,724 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|██████▉   | 616M/892M [00:16<00:06, 44.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,824 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|██████▉   | 620M/892M [00:16<00:05, 45.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:50,931 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|███████   | 625M/892M [00:16<00:05, 46.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,032 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|███████   | 630M/892M [00:16<00:05, 45.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,160 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|███████   | 635M/892M [00:16<00:05, 47.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,321 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|███████▏  | 640M/892M [00:16<00:05, 44.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,321 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|███████▏  | 640M/892M [00:16<00:05, 44.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,422 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|███████▏  | 644M/892M [00:16<00:06, 37.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,522 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|███████▎  | 649M/892M [00:16<00:06, 38.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,626 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|███████▎  | 653M/892M [00:16<00:05, 40.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,742 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|███████▎  | 657M/892M [00:17<00:05, 41.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:51,856 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|███████▍  | 662M/892M [00:17<00:05, 39.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,026 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|███████▍  | 666M/892M [00:17<00:05, 38.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,126 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|███████▌  | 670M/892M [00:17<00:06, 32.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,226 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|███████▌  | 676M/892M [00:17<00:05, 39.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,422 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|███████▏  | 644M/892M [00:16<00:06, 37.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,522 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|███████▎  | 649M/892M [00:16<00:06, 38.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,626 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|███████▎  | 653M/892M [00:16<00:05, 40.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,742 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|███████▎  | 657M/892M [00:17<00:05, 41.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:51,856 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|███████▍  | 662M/892M [00:17<00:05, 39.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,026 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|███████▍  | 666M/892M [00:17<00:05, 38.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,126 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|███████▌  | 670M/892M [00:17<00:06, 32.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,226 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|███████▌  | 676M/892M [00:17<00:05, 39.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|███████▋  | 680M/892M [00:17<00:05, 41.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,428 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|███████▋  | 686M/892M [00:17<00:04, 46.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,528 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|███████▊  | 691M/892M [00:17<00:04, 46.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,628 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|███████▊  | 697M/892M [00:17<00:03, 49.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|███████▉  | 702M/892M [00:18<00:03, 50.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:52,902 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|███████▉  | 707M/892M [00:18<00:04, 44.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,002 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|███████▉  | 712M/892M [00:18<00:04, 42.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|████████  | 718M/892M [00:18<00:03, 46.3MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,213 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|████████  | 723M/892M [00:18<00:03, 47.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|███████▋  | 680M/892M [00:17<00:05, 41.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,428 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|███████▋  | 686M/892M [00:17<00:04, 46.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,528 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|███████▊  | 691M/892M [00:17<00:04, 46.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,628 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|███████▊  | 697M/892M [00:17<00:03, 49.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,781 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|███████▉  | 702M/892M [00:18<00:03, 50.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:52,902 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|███████▉  | 707M/892M [00:18<00:04, 44.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,002 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|███████▉  | 712M/892M [00:18<00:04, 42.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|████████  | 718M/892M [00:18<00:03, 46.3MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,213 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|████████  | 723M/892M [00:18<00:03, 47.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|████████▏ | 728M/892M [00:18<00:03, 46.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,426 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|████████▏ | 733M/892M [00:18<00:03, 45.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,526 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%|████████▎ | 739M/892M [00:18<00:02, 51.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,629 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|████████▎ | 746M/892M [00:18<00:02, 55.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,757 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|████████▍ | 752M/892M [00:19<00:02, 55.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,857 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%|████████▍ | 757M/892M [00:19<00:02, 51.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:53,959 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|████████▌ | 763M/892M [00:19<00:02, 53.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:54,157 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|████████▌ | 769M/892M [00:19<00:02, 53.8MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:54,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%|████████▋ | 774M/892M [00:19<00:02, 42.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,326 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|████████▏ | 728M/892M [00:18<00:03, 46.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,426 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|████████▏ | 733M/892M [00:18<00:03, 45.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,526 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%|████████▎ | 739M/892M [00:18<00:02, 51.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,629 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|████████▎ | 746M/892M [00:18<00:02, 55.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,757 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|████████▍ | 752M/892M [00:19<00:02, 55.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,857 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%|████████▍ | 757M/892M [00:19<00:02, 51.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:53,959 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|████████▌ | 763M/892M [00:19<00:02, 53.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:54,157 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|████████▌ | 769M/892M [00:19<00:02, 53.8MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:54,257 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%|████████▋ | 774M/892M [00:19<00:02, 42.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,362 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|█████████▎| 830M/892M [00:20<00:01, 50.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,481 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|█████████▎| 835M/892M [00:20<00:01, 48.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,581 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|█████████▍| 840M/892M [00:20<00:01, 46.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,698 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|█████████▍| 845M/892M [00:20<00:01, 46.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|█████████▌| 849M/892M [00:21<00:00, 44.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:55,911 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|█████████▌| 856M/892M [00:21<00:00, 50.1MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,012 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|█████████▋| 861M/892M [00:21<00:00, 48.4MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,112 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|█████████▋| 867M/892M [00:21<00:00, 51.2MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,256 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|█████████▊| 872M/892M [00:21<00:00, 51.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,362 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|█████████▎| 830M/892M [00:20<00:01, 50.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,481 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|█████████▎| 835M/892M [00:20<00:01, 48.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,581 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|█████████▍| 840M/892M [00:20<00:01, 46.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,698 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|█████████▍| 845M/892M [00:20<00:01, 46.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,797 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|█████████▌| 849M/892M [00:21<00:00, 44.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:55,911 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|█████████▌| 856M/892M [00:21<00:00, 50.1MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,012 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|█████████▋| 861M/892M [00:21<00:00, 48.4MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,112 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|█████████▋| 867M/892M [00:21<00:00, 51.2MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,256 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|█████████▊| 872M/892M [00:21<00:00, 51.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,361 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|█████████▊| 877M/892M [00:21<00:00, 45.9MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,461 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|█████████▉| 882M/892M [00:21<00:00, 47.0MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:56,538 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|█████████▉| 887M/892M [00:21<00:00, 47.7MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,361 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|█████████▊| 877M/892M [00:21<00:00, 45.9MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,461 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|█████████▉| 882M/892M [00:21<00:00, 47.0MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:56,538 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|█████████▉| 887M/892M [00:21<00:00, 47.7MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,605 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|██████████| 892M/892M [00:21<00:00, 40.6MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,606 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|██████████| 792k/792k [00:00<00:00, 63.5MB/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[34m2022-08-17 03:45:59,783 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:00,264 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35361\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:35615|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707960\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:72|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,605 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|██████████| 892M/892M [00:21<00:00, 40.6MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,606 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,618 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|██████████| 792k/792k [00:00<00:00, 63.5MB/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,763 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001B[0m\n",
      "\u001B[35m2022-08-17 03:45:59,783 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:00,264 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35361\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:35615|#Level:Host|#hostname:96d3b230a6af,timestamp:1660707960\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:00,265 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:72|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1171\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1171\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1169.13|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:98591bdd-3b5e-4e88-adc1-483f26497e82,timestamp:1660707961\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 36267\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:35087|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,436 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1169.13|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:98591bdd-3b5e-4e88-adc1-483f26497e82,timestamp:1660707961\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 36267\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:35087|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:01,437 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1935.92|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:d284310b-e7e6-43fb-9833-443ad6a93996,timestamp:1660707963\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1938\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1935.92|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:d284310b-e7e6-43fb-9833-443ad6a93996,timestamp:1660707963\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1938\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,427 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:03,428 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\n",
      "\u001B[34m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3398.71|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:42c7ef98-007c-4ebd-89f9-99adcd6c7b53,timestamp:1660707968\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3400\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 3400\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:3398.71|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:42c7ef98-007c-4ebd-89f9-99adcd6c7b53,timestamp:1660707968\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3400\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,321 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 3400\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:08,322 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1083\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1083\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1082.82|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:6a9de375-6c75-4741-afe2-d563035262b9,timestamp:1660707969\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1085\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[34m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,409 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1082.82|#ModelName:model,Level:Model|#hostname:96d3b230a6af,requestID:6a9de375-6c75-4741-afe2-d563035262b9,timestamp:1660707969\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:60802 \"POST /invocations HTTP/1.1\" 200 1085\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n",
      "\u001B[35m2022-08-17 03:46:09,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:96d3b230a6af,timestamp:null\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# starts batch transform job and uses S3 data as input\n",
    "batch_job.transform(\n",
    "    data=input_s3_path,\n",
    "    content_type='application/json',    \n",
    "    split_type='Line'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ec5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.s3 import S3Downloader\n",
    "from ast import literal_eval\n",
    "# creating s3 uri for result file -> input file + .out\n",
    "output_file = f\"{dataset_jsonl_file}.out\"\n",
    "output_path = s3_path_join(\"s3://sagemaker-us-east-1-726335585155/batch_transform/output\",output_file)\n",
    "\n",
    "local_path = \"output\"  # Where to save the output locally\n",
    "\n",
    "S3Downloader.download(output_path,local_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d7ae96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting jsonlines\n",
      "  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages (from jsonlines) (21.2.0)\n",
      "Installing collected packages: jsonlines\n",
      "Successfully installed jsonlines-3.1.0\n",
      "\u001B[33mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001B[0m\u001B[33m\n",
      "\u001B[0m"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe820515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": \"(VERY extra large, size)\"}{\"result\": \"(I really liked the look of this dress, style); (It just wasn\\u2019t cute on me, feelings)\"}{\"result\": \"(Beautifully made, quality); (made in China, scene)\"}{\"result\": \"(I went up a size, size); (run a little small, size); (great quality, quality); (lined, fabric); (light weight, fabric); (very happy, feelings); (highly recommend, purchase_behavior)\"}{\"result\": \"(Not true to size, size)\"}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the output\n",
    "\n",
    "import os\n",
    "import jsonlines\n",
    "import json\n",
    "from ast import literal_eval\n",
    "\n",
    "output_file = f\"{dataset_jsonl_file}.out\"\n",
    "\n",
    "batch_transform_result = []\n",
    "\n",
    "path = os.path.join(local_path, output_file)\n",
    "with open(path, \"r\") as f:\n",
    "    for line in f:\n",
    "        print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5a4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}