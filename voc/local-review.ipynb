{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10c9e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.6.0\n",
      "  Using cached transformers-4.6.0-py3-none-any.whl (2.3 MB)\n",
      "Collecting datasets==1.11.0\n",
      "  Using cached datasets-1.11.0-py3-none-any.whl (264 kB)\n",
      "Collecting sentencepiece==0.1.91\n",
      "  Using cached sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting pytorch_lightning==0.8.1\n",
      "  Using cached pytorch_lightning-0.8.1-py3-none-any.whl (293 kB)\n",
      "Collecting jieba\n",
      "  Using cached jieba-0.42.1-py3-none-any.whl\n",
      "Collecting editdistance\n",
      "  Using cached editdistance-0.6.0-cp36-cp36m-manylinux2010_x86_64.whl (284 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2020.11.13)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Using cached huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (3.7.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (21.3)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp36-cp36m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (1.19.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (0.8)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from transformers==4.6.0->-r requirements.txt (line 1)) (2.26.0)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting fsspec>=2021.05.0\n",
      "  Using cached fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (0.70.12.2)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from datasets==1.11.0->-r requirements.txt (line 2)) (1.1.5)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.0.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (1.7.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.18.2)\n",
      "Collecting tensorboard>=1.14\n",
      "  Using cached tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (2.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from requests->transformers==4.6.0->-r requirements.txt (line 1)) (1.26.8)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.46.3-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (2.0.2)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (3.19.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (49.6.0.post20210108)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.36.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.8.0-py2.py3-none-any.whl (164 kB)\n",
      "     |████████████████████████████████| 164 kB 21.7 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from torch>=1.3->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from importlib-metadata->transformers==4.6.0->-r requirements.txt (line 1)) (3.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from packaging->transformers==4.6.0->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pandas->datasets==1.11.0->-r requirements.txt (line 2)) (2021.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from sacremoses->transformers==4.6.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 32.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (4.7.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch_lightning==0.8.1->-r requirements.txt (line 4)) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, filelock, absl-py, xxhash, tokenizers, tensorboard, sacremoses, huggingface-hub, fsspec, transformers, sentencepiece, pytorch-lightning, jieba, editdistance, datasets\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.7.0\n",
      "    Uninstalling importlib-metadata-3.7.0:\n",
      "      Successfully uninstalled importlib-metadata-3.7.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2021.4.0\n",
      "    Uninstalling fsspec-2021.4.0:\n",
      "      Successfully uninstalled fsspec-2021.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2021.4.0 requires fsspec==2021.04.0, but you have fsspec 2022.1.0 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-1.1.0 cachetools-4.2.4 datasets-1.11.0 editdistance-0.6.0 filelock-3.4.1 fsspec-2022.1.0 google-auth-2.8.0 google-auth-oauthlib-0.4.6 grpcio-1.46.3 huggingface-hub-0.0.8 importlib-metadata-4.8.3 jieba-0.42.1 markdown-3.3.7 oauthlib-3.2.0 pyasn1-modules-0.2.8 pytorch-lightning-0.8.1 requests-oauthlib-1.3.1 sacremoses-0.0.53 sentencepiece-0.1.91 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tokenizers-0.10.3 transformers-4.6.0 xxhash-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65edd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "import numpy as np\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a69567a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  sent_num                                               text  \\\n",
      "0           0         0  We are new to the sport and have not used othe...   \n",
      "1           1         1  Bought for my parents retirement. They are lov...   \n",
      "2           2         2  Good set.  Paddles and balls are both good qua...   \n",
      "3           3         3  Got into Pickleball this year and researched a...   \n",
      "4           4         4  I love these paddles and the case but didn’t r...   \n",
      "\n",
      "   sent_start  sent_end  sent_len  \\\n",
      "0           0        85        85   \n",
      "1          85       140        55   \n",
      "2         140       191        51   \n",
      "3         191       590       399   \n",
      "4         590       768       178   \n",
      "\n",
      "                                               label  \n",
      "0                           [('paddles', 'product')]  \n",
      "1                          [('parents', 'consumer')]  \n",
      "2                 [('Paddles and balls', 'product')]  \n",
      "3  [('paddle', 'product'), ('me and my wife', 'co...  \n",
      "4  [('paddles', 'product'), ('didn’t realize thes...  \n",
      "<< path valid!\n",
      "training size:  (1018, 7)\n",
      "test size:  (128, 7)\n",
      "validate size:  (127, 7)\n",
      "<<<finish data preparing!\n"
     ]
    }
   ],
   "source": [
    "#preprocess data\n",
    "def write_txt(df,path):\n",
    "    '''\n",
    "    write back to txt\n",
    "    '''\n",
    "    #output txt file\n",
    "    df = df.reset_index()\n",
    "    with open(path,'a')as f:\n",
    "        for i in range(len(df)):\n",
    "            f.write(\"{} #### {}\".format(df.loc[i,'text'].strip(),df.loc[i,'label']))\n",
    "            f.write('\\n')\n",
    "            \n",
    "            \n",
    "def mkdir_rm(folder):\n",
    "    '''\n",
    "    make directory if not exists\n",
    "    '''\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder) \n",
    "    os.mkdir(folder)\n",
    "    print (\"<< path valid!\")\n",
    "    \n",
    "\n",
    "def preprocess_data(input_file,output_path,over_sample=True):\n",
    "    jsonObj = pd.read_csv(input_file)\n",
    "    jsonObj = jsonObj[jsonObj['label']!='[]']\n",
    "    print (jsonObj.head())\n",
    "    \n",
    "    #remove & remake the output folder \n",
    "    mkdir_rm(output_path)\n",
    "    \n",
    "    #generate tag.txt\n",
    "    a_list = ['consumer','zone','target','consequence','product','product_spec']\n",
    "    with open('tag.txt', 'w') as filehandle:\n",
    "        filehandle.writelines(\"%s\\n\" % tag for tag in a_list)\n",
    "    \n",
    "    #train/test/val split\n",
    "    train, validate, test = np.split(jsonObj.sample(frac=1), [int(.8*len(jsonObj)), int(.9*len(jsonObj))])\n",
    "   \n",
    "    print (\"training size: \",train.shape)\n",
    "    print (\"test size: \",test.shape)\n",
    "    print (\"validate size: \",validate.shape)\n",
    "    \n",
    "    # write train/test/dev\n",
    "    write_txt(train,os.path.join(output_path,'train.txt'))\n",
    "    write_txt(test,os.path.join(output_path,'test.txt'))\n",
    "    write_txt(validate,os.path.join(output_path,'dev.txt'))\n",
    "    print (\"<<<finish data preparing!\")\n",
    "    \n",
    "input_file = './aspect_category.csv'\n",
    "output_path = './data/tasd/haofangReview'\n",
    "preprocess_data(input_file,output_path,over_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb45a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Error: mkl-service + Intel(R) MKL: MKL_THREADING_LAYER=INTEL is incompatible with libgomp.so.1 library.\n",
    "#\tTry to import numpy first or set the threading layer accordingly. Set MKL_SERVICE_FORCE_INTEL to force it.\n",
    "\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ed343",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17f44d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================== NEW EXP: TASD on haofangReview ============================== \n",
      "\n",
      "Downloading: 100%|███████████████████████████| 792k/792k [00:00<00:00, 25.5MB/s]\n",
      "Downloading: 100%|█████████████████████████| 1.39M/1.39M [00:00<00:00, 42.3MB/s]\n",
      "Here is an example (from dev set) under `extraction` paradigm:\n",
      "Total examples = 127 for data/tasd/haofangReview/dev.txt\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "Input : My job provided me a headset to use as we are switching to Skype for all of our calls. This works great with Skype! And way better than having to be strapped to my desk with a headset. Awesome product!\n",
      "Output: (product, product); (This, product)\n",
      "\n",
      "****** Conduct Training ******\n",
      "Downloading: 100%|█████████████████████████| 1.20k/1.20k [00:00<00:00, 1.78MB/s]\n",
      "Downloading: 100%|███████████████████████████| 892M/892M [00:28<00:00, 31.3MB/s]\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 222 M \n",
      "Total examples = 127 for data/tasd/haofangReview/dev.txt\n",
      "Total examples = 1018 for data/tasd/haofangReview/train.txt                     \n",
      "Total examples = 127 for data/tasd/haofangReview/dev.txt\n",
      "Epoch 1:  89%|█████████▊ | 509/573 [01:29<00:11,  5.68it/s, loss=0.465, v_num=0]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  89%|█████████▊ | 510/573 [01:29<00:11,  5.69it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  90%|█████████▊ | 513/573 [01:29<00:10,  5.71it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  90%|█████████▉ | 516/573 [01:29<00:09,  5.73it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  91%|█████████▉ | 519/573 [01:30<00:09,  5.76it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  91%|██████████ | 522/573 [01:30<00:08,  5.78it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  92%|██████████ | 525/573 [01:30<00:08,  5.81it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  92%|██████████▏| 528/573 [01:30<00:07,  5.83it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  93%|██████████▏| 531/573 [01:30<00:07,  5.85it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  93%|██████████▎| 534/573 [01:30<00:06,  5.88it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  94%|██████████▎| 537/573 [01:30<00:06,  5.90it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  94%|██████████▎| 540/573 [01:31<00:05,  5.93it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  95%|██████████▍| 543/573 [01:31<00:05,  5.95it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  95%|██████████▍| 546/573 [01:31<00:04,  5.97it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  96%|██████████▌| 549/573 [01:31<00:04,  6.00it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  96%|██████████▌| 552/573 [01:31<00:03,  6.02it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  97%|██████████▋| 555/573 [01:31<00:02,  6.04it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  97%|██████████▋| 558/573 [01:31<00:02,  6.07it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  98%|██████████▊| 561/573 [01:32<00:01,  6.09it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  98%|██████████▊| 564/573 [01:32<00:01,  6.11it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  99%|██████████▉| 567/573 [01:32<00:00,  6.14it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1:  99%|██████████▉| 570/573 [01:32<00:00,  6.16it/s, loss=0.465, v_num=0]\u001b[A\n",
      "Epoch 1: 100%|█| 573/573 [01:32<00:00,  6.18it/s, loss=0.465, v_num=0, val_loss=\u001b[A\n",
      "Epoch 1: 100%|█| 573/573 [01:37<00:00,  5.87it/s, loss=0.465, v_num=0, val_loss=\u001b[A\n",
      "Finish training and saving the model!\n",
      "CPU times: user 2.26 s, sys: 599 ms, total: 2.86 s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!python -u main.py --task tasd \\\n",
    "            --dataset haofangReview \\\n",
    "            --paradigm extraction \\\n",
    "            --n_gpu '0' \\\n",
    "            --model_name_or_path t5-base \\\n",
    "            --do_train \\\n",
    "            --train_batch_size 2 \\\n",
    "            --gradient_accumulation_steps 2 \\\n",
    "            --eval_batch_size 2 \\\n",
    "            --learning_rate 3e-4 \\\n",
    "            --num_train_epochs 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf0787",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12bf31ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================== NEW EXP: TASD on haofangReview ============================== \n",
      "\n",
      "Here is an example (from dev set) under `extraction` paradigm:\n",
      "Total examples = 127 for data/tasd/haofangReview/dev.txt\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "Input : My job provided me a headset to use as we are switching to Skype for all of our calls. This works great with Skype! And way better than having to be strapped to my desk with a headset. Awesome product!\n",
      "Output: (product, product); (This, product)\n",
      "\n",
      "****** Conduct Evaluating with the last state ******\n",
      "\n",
      "Load the trained model from outputs/tasd/haofangReview/extraction/cktepoch=1.ckpt...\n",
      "<<< read lines\n",
      "Total examples = 128 for data/tasd/haofangReview/test.txt\n",
      "<<< load test data\n",
      "Total examples = 128 for data/tasd/haofangReview/test.txt\n",
      "<<<< start evaluate\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:16<00:00, 16.46s/it]\n",
      "\n",
      "Results of raw output, only tag category\n",
      "<<<< res {'product': {'n_tp': 47, 'n_gold': 76, 'n_pred': 61, 'precision': 0.7704918032786885, 'recall': 0.618421052631579, 'f1': 0.6861313868613139}, '': {'n_tp': 5, 'n_gold': 8, 'n_pred': 31, 'precision': 0.16129032258064516, 'recall': 0.625, 'f1': 0.2564102564102564}, 'product_spe': {'n_tp': 0, 'n_gold': 0, 'n_pred': 1, 'precision': 0.0, 'recall': 0, 'f1': 0}, 'zone': {'n_tp': 0, 'n_gold': 8, 'n_pred': 1, 'precision': 0.0, 'recall': 0.0, 'f1': 0}, 'consumer)': {'n_tp': 0, 'n_gold': 0, 'n_pred': 1, 'precision': 0.0, 'recall': 0, 'f1': 0}, 'product_spec)': {'n_tp': 0, 'n_gold': 0, 'n_pred': 1, 'precision': 0.0, 'recall': 0, 'f1': 0}, 'consumer': {'n_tp': 11, 'n_gold': 30, 'n_pred': 21, 'precision': 0.5238095238095238, 'recall': 0.36666666666666664, 'f1': 0.4313725490196078}, 'target': {'n_tp': 1, 'n_gold': 23, 'n_pred': 7, 'precision': 0.14285714285714285, 'recall': 0.043478260869565216, 'f1': 0.06666666666666667}, 'product_spec': {'n_tp': 27, 'n_gold': 47, 'n_pred': 54, 'precision': 0.5, 'recall': 0.574468085106383, 'f1': 0.5346534653465347}, 'consume': {'n_tp': 0, 'n_gold': 0, 'n_pred': 1, 'precision': 0.0, 'recall': 0, 'f1': 0}, 'produc': {'n_tp': 0, 'n_gold': 0, 'n_pred': 6, 'precision': 0.0, 'recall': 0, 'f1': 0}, 'consequence': {'n_tp': 41, 'n_gold': 62, 'n_pred': 65, 'precision': 0.6307692307692307, 'recall': 0.6612903225806451, 'f1': 0.6456692913385826}}\n",
      "{'total precision': 0.528, 'total recall': 0.5196850393700787, 'total f1': 0.5238095238095237}\n",
      "\n",
      "Results of raw output, total\n",
      "{'total precision': 0.14722222222222223, 'total recall': 0.13984168865435356, 'total f1': 0.14343707713125847}\n",
      "raw results:  [['product', '', 'consumer', 'product_spec', 'consequence'], ['product', 'target', 'consequence'], ['', 'consequence', 'product_spec'], ['product'], ['product']]\n",
      "all_predictions_fixed:  [['product', 'zone', 'consumer', 'product_spec', 'consequence'], ['product', 'target', 'consequence'], ['zone', 'consequence', 'product_spec'], ['product'], ['product']]\n",
      "\n",
      "Results of fixed output\n",
      "<<<< res {'product': {'n_tp': 48, 'n_gold': 76, 'n_pred': 62, 'precision': 0.7741935483870968, 'recall': 0.631578947368421, 'f1': 0.6956521739130435}, '': {'n_tp': 0, 'n_gold': 8, 'n_pred': 0, 'precision': 0, 'recall': 0.0, 'f1': 0}, 'zone': {'n_tp': 3, 'n_gold': 8, 'n_pred': 32, 'precision': 0.09375, 'recall': 0.375, 'f1': 0.15}, 'consumer': {'n_tp': 11, 'n_gold': 30, 'n_pred': 21, 'precision': 0.5238095238095238, 'recall': 0.36666666666666664, 'f1': 0.4313725490196078}, 'target': {'n_tp': 1, 'n_gold': 23, 'n_pred': 7, 'precision': 0.14285714285714285, 'recall': 0.043478260869565216, 'f1': 0.06666666666666667}, 'product_spec': {'n_tp': 27, 'n_gold': 47, 'n_pred': 54, 'precision': 0.5, 'recall': 0.574468085106383, 'f1': 0.5346534653465347}, 'consequence': {'n_tp': 41, 'n_gold': 62, 'n_pred': 65, 'precision': 0.6307692307692307, 'recall': 0.6612903225806451, 'f1': 0.6456692913385826}}\n",
      "{'total precision': 0.5435684647302904, 'total recall': 0.515748031496063, 'total f1': 0.5292929292929294}\n"
     ]
    }
   ],
   "source": [
    "!python main.py --task tasd \\\n",
    "            --dataset haofangReview \\\n",
    "            --ckpoint_path outputs/tasd/haofangReview/extraction/cktepoch=1.ckpt \\\n",
    "            --model_name_or_path  t5-base \\\n",
    "            --paradigm extraction \\\n",
    "            --n_gpu '0' \\\n",
    "            --do_direct_eval \\\n",
    "            --eval_batch_size 128 \\\n",
    "            --customer_jj False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e695ace",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed39e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ============================== NEW EXP: TASD on haofangReview ============================== \n",
      "\n",
      "Here is an example (from dev set) under `extraction` paradigm:\n",
      "Total examples = 127 for data/tasd/haofangReview/dev.txt\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "Input : My job provided me a headset to use as we are switching to Skype for all of our calls. This works great with Skype! And way better than having to be strapped to my desk with a headset. Awesome product!\n",
      "Output: (product, product); (This, product)\n",
      "\n",
      "****** Conduct predicting with the last state ******\n",
      "\n",
      "Load the trained model from outputs/tasd/haofangReview/extraction/cktepoch=4.ckpt...\n",
      "Traceback (most recent call last):\n",
      "  File \"main.py\", line 460, in <module>\n",
      "    model_ckpt = torch.load(checkpoint, map_location=device)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/serialization.py\", line 581, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'outputs/tasd/haofangReview/extraction/cktepoch=4.ckpt'\n",
      "CPU times: user 36.6 ms, sys: 13.8 ms, total: 50.4 ms\n",
      "Wall time: 2.01 s\n",
      "CPU times: user 37.2 ms, sys: 14 ms, total: 51.2 ms\n",
      "Wall time: 2.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%%time\n",
    " #### [('lightweight easy to hold', 'product_spec')]\n",
    "\n",
    "!python main.py --task tasd \\\n",
    "            --dataset haofangReview \\\n",
    "            --ckpoint_path outputs/tasd/haofangReview/extraction/cktepoch=1.ckpt \\\n",
    "            --text \"I am pretty new to pickleball and finally decided to try out some different paddles. This one so far is my favorite of the ones I've purchased. It's very lightweight easy to hold and I would highly recommend for those of you that are looking for an affordable“ paddle\" \\\n",
    "            --paradigm extraction \\\n",
    "            --n_gpu 0 \\\n",
    "            --do_direct_predict \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510cfac",
   "metadata": {},
   "source": [
    "## output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ec1c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "f = open('./outputs/tasd/haofang/extraction/results-tasd-haofang-extraction-pred.pickle','rb')\n",
    "x = pickle.load(f)\n",
    "\n",
    "sent = [' '.join(i) for i in x['sent']]\n",
    "res_table = pd.DataFrame({'sentence':sent,\"label\":x['label'],\"prediction\":x['pred']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f168c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
